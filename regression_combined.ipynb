{
 "cells": [
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-11-18T08:32:48.922923Z",
     "start_time": "2025-11-18T08:32:46.834278Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def filter_and_clean_excel(input_path, output_path, columns_to_keep, sheet_name=0, diff_columns=None):\n",
    "    \"\"\"\n",
    "    ×˜×•×¢×Ÿ ×§×•×‘×¥ Excel (xlsx), ×‘×•×—×¨ ×¢××•×“×•×ª, ××•×—×§ ×©×•×¨×•×ª ×—×¡×¨×•×ª,\n",
    "    ××—×©×‘ ×¢××•×“×•×ª ×”×¤×¨×© (×× ×¡×•×¤×§×•), ×•×©×•××¨ ×›-CSV.\n",
    "\n",
    "    Args:\n",
    "        input_path (str): × ×ª×™×‘ ×œ×§×•×‘×¥ ×”-Excel.\n",
    "        output_path (str): × ×ª×™×‘ ×œ×©××™×¨×ª ×§×•×‘×¥ ×”-CSV ×”×—×“×©.\n",
    "        columns_to_keep (list): ×¨×©×™××ª ×”×¢××•×“×•×ª ×œ×©××•×¨ (×—×™×™×‘×ª ×œ×›×œ×•×œ ×¢××•×“×•×ª ×œ×—×™×©×•×‘).\n",
    "        sheet_name (str or int): ×©× ×”×’×™×œ×™×•×Ÿ (×‘×¨×™×¨×ª ××—×“×œ: 0).\n",
    "        diff_columns (dict): ××™×œ×•×Ÿ ×œ×”×’×“×¨×ª ×¢××•×“×•×ª ×”×¤×¨×©.\n",
    "                           ×¤×•×¨××˜: {'×©×_×¢××•×“×”_×—×“×©×”': ('×¢××•×“×”_A', '×¢××•×“×”_B')}\n",
    "                           ×”×—×™×©×•×‘ ×™×”×™×”: ×¢××•×“×”_A - ×¢××•×“×”_B\n",
    "    \"\"\"\n",
    "    print(f\"××ª×—×™×œ ×‘×ª×”×œ×™×š...\")\n",
    "\n",
    "    try:\n",
    "        # 1. ×˜×¢×™× ×ª ×”× ×ª×•× ×™× ××§×•×‘×¥ ××§×¡×œ\n",
    "        print(f\"×˜×•×¢×Ÿ × ×ª×•× ×™× ××§×•×‘×¥ Excel: {input_path} (×’×™×œ×™×•×Ÿ: {sheet_name})\")\n",
    "        df = pd.read_excel(\n",
    "            input_path,\n",
    "            sheet_name=sheet_name,\n",
    "            usecols=columns_to_keep\n",
    "        )\n",
    "        original_rows = len(df)\n",
    "        print(f\"× ×ª×•× ×™× × ×˜×¢× ×•. ×¦×•×¨×” ××§×•×¨×™×ª (×¨×§ ×¢××•×“×•×ª × ×‘×—×¨×•×ª): {df.shape}\")\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"×©×’×™××”: ×”×§×•×‘×¥ ×œ× × ××¦× ×‘× ×ª×™×‘: {input_path}\")\n",
    "        return\n",
    "    except ValueError as e:\n",
    "        print(f\"×©×’×™××”: ×™×™×ª×›×Ÿ ×©××—×ª ×”×¢××•×“×•×ª ×©×‘×™×§×©×ª ××™× ×” ×§×™×™××ª. {e}\")\n",
    "        return\n",
    "    except Exception as e:\n",
    "        print(f\"××™×¨×¢×” ×©×’×™××” ×‘×˜×¢×™× ×ª ×”×§×•×‘×¥: {e}\")\n",
    "        print(\"×”×¢×¨×”: ×•×“× ×©×”×¡×¤×¨×™×™×” 'openpyxl' ××•×ª×§× ×ª ('pip install openpyxl')\")\n",
    "        return\n",
    "\n",
    "    # 2. ××—×™×§×ª ×©×•×¨×•×ª ×¢× ×¢×¨×›×™× ×—×¡×¨×™× (NaN)\n",
    "    print(\"××•×—×§ ×©×•×¨×•×ª ×¢× ×¢×¨×›×™× ×—×¡×¨×™×...\")\n",
    "    df_cleaned = df.dropna()\n",
    "    cleaned_rows = len(df_cleaned)\n",
    "\n",
    "    rows_dropped = original_rows - cleaned_rows\n",
    "    print(f\"× ××—×§×• {rows_dropped} ×©×•×¨×•×ª.\")\n",
    "\n",
    "    # 3. ×”×•×¡×¤×ª ×¢××•×“×•×ª ×”×¤×¨×© (×”×—×œ×§ ×”×—×“×©)\n",
    "    if diff_columns:\n",
    "        print(\"××—×©×‘ ×¢××•×“×•×ª ×”×¤×¨×©...\")\n",
    "        # ×—×©×•×‘: ×”×©×ª××© ×‘-copy() ×›×“×™ ×œ×× ×•×¢ ××–×”×¨×ª SettingWithCopyWarning\n",
    "        df_cleaned = df_cleaned.copy()\n",
    "\n",
    "        for new_col, (col_a, col_b) in diff_columns.items():\n",
    "            if col_a in df_cleaned.columns and col_b in df_cleaned.columns:\n",
    "\n",
    "                # ×•×“× ×©×”×¢××•×“×•×ª ×”×Ÿ ××¡×¤×¨×™×•×ª ×œ×¤× ×™ ×”×—×™×¡×•×¨\n",
    "                # errors='coerce' ×™×”×¤×•×š ×˜×§×¡×˜ (×›××• \"N/A\") ×œ-NaN\n",
    "                col_a_numeric = pd.to_numeric(df_cleaned[col_a], errors='coerce')\n",
    "                col_b_numeric = pd.to_numeric(df_cleaned[col_b], errors='coerce')\n",
    "\n",
    "                # ×‘×¦×¢ ××ª ×”×—×™×©×•×‘\n",
    "                df_cleaned[new_col] = col_a_numeric - col_b_numeric\n",
    "                print(f\"  × ×•×¦×¨×” ×¢××•×“×”: {new_col} = {col_a} - {col_b}\")\n",
    "            else:\n",
    "                print(f\"  ××–×”×¨×”: ×œ× × ×™×ª×Ÿ ×œ×™×¦×•×¨ '{new_col}'. ××—×ª ××”×¢××•×“×•×ª ({col_a}, {col_b}) ×—×¡×¨×”.\")\n",
    "\n",
    "        # 4. × ×™×§×•×™ × ×•×¡×£\n",
    "        # ×× ×”×—×™×©×•×‘ ××• ×”×”××¨×” ×œ-numeric ×™×¦×¨×• ×¢×¨×›×™ NaN ×—×“×©×™×, × × ×§×” ×’× ××•×ª×\n",
    "        # (×–×” ×©×•××¨ ×¢×œ ×”×›×œ×œ ×©×œ×š \"×œ××—×•×§ ×©×•×¨×•×ª ×¢× ×¢×¨×›×™× ×¨×™×§×™×\")\n",
    "        final_cols_to_check = list(diff_columns.keys())\n",
    "        df_cleaned = df_cleaned.dropna(subset=final_cols_to_check)\n",
    "        final_rows_dropped = cleaned_rows - len(df_cleaned)\n",
    "\n",
    "        if final_rows_dropped > 0:\n",
    "            print(f\"× ××—×§×• {final_rows_dropped} ×©×•×¨×•×ª × ×•×¡×¤×•×ª ×¢×§×‘ ×—×™×©×•×‘ ×”×¤×¨×© (×œ××©×œ, ×˜×§×¡×˜ ×‘×¢××•×“×”).\")\n",
    "\n",
    "    print(f\"×¦×•×¨×” ×¡×•×¤×™×ª: {df_cleaned.shape}\")\n",
    "\n",
    "    # 5. ×©××™×¨×ª ×”×§×•×‘×¥ ×”×—×“×© ×›-CSV\n",
    "    try:\n",
    "        output_dir = os.path.dirname(output_path)\n",
    "        if output_dir:\n",
    "            os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "        df_cleaned.to_csv(output_path, index=False, encoding='utf-8-sig')\n",
    "        print(f\"\\nâœ… ×”×§×•×‘×¥ ×”× ×§×™ × ×©××¨ ×‘×”×¦×œ×—×” ×‘: {output_path}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"××™×¨×¢×” ×©×’×™××” ×‘×©××™×¨×ª ×”×§×•×‘×¥: {e}\")\n",
    "\n",
    "# ===================================================================\n",
    "#           ×“×•×’××ª ×©×™××•×©\n",
    "# ===================================================================\n",
    "\n",
    "# 1. ğŸ’¡ ×”×’×“×¨ ××ª *×›×œ* ×”×¢××•×“×•×ª ×©××ª×” ×¦×¨×™×š (×’× ×œ×—×™×©×•×‘ ×•×’× ×œ×©××™×¨×”)\n",
    "my_selected_columns = [\n",
    "    'Subject_Code',\n",
    "    'b_DES_average',\n",
    "    'after_DES_total',\n",
    "    'b_DERS_total',\n",
    "    'after_DERS_total',\n",
    "     \"after_DERS_Nonacceptance_Emotional_Responses\",\n",
    "     \"after_DERS_Goal_Directed_Behavior\",\n",
    "     \"after_DERS_Impulse_Control\",\n",
    "     \"after_DERS_Lack_Emotional_Awareness\",\n",
    "     \"after_DERS_Emotion_Regulation_Strategies\",\n",
    "     \"after_DERS_Lack_Emotional_Clarity\" ,\n",
    "]\n",
    "\n",
    "# 2. ğŸ’¡ ×”×’×“×¨ ××ª ×—×™×©×•×‘×™ ×”×”×¤×¨×©\n",
    "#    ×¤×•×¨××˜: '×©×_×—×“×©': ('××× ×•_×œ×—×¡×¨', '××”_×œ×—×¡×¨')\n",
    "my_diff_calculations = {\n",
    "    'diff_DES': ('after_DES_total', 'b_DES_average'),\n",
    "    'diff_DERS': ('after_DERS_total', 'b_DERS_total')\n",
    "}\n",
    "\n",
    "# 3. ğŸ’¡ ×”×’×“×¨ ××ª × ×ª×™×‘×™ ×”×§×‘×¦×™×\n",
    "input_file_path = 'data/q_data/Study_Questionnaire_Responses_October.xlsx'\n",
    "output_file_path = 'data/only_Q_outputs/combined/regression/regression_parameters.csv'\n",
    "\n",
    "# 4. ×§×¨×™××” ×œ×¤×•× ×§×¦×™×”\n",
    "filter_and_clean_excel(\n",
    "    input_path=input_file_path,\n",
    "    output_path=output_file_path,\n",
    "    columns_to_keep=my_selected_columns,\n",
    "    diff_columns=my_diff_calculations\n",
    ")"
   ],
   "id": "initial_id",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "××ª×—×™×œ ×‘×ª×”×œ×™×š...\n",
      "×˜×•×¢×Ÿ × ×ª×•× ×™× ××§×•×‘×¥ Excel: data/q_data/Study_Questionnaire_Responses_October.xlsx (×’×™×œ×™×•×Ÿ: 0)\n",
      "× ×ª×•× ×™× × ×˜×¢× ×•. ×¦×•×¨×” ××§×•×¨×™×ª (×¨×§ ×¢××•×“×•×ª × ×‘×—×¨×•×ª): (208, 11)\n",
      "××•×—×§ ×©×•×¨×•×ª ×¢× ×¢×¨×›×™× ×—×¡×¨×™×...\n",
      "× ××—×§×• 71 ×©×•×¨×•×ª.\n",
      "××—×©×‘ ×¢××•×“×•×ª ×”×¤×¨×©...\n",
      "  × ×•×¦×¨×” ×¢××•×“×”: diff_DES = after_DES_total - b_DES_average\n",
      "  × ×•×¦×¨×” ×¢××•×“×”: diff_DERS = after_DERS_total - b_DERS_total\n",
      "×¦×•×¨×” ×¡×•×¤×™×ª: (137, 13)\n",
      "\n",
      "âœ… ×”×§×•×‘×¥ ×”× ×§×™ × ×©××¨ ×‘×”×¦×œ×—×” ×‘: data/only_Q_outputs/combined/regression/regression_parameters.csv\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-18T08:48:06.472910Z",
     "start_time": "2025-11-18T08:48:05.920696Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# ---------- 1. Paths ----------\n",
    "t1_file = \"data/T1_first_session_data.xlsx\"  # the multi-sheet T1 file\n",
    "regression_file = \"data/only_Q_outputs/combined/regression/regression_parameters.csv\"\n",
    "pca_file = \"data/only_Q_outputs/combined/combined_pca_components.csv\"\n",
    "\n",
    "# Folder where you want the new CSVs:\n",
    "output_dir = \"data/only_Q_outputs/combined/regression\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# ---------- 2. Define the sheets you want to create CSVs for ----------\n",
    "sheets = [\n",
    "    \"global_parameters\",\n",
    "    \"subcortical_vol\",\n",
    "    \"cortical_vol_lr\",\n",
    "    \"cortical_lobes_lr\",\n",
    "    \"cortical_lobes_full_brain\",\n",
    "    \"cortical_networks_full_brain\",\n",
    "]\n",
    "\n",
    "# ---------- 3. Load regression + PCA data ----------\n",
    "reg_df = pd.read_csv(regression_file)\n",
    "pca_df = pd.read_csv(pca_file)\n",
    "\n",
    "# Normalize column names\n",
    "reg_df.columns = reg_df.columns.str.lower()\n",
    "pca_df.columns = pca_df.columns.str.lower()\n",
    "\n",
    "# Ensure we have subject_code and time_point\n",
    "# (rename here if your columns are a bit different)\n",
    "# reg_df = reg_df.rename(columns={\"your_reg_col\": \"subject_code\"})\n",
    "# pca_df = pca_df.rename(columns={\"your_pca_col\": \"subject_code\"})\n",
    "\n",
    "# ---------- 4. Keep only time point \"b\" ----------\n",
    "# If time_point is exactly \"b\":\n",
    "mask_b_pca = pca_df[\"timepoint\"].astype(str).str.contains(\"b\", case=False, na=False)\n",
    "\n",
    "reg_b = reg_df.copy()\n",
    "pca_b = pca_df[mask_b_pca].copy()\n",
    "\n",
    "# ---------- 5. Merge regression + PCA once (for all subjects) ----------\n",
    "# Merge on both subject_code and time_point to be safe\n",
    "merged_all = reg_b.merge(\n",
    "    pca_b,\n",
    "    on=[\"subject_code\"],\n",
    "    how=\"inner\",\n",
    "    suffixes=(\"_reg\", \"_pc\")\n",
    ")\n",
    "\n",
    "# Optionally drop rows that still have NaNs\n",
    "merged_all = merged_all.dropna(how=\"any\")\n",
    "\n",
    "print(f\"Total rows after merging regression + PCs (time point b): {len(merged_all)}\")\n",
    "\n",
    "# ---------- 6. For each T1 sheet, subset by subjects and save a CSV ----------\n",
    "for sheet_name in sheets:\n",
    "    print(f\"Processing sheet: {sheet_name}\")\n",
    "\n",
    "    # Load that sheet (just to get the subject list for this modality)\n",
    "    t1_df = pd.read_excel(t1_file, sheet_name=sheet_name)\n",
    "    t1_df.columns = t1_df.columns.str.lower()\n",
    "\n",
    "    if \"subject_code\" not in t1_df.columns:\n",
    "        raise ValueError(f\"'subject_code' column not found in sheet '{sheet_name}'\")\n",
    "\n",
    "    # Subjects present in this sheet\n",
    "    sheet_subjects = t1_df[\"subject_code\"].unique()\n",
    "\n",
    "    # Subset merged regression+PCs to these subjects\n",
    "    sheet_merged = merged_all[merged_all[\"subject_code\"].isin(sheet_subjects)].copy()\n",
    "\n",
    "    # If you also want to remove any remaining NaNs (just in case):\n",
    "    sheet_merged = sheet_merged.dropna(how=\"any\")\n",
    "\n",
    "    # ---------- 7. Save per-sheet CSV ----------\n",
    "    output_file = os.path.join(\n",
    "        output_dir,\n",
    "        f\"{sheet_name}_regression_pcs_b.csv\"\n",
    "    )\n",
    "    sheet_merged.to_csv(output_file, index=False)\n",
    "\n",
    "    print(f\"  Saved {len(sheet_merged)} rows to: {output_file}\")\n",
    "\n",
    "print(\"Done! All regression + PC CSVs (time point b) saved in the 'regression' folder.\")\n"
   ],
   "id": "36eae3e1796dd041",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows after merging regression + PCs (time point b): 114\n",
      "Processing sheet: global_parameters\n",
      "  Saved 80 rows to: data/only_Q_outputs/combined/regression\\global_parameters_regression_pcs_b.csv\n",
      "Processing sheet: subcortical_vol\n",
      "  Saved 80 rows to: data/only_Q_outputs/combined/regression\\subcortical_vol_regression_pcs_b.csv\n",
      "Processing sheet: cortical_vol_lr\n",
      "  Saved 80 rows to: data/only_Q_outputs/combined/regression\\cortical_vol_lr_regression_pcs_b.csv\n",
      "Processing sheet: cortical_lobes_lr\n",
      "  Saved 80 rows to: data/only_Q_outputs/combined/regression\\cortical_lobes_lr_regression_pcs_b.csv\n",
      "Processing sheet: cortical_lobes_full_brain\n",
      "  Saved 80 rows to: data/only_Q_outputs/combined/regression\\cortical_lobes_full_brain_regression_pcs_b.csv\n",
      "Processing sheet: cortical_networks_full_brain\n",
      "  Saved 80 rows to: data/only_Q_outputs/combined/regression\\cortical_networks_full_brain_regression_pcs_b.csv\n",
      "Done! All regression + PC CSVs (time point b) saved in the 'regression' folder.\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-18T08:14:55.768844Z",
     "start_time": "2025-11-18T08:14:55.765848Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "7c4d8db784558105",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-18T08:14:58.758764Z",
     "start_time": "2025-11-18T08:14:58.659970Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "# ---------- 1. Paths ----------\n",
    "t1_file = \"data/T1_first_session_data.xlsx\"      # this is the file you already uploaded\n",
    "subjects_file = \"data/only_Q_outputs/combined/regression_parameters.csv\"  # <-- change to your second file name\n",
    "\n",
    "# ---------- 2. Load the sheet you want from the T1 file ----------\n",
    "# Choose one of:\n",
    "#   \"global_parameters\"\n",
    "#   \"subcortical_vol\"\n",
    "#   \"cortical_vol_lr\"\n",
    "#   \"cortical_lobes_lr\"\n",
    "#   \"cortical_lobes_full_brain\"\n",
    "#   \"cortical_networks_full_brain\"\n",
    "\n",
    "sheet_name = \"cortical_networks_full_brain\"  # <-- change to the sheet you want\n",
    "\n",
    "t1_df = pd.read_excel(t1_file, sheet_name=sheet_name)\n",
    "\n",
    "# ---------- 3. Load the subject_code file ----------\n",
    "# If itâ€™s an Excel:\n",
    "subjects_df = pd.read_csv(subjects_file)\n",
    "# If itâ€™s CSV instead, use:\n",
    "# subjects_df = pd.read_csv(subjects_file)\n",
    "\n",
    "# ---------- 4. Normalize column names (to avoid Subject_Code vs subject_code issues) ----------\n",
    "t1_df.columns = t1_df.columns.str.lower()\n",
    "subjects_df.columns = subjects_df.columns.str.lower()\n",
    "\n",
    "# Make sure both have a 'subject_code' column\n",
    "# (rename here if your column is called differently)\n",
    "# subjects_df = subjects_df.rename(columns={\"your_col_name\": \"subject_code\"})\n",
    "\n",
    "# ---------- 5. Merge on subject_code ----------\n",
    "# subjects_df is treated as the main list of subjects\n",
    "merged = subjects_df.merge(t1_df, on=\"subject_code\", how=\"left\")\n",
    "\n",
    "# ---------- 6. Drop rows with ANY NaNs ----------\n",
    "# This removes any line that contains at least one NaN value\n",
    "merged_no_nan = merged.dropna(how=\"any\")\n",
    "\n",
    "# ---------- 7. Save result ----------\n",
    "output_file = \"data/merged_no_nan.csv\"\n",
    "merged_no_nan.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"Done! Saved merged file without NaNs to: {output_file}\")\n"
   ],
   "id": "1dc3c6ed174a4e19",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done! Saved merged file without NaNs to: data/merged_no_nan.csv\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# ---------- 1. Paths ----------\n",
    "t1_file = \"data/T1_first_session_data.xlsx\"  # the multi-sheet T1 file\n",
    "regression_file = \"data/only_Q_outputs/combined/regression_parameters.csv\"\n",
    "pca_file = \"data/combined_pca_components.csv\"\n",
    "\n",
    "# Folder where you want the new CSVs:\n",
    "output_dir = \"data/only_Q_outputs/combined/regression\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# ---------- 2. Define the sheets you want to create CSVs for ----------\n",
    "sheets = [\n",
    "    \"global_parameters\",\n",
    "    \"subcortical_vol\",\n",
    "    \"cortical_vol_lr\",\n",
    "    \"cortical_lobes_lr\",\n",
    "    \"cortical_lobes_full_brain\",\n",
    "    \"cortical_networks_full_brain\",\n",
    "]\n",
    "\n",
    "# ---------- 3. Load regression + PCA data ----------\n",
    "reg_df = pd.read_csv(regression_file)\n",
    "pca_df = pd.read_csv(pca_file)\n",
    "\n",
    "# Normalize column names\n",
    "reg_df.columns = reg_df.columns.str.lower()\n",
    "pca_df.columns = pca_df.columns.str.lower()\n",
    "\n",
    "# Ensure we have subject_code and time_point\n",
    "# (rename here if your columns are a bit different)\n",
    "# reg_df = reg_df.rename(columns={\"your_reg_col\": \"subject_code\"})\n",
    "# pca_df = pca_df.rename(columns={\"your_pca_col\": \"subject_code\"})\n",
    "\n",
    "# ---------- 4. Keep only time point \"b\" ----------\n",
    "# If time_point is exactly \"b\":\n",
    "mask_b_reg = reg_df[\"time_point\"].astype(str).str.contains(\"b\", case=False, na=False)\n",
    "mask_b_pca = pca_df[\"time_point\"].astype(str).str.contains(\"b\", case=False, na=False)\n",
    "\n",
    "reg_b = reg_df[mask_b_reg].copy()\n",
    "pca_b = pca_df[mask_b_pca].copy()\n",
    "\n",
    "# ---------- 5. Merge regression + PCA once (for all subjects) ----------\n",
    "# Merge on both subject_code and time_point to be safe\n",
    "merged_all = reg_b.merge(\n",
    "    pca_b,\n",
    "    on=[\"subject_code\", \"time_point\"],\n",
    "    how=\"inner\",\n",
    "    suffixes=(\"_reg\", \"_pc\")\n",
    ")\n",
    "\n",
    "# Optionally drop rows that still have NaNs\n",
    "merged_all = merged_all.dropna(how=\"any\")\n",
    "\n",
    "print(f\"Total rows after merging regression + PCs (time point b): {len(merged_all)}\")\n",
    "\n",
    "# ---------- 6. For each T1 sheet, subset by subjects and save a CSV ----------\n",
    "for sheet_name in sheets:\n",
    "    print(f\"Processing sheet: {sheet_name}\")\n",
    "\n",
    "    # Load that sheet (just to get the subject list for this modality)\n",
    "    t1_df = pd.read_excel(t1_file, sheet_name=sheet_name)\n",
    "    t1_df.columns = t1_df.columns.str.lower()\n",
    "\n",
    "    if \"subject_code\" not in t1_df.columns:\n",
    "        raise ValueError(f\"'subject_code' column not found in sheet '{sheet_name}'\")\n",
    "\n",
    "    # Subjects present in this sheet\n",
    "    sheet_subjects = t1_df[\"subject_code\"].unique()\n",
    "\n",
    "    # Subset merged regression+PCs to these subjects\n",
    "    sheet_merged = merged_all[merged_all[\"subject_code\"].isin(sheet_subjects)].copy()\n",
    "\n",
    "    # If you also want to remove any remaining NaNs (just in case):\n",
    "    sheet_merged = sheet_merged.dropna(how=\"any\")\n",
    "\n",
    "    # ---------- 7. Save per-sheet CSV ----------\n",
    "    output_file = os.path.join(\n",
    "        output_dir,\n",
    "        f\"{sheet_name}_regression_pcs_b.csv\"\n",
    "    )\n",
    "    sheet_merged.to_csv(output_file, index=False)\n",
    "\n",
    "    print(f\"  Saved {len(sheet_merged)} rows to: {output_file}\")\n",
    "\n",
    "print(\"Done! All regression + PC CSVs (time point b) saved in the 'regression' folder.\")\n"
   ],
   "id": "82ff806af8b3b55b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## pc1 predictio\n",
   "id": "8e5a67e9b9b10d19"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-18T08:15:01.133361Z",
     "start_time": "2025-11-18T08:15:00.781049Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# from sklearn.linear_model import LinearRegression\n",
    "# from sklearn.model_selection import KFold, cross_validate\n",
    "# from sklearn.metrics import mean_squared_error, r2_score\n",
    "# import os\n",
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "# from scipy import stats # ××©××© ×œ×—×™×©×•×‘ P-value\n",
    "#\n",
    "# # ===================================================================\n",
    "# #           ×—×œ×§ 1: ×”×’×“×¨×•×ª × ×ª×™×‘×™× ×•×¤×¨××˜×¨×™×\n",
    "# # ===================================================================\n",
    "#\n",
    "# # × ×ª×™×‘×™ ×”×§×‘×¦×™× - ×—×•×‘×” ×œ×¢×“×›×Ÿ ××ª × ×ª×™×‘ × ×ª×•× ×™ ×”-PC!\n",
    "# # ×§×•×‘×¥ ×–×” ×”×•× ×‘×¤×•×¨××˜ LONG: (Subject_Code | timepoint | PC1 | PC2 |...)\n",
    "# PC_DATA_LONG_PATH = \"data/only_Q_outputs/combined/combined_pca_components.csv\"\n",
    "# raw_data_path = \"data/only_Q_outputs/combined/regression_parameters.csv\"\n",
    "#\n",
    "# # ×ª×™×§×™×™×” ×œ×©××™×¨×ª ×›×œ ×”×’×¨×¤×™×\n",
    "# PLOTS_SAVE_DIR = \"data/only_Q_outputs/combined/regression_PC1_SIMPLE_plots_PIVOTED\"\n",
    "# # ×§×•×‘×¥ ×œ×©××™×¨×ª ×˜×‘×œ×ª ×”×¡×™×›×•×\n",
    "# SUMMARY_TABLE_SAVE_PATH = \"data/only_Q_outputs/combined/regression_PC1_SIMPLE_summary_table_PIVOTED.csv\"\n",
    "#\n",
    "# # ğŸ’¡ğŸ’¡ğŸ’¡\n",
    "# # --- ×”×’×“×¨ ×›××Ÿ ××ª ×”×¤×¨××˜×¨×™× ---\n",
    "# # ğŸ’¡ğŸ’¡ğŸ’¡\n",
    "#\n",
    "# # 1. ×¨×©×™××ª ×”××©×ª× ×™× *×”×§×‘×•×¢×™×* ×©××ª×” ×¨×•×¦×” ×œ× ×‘× (Y)\n",
    "# Y_VARIABLES_TO_PREDICT = [\n",
    "#     'b_DES_average',\n",
    "#     'after_DES_total',\n",
    "#     \"b_DERS_total\",\n",
    "#     \"after_DERS_total\",\n",
    "#     \"diff_DERS\",\n",
    "#     \"diff_DES\"\n",
    "# ]\n",
    "#\n",
    "# # 2. ×¨×©×™××ª × ×§×•×“×•×ª ×”×–××Ÿ ×•×”-PC's ×œ×©×™××•×©\n",
    "# PC_TIMEPOINTS = ['b', 't1', 't2', 't3', 'after']\n",
    "# PC_COMPONENT = 'PC1' # *** ××©×ª× ×” ×× ×‘× ×™×—×™×“: PC1 ***\n",
    "#\n",
    "# # 3. ×”×’×“×¨×•×ª ×œ××™××•×ª ×¦×•×œ×‘\n",
    "# N_SPLITS = 5\n",
    "# RANDOM_STATE = 42\n",
    "#\n",
    "# df_for_regression = None\n",
    "#\n",
    "# try:\n",
    "#     # ===================================================================\n",
    "#     #           ×—×œ×§ 1: ×”×›× ×ª ×”× ×ª×•× ×™× (×˜×¢×™× ×”, Pivot ×•××™×–×•×’)\n",
    "#     # ===================================================================\n",
    "#\n",
    "#     # --- 1×: ×˜×¢×™× ×ª × ×ª×•× ×™ ×”-PC ×‘-LONG FORMAT ---\n",
    "#     print(f\"Loading PC data in Long Format from {PC_DATA_LONG_PATH}...\")\n",
    "#     pc_df_long = pd.read_csv(PC_DATA_LONG_PATH)\n",
    "#\n",
    "#     # --- 1×‘: ×™×¦×™×¨×ª WIDE FORMAT (Pivot) ×¨×§ ×¢×‘×•×¨ PC1 ---\n",
    "#     print(f\"Pivoting to Wide Format using '{PC_COMPONENT}' values...\")\n",
    "#\n",
    "#     # ×•×“× ×©×›×œ ×”××™×“×¢ ×”×“×¨×•×© ×§×™×™× ×œ×¤× ×™ ×”×¤×™×•×•×˜\n",
    "#     if 'Subject_Code' not in pc_df_long.columns or 'timepoint' not in pc_df_long.columns or PC_COMPONENT not in pc_df_long.columns:\n",
    "#         raise ValueError(f\"Missing essential columns (Subject_Code, timepoint, or {PC_COMPONENT}) in the PC data.\")\n",
    "#\n",
    "#     pc_df_wide = pc_df_long.pivot(\n",
    "#         index='Subject_Code',\n",
    "#         columns='timepoint',\n",
    "#         values=PC_COMPONENT # ××©×ª××©×™× ×¨×§ ×‘-PC1\n",
    "#     ).reset_index()\n",
    "#\n",
    "#     # ×”××¨×” ×œ-float64\n",
    "#     for tp in PC_TIMEPOINTS:\n",
    "#         if tp in pc_df_wide.columns:\n",
    "#             pc_df_wide[tp] = pc_df_wide[tp].astype(np.float64, errors='ignore')\n",
    "#\n",
    "#     # --- 1×’: ×”×›× ×ª × ×ª×•× ×™ ×”-Y ×•××™×–×•×’ ---\n",
    "#     print(\"Loading Y variables and merging...\")\n",
    "#     columns_to_load = ['Subject_Code'] + Y_VARIABLES_TO_PREDICT\n",
    "#     raw_df = pd.read_csv(raw_data_path, usecols=lambda c: c in columns_to_load)\n",
    "#\n",
    "#     # ×”××¨×” ×œ-float64\n",
    "#     for y_col in Y_VARIABLES_TO_PREDICT:\n",
    "#         if y_col in raw_df.columns:\n",
    "#             raw_df[y_col] = raw_df[y_col].astype(np.float64, errors='ignore')\n",
    "#\n",
    "#     df_for_regression = pd.merge(\n",
    "#         pc_df_wide,\n",
    "#         raw_df,\n",
    "#         on='Subject_Code',\n",
    "#         how='inner'\n",
    "#     )\n",
    "#\n",
    "#     print(\"--- Data successfully merged (Wide Format for PC1) ---\")\n",
    "#     print(df_for_regression.head())\n",
    "#\n",
    "#     # ×™×¦×™×¨×ª ×ª×™×§×™×™×ª ×”×¤×œ×˜ ×œ×’×¨×¤×™×\n",
    "#     os.makedirs(PLOTS_SAVE_DIR, exist_ok=True)\n",
    "#\n",
    "# except FileNotFoundError:\n",
    "#     print(f\"×©×’×™××”: ××—×“ ××§×•×‘×¦×™ ×”× ×ª×•× ×™× ×œ× × ××¦×. ×•×“× × ×ª×™×‘×™×.\")\n",
    "#     df_for_regression = None\n",
    "# except Exception as e:\n",
    "#     # ×”×¦×’×ª ×”×©×’×™××” ×©×”×ª×¨×—×©×” (×›×“×™ ×œ×“×¢×ª ××™×¤×” ×”×‘×¢×™×”)\n",
    "#     print(f\"××™×¨×¢×” ×©×’×™××”: {e}\")\n",
    "#     df_for_regression = None\n",
    "#\n",
    "# # ===================================================================\n",
    "# #           ×—×œ×§ 2: ×”×¨×¦×ª ×”× ×™×ª×•×— ×‘×œ×•×œ××” (×¨×’×¨×¡×™×” ×¤×©×•×˜×” ×•-CV)\n",
    "# # ===================================================================\n",
    "#\n",
    "# all_results_list = []\n",
    "#\n",
    "# if df_for_regression is not None:\n",
    "#\n",
    "#     # --- ×”×ª×—×œ×ª ×”×œ×•×œ××•×ª ---\n",
    "#     for y_col in Y_VARIABLES_TO_PREDICT:\n",
    "#         print(f\"\\n=======================================================\")\n",
    "#         print(f\"  Processing Y-Variable: {y_col}\")\n",
    "#         print(f\"=======================================================\")\n",
    "#\n",
    "#         # *** ×”×œ×•×œ××” ×¨×¦×” ×¢×œ ×›×œ × ×§×•×“×ª ×–××Ÿ ×›×¢××•×“×ª ×× ×‘× ***\n",
    "#         for predictor_col_name in PC_TIMEPOINTS:\n",
    "#\n",
    "#             if predictor_col_name not in df_for_regression.columns:\n",
    "#                 print(f\"--- Skipping: Timepoint column '{predictor_col_name}' not found after pivot.\")\n",
    "#                 continue\n",
    "#\n",
    "#             timepoint_name = predictor_col_name # ×©× ×”×¢××•×“×” (×œ×“×•×’××” 'b') ×”×•× ×©× × ×§×•×“×ª ×”×–××Ÿ\n",
    "#\n",
    "#             print(f\"\\n--- Running Simple Regression: '{y_col}' ~ '{predictor_col_name}' ({PC_COMPONENT} at {timepoint_name}) ---\")\n",
    "#\n",
    "#             # 4. ×”×›× ×ª X ×•-Y, ×•× ×™×§×•×™ ×¢×¨×›×™× ×—×¡×¨×™×\n",
    "#             data_clean = df_for_regression[[predictor_col_name, y_col]].dropna()\n",
    "#\n",
    "#             if len(data_clean) < N_SPLITS * 2:\n",
    "#                 print(f\"  Skipping: Not enough data (N={len(data_clean)})\")\n",
    "#                 continue\n",
    "#\n",
    "#             # X ×—×™×™×‘ ×œ×”×™×•×ª ××˜×¨×™×¦×” ×“×•-×××“×™×ª ×¢×‘×•×¨ sklearn\n",
    "#             X = data_clean[[predictor_col_name]]\n",
    "#             y = data_clean[y_col]\n",
    "#\n",
    "#             # --- ğŸ’¡ ×—×™×©×•×‘ P-value (P-value ×¢×‘×•×¨ ××§×“× ×‘×˜× ×©×œ ×”×¨×’×¨×¡×™×”)\n",
    "#             try:\n",
    "#                 slope, intercept, r_value, p_value, std_err = stats.linregress(X[predictor_col_name], y)\n",
    "#                 t_stat = slope / std_err\n",
    "#             except ValueError:\n",
    "#                 t_stat, p_value, slope, intercept = np.nan, np.nan, np.nan, np.nan\n",
    "#             # -------------------------------------------------------------\n",
    "#\n",
    "#             # 5. ×©×œ×‘ ×': ×”×¢×¨×›×ª ×”××•×“×œ (××™××•×ª ×¦×•×œ×‘)\n",
    "#             model_cv = LinearRegression()\n",
    "#             kfold = KFold(n_splits=N_SPLITS, shuffle=True, random_state=RANDOM_STATE)\n",
    "#             scoring = {'r_squared': 'r2', 'neg_mse': 'neg_mean_squared_error'}\n",
    "#\n",
    "#             # *** ×”×ª×™×§×•×Ÿ ×›××Ÿ: cv=kfold ***\n",
    "#             cv_scores = cross_validate(model_cv, X, y, cv=kfold, scoring=scoring)\n",
    "#\n",
    "#             mean_r2 = np.mean(cv_scores['test_r_squared'])\n",
    "#             std_r2 = np.std(cv_scores['test_r_squared'])\n",
    "#             mean_rmse = np.sqrt(-np.mean(cv_scores['test_neg_mse']))\n",
    "#             print(f\"  RÂ² (CV): {mean_r2:.3f} | RMSE (CV): {mean_rmse:.3f} | N = {len(y)}\")\n",
    "#\n",
    "#             # 6. ×©×œ×‘ ×‘': ××§×“××™× ×¡×•×¤×™×™×\n",
    "#             alpha = intercept\n",
    "#             beta = slope\n",
    "#             print(f\"  Intercept (Alpha): {alpha:.4f} | Slope (Beta): {beta:.4f}\")\n",
    "#             print(f\"  P-value (Beta): {p_value:.4f}\")\n",
    "#\n",
    "#             # ===============================================================\n",
    "#             #               ğŸ’¡ğŸ’¡ğŸ’¡ ×ª× ××™: ×”×¦×’×” ×¨×§ ×× RÂ² ×—×™×•×‘×™ ğŸ’¡ğŸ’¡ğŸ’¡\n",
    "#             # ===============================================================\n",
    "#             if mean_r2 > 0:\n",
    "#                 print(f\"  âœ… RÂ² is positive ({mean_r2:.3f}). Plotting graph.\")\n",
    "#\n",
    "#                 # 7. ×©×œ×‘ ×’': ×©×¨×˜×•×˜ ×”×’×¨×£ (×’×¨×£ ×¤×™×–×•×¨)\n",
    "#                 plt.figure(figsize=(8, 6))\n",
    "#\n",
    "#                 # ×’×¨×£ ×¤×™×–×•×¨ ×©×œ ×”× ×ª×•× ×™×\n",
    "#                 sns.scatterplot(x=predictor_col_name, y=y_col, data=data_clean, color='darkblue', alpha=0.7)\n",
    "#\n",
    "#                 # ×”×•×¡×¤×ª ×§×• ×”×¨×’×¨×¡×™×”\n",
    "#                 sns.regplot(x=predictor_col_name, y=y_col, data=data_clean, scatter=False, color='red', line_kws={'lw': 2, 'linestyle': '-'})\n",
    "#\n",
    "#                 plt.title(f'Prediction: {y_col} by {PC_COMPONENT} at Timepoint {timepoint_name}')\n",
    "#                 plt.xlabel(f'{PC_COMPONENT} ({timepoint_name})')\n",
    "#                 plt.ylabel(f'{y_col}')\n",
    "#\n",
    "#                 plt.text(0.05, 0.95,\n",
    "#                          f'$R^2$ (CV) = {mean_r2:.3f}\\nSlope (Beta) = {beta:.3f}\\n$P$ (Beta) = {p_value:.4f}',\n",
    "#                          transform=plt.gca().transAxes,\n",
    "#                          verticalalignment='top',\n",
    "#                          bbox=dict(boxstyle='round,pad=0.5', fc='white', alpha=0.7))\n",
    "#\n",
    "#                 plt.tight_layout()\n",
    "#\n",
    "#                 # ×©××™×¨×ª ×”×’×¨×£ ×¢× ×©× ×™×™×—×•×“×™\n",
    "#                 plot_save_path = os.path.join(PLOTS_SAVE_DIR, f\"simple_reg_{y_col}_vs_{PC_COMPONENT}_{predictor_col_name}.png\")\n",
    "#                 plt.savefig(plot_save_path, dpi=100)\n",
    "#                 plt.close()\n",
    "#                 print(f\"  Plot saved to {plot_save_path}\")\n",
    "#             else:\n",
    "#                 print(f\"  âŒ RÂ² is not positive ({mean_r2:.3f}). Skipping graph plotting.\")\n",
    "#             # ===============================================================\n",
    "#\n",
    "#             # 8. ×©××™×¨×ª ×”×ª×•×¦××•×ª ×œ×¨×©×™××”\n",
    "#             all_results_list.append({\n",
    "#                 'Y_Variable': y_col,\n",
    "#                 'X_Variable (PC1_Timepoint)': predictor_col_name,\n",
    "#                 'PC_Component': PC_COMPONENT,\n",
    "#                 'Timepoint': timepoint_name,\n",
    "#                 'R_Squared_CV': mean_r2,\n",
    "#                 'R_Squared_Std': std_r2,\n",
    "#                 'RMSE_CV': mean_rmse,\n",
    "#                 'Alpha_Intercept': alpha,\n",
    "#                 'Beta_Slope': beta,\n",
    "#                 'T_Stat': t_stat,\n",
    "#                 'P_Value': p_value,\n",
    "#                 'N': len(y),\n",
    "#                 'Plotted': mean_r2 > 0\n",
    "#             })\n",
    "#\n",
    "#     print(\"\\n\\n--- ×›×œ ×”× ×™×ª×•×—×™× ×”×¡×ª×™×™××• ---\")\n",
    "#\n",
    "#     # ===================================================================\n",
    "#     #           ×—×œ×§ 3: ×™×¦×™×¨×ª ×˜×‘×œ×ª ×¡×™×›×•×\n",
    "#     # ===================================================================\n",
    "#\n",
    "#     if all_results_list:\n",
    "#         summary_df = pd.DataFrame(all_results_list)\n",
    "#         # × ××™×™×Ÿ ×œ×¤×™ R^2 ×™×•×¨×“\n",
    "#         summary_df = summary_df.sort_values(by=['Y_Variable', 'R_Squared_CV'], ascending=[True, False])\n",
    "#\n",
    "#         print(\"\\n--- ×˜×‘×œ×ª ×¡×™×›×•× ×¡×•×¤×™×ª (×¨×’×¨×¡×™×” ×¤×©×•×˜×” PC1) ---\")\n",
    "#\n",
    "#         summary_df.to_csv(SUMMARY_TABLE_SAVE_PATH, index=False, encoding='utf-8-sig')\n",
    "#         print(f\"\\nâœ… ×˜×‘×œ×ª ×”×¡×™×›×•× × ×©××¨×” ×‘: {SUMMARY_TABLE_SAVE_PATH}\")\n",
    "#     else:\n",
    "#         print(\"\\n--- ×œ× × ×•×¦×¨×• ×ª×•×¦××•×ª ---\")\n",
    "#\n",
    "# else:\n",
    "#     print(\"×”× ×™×ª×•×— ×œ× ×¨×¥ ×›×™ ×”× ×ª×•× ×™× ×œ× × ×˜×¢× ×• ×›×¨××•×™.\")"
   ],
   "id": "90985271b8b2468f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading PC data in Long Format from data/only_Q_outputs/combined/combined_pca_components.csv...\n",
      "×©×’×™××”: ××—×“ ××§×•×‘×¦×™ ×”× ×ª×•× ×™× ×œ× × ××¦×. ×•×“× × ×ª×™×‘×™×.\n",
      "×”× ×™×ª×•×— ×œ× ×¨×¥ ×›×™ ×”× ×ª×•× ×™× ×œ× × ×˜×¢× ×• ×›×¨××•×™.\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## clusters prediction\n",
   "id": "726615f6e0353ecf"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-18T08:15:01.171375Z",
     "start_time": "2025-11-18T08:15:01.145374Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import KFold, cross_validate\n",
    "from sklearn.metrics import make_scorer, mean_squared_error, r2_score\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats # ×œ×¡×¤×™×¨×ª P-value (××•×‘×”×§×•×ª)\n",
    "\n",
    "# ===================================================================\n",
    "#           ×—×œ×§ 1: ×”×›× ×ª ×”× ×ª×•× ×™× (×˜×¢×™× ×”, ×•××™×–×•×’)\n",
    "# ===================================================================\n",
    "\n",
    "# × ×ª×™×‘×™ ×”×§×‘×¦×™× - ×—×•×‘×” ×œ×¢×“×›×Ÿ ××ª × ×ª×™×‘ ×”××©×›×•×œ×•×ª!\n",
    "# ×§×•×‘×¥ ×–×” ×¦×¨×™×š ×œ×”×™×•×ª ×‘×¤×•×¨××˜: (Subject_Code | b | t1 | t2 | t3 | after)\n",
    "CLUSTER_DATA_WIDE_PATH = \"data/only_Q_outputs/combined/timepoints_file_inverted_2.csv\"\n",
    "raw_data_path = \"data/only_Q_outputs/combined/regression_parameters.csv\"\n",
    "\n",
    "# ×ª×™×§×™×™×” ×œ×©××™×¨×ª ×›×œ ×”×’×¨×¤×™× - ×©×™× ×•×™ ×©× ×”×ª×™×§×™×™×” ×›×“×™ ×œ×©×§×£ ×¡×™× ×•×Ÿ\n",
    "PLOTS_SAVE_DIR = \"data/only_Q_outputs/combined/cluster_ders_des_regression_CLUSTER_POSITIVE_R2_plots\"\n",
    "# ×§×•×‘×¥ ×œ×©××™×¨×ª ×˜×‘×œ×ª ×”×¡×™×›×•×\n",
    "SUMMARY_TABLE_SAVE_PATH = \"data/only_Q_outputs/combined/clusters_regression_CLUSTER_WIDE_summary_table_filtered.csv\"\n",
    "\n",
    "# ğŸ’¡ğŸ’¡ğŸ’¡\n",
    "# --- ×”×’×“×¨ ×›××Ÿ ××ª ×”×¤×¨××˜×¨×™× ---\n",
    "# ğŸ’¡ğŸ’¡ğŸ’¡\n",
    "\n",
    "# 1. ×¨×©×™××ª ×”××©×ª× ×™× *×”×§×‘×•×¢×™×* ×©××ª×” ×¨×•×¦×” ×œ× ×‘× (Y) - (×›××• ×§×•×“×)\n",
    "Y_VARIABLES_TO_PREDICT = [\n",
    "    'b_DES_average',\n",
    "    'after_DES_total',\n",
    "    \"b_DERS_total\",\n",
    "    \"after_DERS_total\",\n",
    "    \"diff_DERS\",\n",
    "    \"diff_DES\"\n",
    "    # ğŸ’¡ ×”×•×¡×£ ×›××Ÿ ×¢×•×“ ×©××•×ª ×¢××•×“×•×ª\n",
    "]\n",
    "\n",
    "# 2. ×¨×©×™××ª × ×§×•×“×•×ª ×”×–××Ÿ ×©×œ ×”××©×›×•×œ (X)\n",
    "# ×”×¨×©×™××” ×”×–×• ×—×™×™×‘×ª ×œ×”×ª××™× ×œ×©××•×ª ×”×¢××•×“×•×ª ×‘×§×•×‘×¥ ×”××©×›×•×œ×•×ª (CLUSTER_DATA_WIDE_PATH)\n",
    "CLUSTER_TIMEPOINTS = ['before', 't1', 't2', 't3', 'after']\n",
    "\n",
    "df_for_regression = None\n",
    "\n",
    "try:\n",
    "    # --- 1×: ×”×›× ×ª × ×ª×•× ×™ ×”-X (Cluster) ---\n",
    "    print(\"Loading Cluster data in Wide Format...\")\n",
    "    cluster_df_wide = pd.read_csv(CLUSTER_DATA_WIDE_PATH)\n",
    "\n",
    "    # --- 1×‘: ×”×›× ×ª × ×ª×•× ×™ ×”-Y (×›××• ×§×•×“×) ---\n",
    "    print(\"Loading Y variables...\")\n",
    "    columns_to_load = ['Subject_Code'] + Y_VARIABLES_TO_PREDICT\n",
    "    raw_df = pd.read_csv(raw_data_path, usecols=lambda c: c in columns_to_load)\n",
    "\n",
    "    # --- 1×’: ××™×–×•×’ ---\n",
    "    df_for_regression = pd.merge(\n",
    "        cluster_df_wide,\n",
    "        raw_df,\n",
    "        on='Subject_Code'\n",
    "    )\n",
    "\n",
    "    # ×•×“× ×©×›×œ ×¢××•×“×•×ª ×”×§×œ××¡×˜×¨ (×”×Ÿ ×”-X ×©×œ× ×•) ×”×Ÿ ××¡×¤×¨×™× ×©×œ××™× (0 ××• 1)\n",
    "    for tp in CLUSTER_TIMEPOINTS:\n",
    "         df_for_regression[tp] = df_for_regression[tp].astype('Int64', errors='ignore')\n",
    "\n",
    "    print(\"--- Data successfully merged ---\")\n",
    "    print(df_for_regression.head())\n",
    "\n",
    "    # ×™×¦×™×¨×ª ×ª×™×§×™×™×ª ×”×¤×œ×˜ ×œ×’×¨×¤×™×\n",
    "    os.makedirs(PLOTS_SAVE_DIR, exist_ok=True)\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(\"×©×’×™××”: ××—×“ ××§×•×‘×¦×™ ×”× ×ª×•× ×™× ×œ× × ××¦×. ×•×“× ×©-CLUSTER_DATA_WIDE_PATH ×•-raw_data_path × ×›×•× ×™×.\")\n",
    "    df_for_regression = None\n",
    "except ValueError as e:\n",
    "    print(f\"×©×’×™××” ×‘×˜×¢×™× ×ª ×”× ×ª×•× ×™×. ×™×™×ª×›×Ÿ ×©××—×ª ×”×¢××•×“×•×ª ×‘-Y_VARIABLES_TO_PREDICT ××™× ×” ×§×™×™××ª. {e}\")\n",
    "    df_for_regression = None\n",
    "except Exception as e:\n",
    "    print(f\"××™×¨×¢×” ×©×’×™××”: {e}\")\n",
    "    df_for_regression = None\n",
    "\n",
    "# ===================================================================\n",
    "#           ×—×œ×§ 2: ×”×¨×¦×ª ×”× ×™×ª×•×— ×‘×œ×•×œ××” (×¨×’×¨×¡×™×” ×•-CV)\n",
    "# ===================================================================\n",
    "\n",
    "# ×”×’×“×¨×•×ª × ×•×¡×¤×•×ª\n",
    "N_SPLITS = 5\n",
    "RANDOM_STATE = 42\n",
    "all_results_list = []\n",
    "\n",
    "if df_for_regression is not None:\n",
    "\n",
    "    # --- ×”×ª×—×œ×ª ×”×œ×•×œ××•×ª ---\n",
    "    for y_col in Y_VARIABLES_TO_PREDICT:\n",
    "        print(f\"\\n=======================================================\")\n",
    "        print(f\"  Processing Y-Variable: {y_col}\")\n",
    "        print(f\"=======================================================\")\n",
    "\n",
    "        for tp in CLUSTER_TIMEPOINTS:\n",
    "\n",
    "            # 3. ×‘× ×™×™×ª ×©× ×”××©×ª× ×” ×”×× ×‘× (X)\n",
    "            X_COL_NAME = tp\n",
    "\n",
    "            if X_COL_NAME not in df_for_regression.columns:\n",
    "                print(f\"--- Skipping: Cluster column '{X_COL_NAME}' not found in merged data.\")\n",
    "                continue\n",
    "\n",
    "            print(f\"\\n--- Running: '{y_col}' ~ '{X_COL_NAME}' (Cluster) ---\")\n",
    "\n",
    "            # 4. ×”×›× ×ª X ×•-Y, ×•× ×™×§×•×™ ×¢×¨×›×™× ×—×¡×¨×™×\n",
    "            data_clean = df_for_regression[[X_COL_NAME, y_col]].dropna()\n",
    "\n",
    "            if len(data_clean) < N_SPLITS * 2:\n",
    "                print(f\"  Skipping: Not enough data (N={len(data_clean)})\")\n",
    "                continue\n",
    "\n",
    "            X = data_clean[[X_COL_NAME]]\n",
    "            y = data_clean[y_col]\n",
    "\n",
    "            # --- ğŸ’¡ ×—×™×©×•×‘ P-value ×‘×××¦×¢×•×ª ×¡×˜×˜×™×¡×˜×™×§×ª T (t-test)\n",
    "            if X[X_COL_NAME].nunique() < 2:\n",
    "                print(f\"  Skipping: Only one cluster ({X[X_COL_NAME].iloc[0]}) in the data for this timepoint.\")\n",
    "                continue\n",
    "\n",
    "            group0 = data_clean[data_clean[X_COL_NAME] == 0][y_col]\n",
    "            group1 = data_clean[data_clean[X_COL_NAME] == 1][y_col]\n",
    "\n",
    "            if len(group0) > 1 and len(group1) > 1:\n",
    "                t_stat, p_value = stats.ttest_ind(group1, group0, equal_var=False, nan_policy='omit')\n",
    "            else:\n",
    "                t_stat, p_value = np.nan, np.nan\n",
    "            # -------------------------------------------------------------\n",
    "\n",
    "            # 5. ×©×œ×‘ ×': ×”×¢×¨×›×ª ×”××•×“×œ (××™××•×ª ×¦×•×œ×‘)\n",
    "            model_cv = LinearRegression()\n",
    "            kfold = KFold(n_splits=N_SPLITS, shuffle=True, random_state=RANDOM_STATE)\n",
    "            scoring = {'r_squared': 'r2', 'neg_mse': 'neg_mean_squared_error'}\n",
    "\n",
    "            cv_scores = cross_validate(model_cv, X, y, cv=kfold, scoring=scoring)\n",
    "\n",
    "            mean_r2 = np.mean(cv_scores['test_r_squared'])\n",
    "            std_r2 = np.std(cv_scores['test_r_squared'])\n",
    "            mean_rmse = np.sqrt(-np.mean(cv_scores['test_neg_mse']))\n",
    "            print(f\"  RÂ² (CV): {mean_r2:.3f} | RMSE (CV): {mean_rmse:.3f} | N = {len(y)}\")\n",
    "\n",
    "            # 6. ×©×œ×‘ ×‘': ××™××•×Ÿ ××•×“×œ ×¡×•×¤×™ (×œ×§×‘×œ×ª ××§×“××™×)\n",
    "            model_final = LinearRegression()\n",
    "            model_final.fit(X, y)\n",
    "            alpha = model_final.intercept_\n",
    "            beta = model_final.coef_[0]\n",
    "            print(f\"  Mean Cluster 0 (Alpha): {alpha:.4f} | Diff Clust 1-0 (Beta): {beta:.4f}\")\n",
    "            print(f\"  P-value (t-test): {p_value:.4f}\")\n",
    "\n",
    "            # ===============================================================\n",
    "            #               ğŸ’¡ğŸ’¡ğŸ’¡ ×ª× ××™ ×—×“×©: ×”×¦×’×” ×¨×§ ×× RÂ² ×—×™×•×‘×™ ğŸ’¡ğŸ’¡ğŸ’¡\n",
    "            # ===============================================================\n",
    "            if mean_r2 > 0:\n",
    "                print(f\"  âœ… RÂ² is positive ({mean_r2:.3f}). Plotting graph.\")\n",
    "\n",
    "                # 7. ×©×œ×‘ ×’': ×©×¨×˜×•×˜ ×”×’×¨×£\n",
    "                plt.figure(figsize=(8, 6))\n",
    "                sns.boxplot(x=X_COL_NAME, y=y_col, data=data_clean, palette='pastel')\n",
    "                sns.stripplot(x=X_COL_NAME, y=y_col, data=data_clean, color='black', size=4, alpha=0.7, jitter=True)\n",
    "\n",
    "                # ×”×•×¡×¤×ª ×§×• ×”×¨×’×¨×¡×™×” (×××•×¦×¢×™×)\n",
    "                plt.axhline(alpha, color='red', linestyle='--', label=f'Mean Clust 0 ({alpha:.2f})')\n",
    "                plt.axhline(alpha + beta, color='blue', linestyle='--', label=f'Mean Clust 1 ({alpha + beta:.2f})')\n",
    "\n",
    "                plt.title(f'Prediction: {y_col} by Cluster ({X_COL_NAME})')\n",
    "                plt.xlabel(f'Cluster (0 vs 1) at Timepoint: {X_COL_NAME}')\n",
    "                plt.ylabel(f'{y_col}')\n",
    "\n",
    "                plt.text(0.05, 0.95,\n",
    "                         f'$R^2$ (CV) = {mean_r2:.3f}\\nDiff (Beta) = {beta:.3f}\\n$P$ (t-test) = {p_value:.4f}',\n",
    "                         transform=plt.gca().transAxes,\n",
    "                         verticalalignment='top',\n",
    "                         bbox=dict(boxstyle='round,pad=0.5', fc='white', alpha=0.7))\n",
    "\n",
    "                plt.tight_layout()\n",
    "\n",
    "                # ×©××™×¨×ª ×”×’×¨×£ ×¢× ×©× ×™×™×—×•×“×™\n",
    "                plot_save_path = os.path.join(PLOTS_SAVE_DIR, f\"cluster_reg_{y_col}_vs_{X_COL_NAME}.png\")\n",
    "                plt.savefig(plot_save_path, dpi=100)\n",
    "                plt.close()\n",
    "                print(f\"  Plot saved to {plot_save_path}\")\n",
    "            else:\n",
    "                print(f\"  âŒ RÂ² is not positive ({mean_r2:.3f}). Skipping graph plotting.\")\n",
    "            # ===============================================================\n",
    "            #                         ×¡×•×£ ×”×ª× ××™\n",
    "            # ===============================================================\n",
    "\n",
    "            # 8. ×©××™×¨×ª ×”×ª×•×¦××•×ª ×œ×¨×©×™××” (×©×•××¨×™× ××ª ×›×œ ×”×ª×•×¦××•×ª, ×’× ×©×œ×™×œ×™×•×ª, ×‘×˜×‘×œ×”)\n",
    "            all_results_list.append({\n",
    "                'Y_Variable': y_col,\n",
    "                'X_Variable (Cluster Timepoint)': X_COL_NAME,\n",
    "                'R_Squared_CV': mean_r2,\n",
    "                'R_Squared_Std': std_r2,\n",
    "                'RMSE_CV': mean_rmse,\n",
    "                'Alpha_Mean_Clust0': alpha,\n",
    "                'Beta_Diff_Clust1_Minus_Clust0': beta,\n",
    "                'T_Stat': t_stat,\n",
    "                'P_Value': p_value,\n",
    "                'N': len(y),\n",
    "                'Plotted': mean_r2 > 0 # ×”×•×¡×¤×ª ××™× ×“×™×§×¦×™×” ×”×× ×”×’×¨×£ ×©×•×¨×˜×˜\n",
    "            })\n",
    "\n",
    "    print(\"\\n\\n--- ×›×œ ×”× ×™×ª×•×—×™× ×”×¡×ª×™×™××• ---\")\n",
    "\n",
    "    # ===================================================================\n",
    "    #           ×—×œ×§ 3: ×™×¦×™×¨×ª ×˜×‘×œ×ª ×¡×™×›×•×\n",
    "    # ===================================================================\n",
    "\n",
    "    if all_results_list:\n",
    "        summary_df = pd.DataFrame(all_results_list)\n",
    "        # ×›×“×™ ×œ×”×§×œ ×¢×œ ×”×¡×™× ×•×Ÿ, × ××™×™×Ÿ ×œ×¤×™ R^2 ×™×•×¨×“\n",
    "        summary_df = summary_df.sort_values(by=['Y_Variable', 'R_Squared_CV'], ascending=[True, False])\n",
    "\n",
    "        print(\"\\n--- ×˜×‘×œ×ª ×¡×™×›×•× ×¡×•×¤×™×ª ---\")\n",
    "\n",
    "        summary_df.to_csv(SUMMARY_TABLE_SAVE_PATH, index=False, encoding='utf-8-sig')\n",
    "        print(f\"\\nâœ… ×˜×‘×œ×ª ×”×¡×™×›×•× × ×©××¨×” ×‘: {SUMMARY_TABLE_SAVE_PATH}\")\n",
    "    else:\n",
    "        print(\"\\n--- ×œ× × ×•×¦×¨×• ×ª×•×¦××•×ª ---\")\n",
    "\n",
    "else:\n",
    "    print(\"×”× ×™×ª×•×— ×œ× ×¨×¥ ×›×™ ×”× ×ª×•× ×™× ×œ× × ×˜×¢× ×• ×›×¨××•×™.\")"
   ],
   "id": "9eabe5a581a6e662",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Cluster data in Wide Format...\n",
      "×©×’×™××”: ××—×“ ××§×•×‘×¦×™ ×”× ×ª×•× ×™× ×œ× × ××¦×. ×•×“× ×©-CLUSTER_DATA_WIDE_PATH ×•-raw_data_path × ×›×•× ×™×.\n",
      "×”× ×™×ª×•×— ×œ× ×¨×¥ ×›×™ ×”× ×ª×•× ×™× ×œ× × ×˜×¢× ×• ×›×¨××•×™.\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## only T1 predict clinical\n",
   "id": "152f142821611f21"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-18T08:15:02.173079Z",
     "start_time": "2025-11-18T08:15:01.241008Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import KFold, cross_validate\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats # ××©××© ×œ×—×™×©×•×‘ P-value\n",
    "\n",
    "# ===================================================================\n",
    "#           ×—×œ×§ 1: ×”×’×“×¨×•×ª × ×ª×™×‘×™× ×•×¤×¨××˜×¨×™×\n",
    "# ===================================================================\n",
    "\n",
    "# × ×ª×™×‘ ×”×§×•×‘×¥ - ×”×§×•×‘×¥ ××›×™×œ ××ª ×›×œ ×”× ×ª×•× ×™× ×”× ×“×¨×©×™× (X ×•-Y)\n",
    "# ğŸ’¡ ×•×“× ×©×”× ×ª×™×‘ ×”×–×” × ×›×•×Ÿ ×œ×§×•×‘×¥ ×”×××•×–×’ ×©×œ×š.\n",
    "DATA_PATH = \"data/merged_no_nan.csv\"\n",
    "\n",
    "# ×ª×™×§×™×™×” ×œ×©××™×¨×ª ×›×œ ×”×’×¨×¤×™×\n",
    "PLOTS_SAVE_DIR = \"data/only_Q_outputs/combined/SIMPLE_REGRESSION_CUSTOM_PREDICTORS_plots\"\n",
    "# ×§×•×‘×¥ ×œ×©××™×¨×ª ×˜×‘×œ×ª ×”×¡×™×›×•×\n",
    "SUMMARY_TABLE_SAVE_PATH = \"data/only_Q_outputs/combined/T1_REGRESSION_CUSTOM_PREDICTORS_summary_table.csv\"\n",
    "\n",
    "# ğŸ’¡ğŸ’¡ğŸ’¡\n",
    "# --- ×”×’×“×¨ ×›××Ÿ ××ª ×”×¤×¨××˜×¨×™× ---\n",
    "# ğŸ’¡ğŸ’¡ğŸ’¡\n",
    "print(pd.read_csv(DATA_PATH).columns.tolist())\n",
    "# 1. ×¨×©×™××ª ×”××©×ª× ×™× *×”×§×‘×•×¢×™×* ×©××ª×” ×¨×•×¦×” ×œ× ×‘× (Y)\n",
    "Y_VARIABLES_TO_PREDICT = [\n",
    "    'b_des_average',\n",
    "    'after_des_total',\n",
    "    \"b_ders_total\",\n",
    "    \"after_ders_total\",\n",
    "    \"diff_ders\",\n",
    "    \"diff_des\"\n",
    "]\n",
    "\n",
    "# 2. ×¨×©×™××ª ×”××©×ª× ×™× ×”×× ×‘××™× (X) ×©××ª×” ×¨×•×¦×” ×œ×”×©×ª××© ×‘×”×\n",
    "X_PREDICTORS = [\n",
    "    'dmn_gm',\n",
    "    'fpn_gm',\n",
    "    'lim_gm',\n",
    "    'smn_gm',\n",
    "    'van_gm',\n",
    "    'vis_gm'\n",
    "]\n",
    "\n",
    "# 3. ×”×’×“×¨×•×ª ×œ××™××•×ª ×¦×•×œ×‘\n",
    "N_SPLITS = 5\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "df_for_regression = None\n",
    "\n",
    "try:\n",
    "    # ===================================================================\n",
    "    #           ×—×œ×§ 1: ×”×›× ×ª ×”× ×ª×•× ×™× (×˜×¢×™× ×” ×•× ×™×§×•×™)\n",
    "    # ===================================================================\n",
    "\n",
    "    print(f\"Loading merged data (X and Y variables) from {DATA_PATH}...\")\n",
    "\n",
    "    # ×˜×•×¢× ×™× ××ª ×›×œ ×”×¢××•×“×•×ª ×”×“×¨×•×©×•×ª: Subject_Code, ×›×œ ×”×× ×‘××™× (X) ×•×›×œ ×”×× ×•×‘××™× (Y)\n",
    "    columns_to_load = ['Subject_Code'] + Y_VARIABLES_TO_PREDICT + X_PREDICTORS\n",
    "\n",
    "    # ×˜×¢×™× ×ª ×”× ×ª×•× ×™×. ×× ×”×§×•×‘×¥ ××›×™×œ ×¨×§ ××ª ×”×¢××•×“×•×ª ×”×œ×œ×•, ××¤×©×¨ ×œ×”×©×ª××© ×‘-usecols ×›×“×™ ×œ×”×™×•×ª ×™×¢×™×œ×™×.\n",
    "    df_for_regression = pd.read_csv(DATA_PATH, usecols=lambda c: c in columns_to_load)\n",
    "\n",
    "    # ×”××¨×” ×œ-float64 ×œ×›×œ ×”×¢××•×“×•×ª ×”×¨×œ×•×•× ×˜×™×•×ª\n",
    "    all_var_cols = Y_VARIABLES_TO_PREDICT + X_PREDICTORS\n",
    "    for col in all_var_cols:\n",
    "        if col in df_for_regression.columns:\n",
    "            # ×”××¨×” ×™×–×•××” ×œ-float64 ×ª×•×š ×”×ª×¢×œ××•×ª ××˜×¢×•×™×•×ª ×× ×™×© ×¢×¨×›×™× ×©××™× × ××¡×¤×¨×™×™×\n",
    "            df_for_regression[col] = pd.to_numeric(df_for_regression[col], errors='coerce').astype(np.float64)\n",
    "\n",
    "    print(\"--- Data successfully loaded (ready for regression) ---\")\n",
    "    print(df_for_regression.head())\n",
    "\n",
    "    # ×™×¦×™×¨×ª ×ª×™×§×™×™×ª ×”×¤×œ×˜ ×œ×’×¨×¤×™×\n",
    "    os.makedirs(PLOTS_SAVE_DIR, exist_ok=True)\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"×©×’×™××”: ×§×•×‘×¥ ×”× ×ª×•× ×™× ×œ× × ××¦×. ×•×“× × ×ª×™×‘: {DATA_PATH}\")\n",
    "    df_for_regression = None\n",
    "except Exception as e:\n",
    "    print(f\"××™×¨×¢×” ×©×’×™××”: {e}\")\n",
    "    df_for_regression = None\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# ×”×¢×¨×”: ××›××Ÿ ×•×”×œ××”, ×”×§×•×“ × ×©××¨ ×–×”×” ×œ×§×•×“ ×”×§×•×“×, ×›×™×•×•×Ÿ ×©×”×•× ×›×‘×¨ ××‘×¦×¢\n",
    "# ××ª × ×™×ª×•×— ×”×¨×’×¨×¡×™×” ×”×¤×©×•×˜×” ×‘××•×¤×Ÿ × ×›×•×Ÿ ×¢×œ ×”-DataFrame ×”×˜×¢×•×Ÿ.\n",
    "# -------------------------------------------------------------------\n",
    "\n",
    "# ===================================================================\n",
    "#           ×—×œ×§ 2: ×”×¨×¦×ª ×”× ×™×ª×•×— ×‘×œ×•×œ××” (×¨×’×¨×¡×™×” ×¤×©×•×˜×” ×•-CV)\n",
    "# ===================================================================\n",
    "\n",
    "all_results_list = []\n",
    "\n",
    "if df_for_regression is not None:\n",
    "\n",
    "    # --- ×”×ª×—×œ×ª ×”×œ×•×œ××•×ª ---\n",
    "    for y_col in Y_VARIABLES_TO_PREDICT:\n",
    "        print(f\"\\n=======================================================\")\n",
    "        print(f\"  Processing Y-Variable: {y_col}\")\n",
    "        print(f\"=======================================================\")\n",
    "\n",
    "        # *** ×”×œ×•×œ××” ×¨×¦×” ×¢×œ ×›×œ ××©×ª× ×” ×× ×‘× (X) ××•×ª×× ××™×©×™×ª ***\n",
    "        for predictor_col_name in X_PREDICTORS:\n",
    "\n",
    "            if predictor_col_name not in df_for_regression.columns:\n",
    "                print(f\"--- Skipping: Predictor column '{predictor_col_name}' not found in data.\")\n",
    "                continue\n",
    "\n",
    "            print(f\"\\n--- Running Simple Regression: '{y_col}' ~ '{predictor_col_name}' ---\")\n",
    "\n",
    "            # 4. ×”×›× ×ª X ×•-Y, ×•× ×™×§×•×™ ×¢×¨×›×™× ×—×¡×¨×™× (NaN)\n",
    "            data_clean = df_for_regression[[predictor_col_name, y_col]].dropna()\n",
    "\n",
    "            if len(data_clean) < N_SPLITS * 2:\n",
    "                print(f\"  Skipping: Not enough data (N={len(data_clean)}). Need at least {N_SPLITS*2} for CV.\")\n",
    "                continue\n",
    "\n",
    "            # X ×—×™×™×‘ ×œ×”×™×•×ª ××˜×¨×™×¦×” ×“×•-×××“×™×ª ×¢×‘×•×¨ sklearn\n",
    "            X = data_clean[[predictor_col_name]]\n",
    "            y = data_clean[y_col]\n",
    "\n",
    "            # --- ğŸ’¡ ×—×™×©×•×‘ P-value ×•×¡×˜×˜×™×¡×˜×™×§×•×ª ×¨×’×¨×¡×™×” ×§×œ××¡×™×•×ª\n",
    "            try:\n",
    "                # ××©×ª××©×™× ×‘×¢××•×“×” ×”-1D ×©×œ X ×¢×‘×•×¨ linregress\n",
    "                slope, intercept, r_value, p_value, std_err = stats.linregress(X[predictor_col_name], y)\n",
    "                t_stat = slope / std_err\n",
    "            except ValueError:\n",
    "                t_stat, p_value, slope, intercept = np.nan, np.nan, np.nan, np.nan\n",
    "            # -------------------------------------------------------------\n",
    "\n",
    "            # 5. ×©×œ×‘ ×': ×”×¢×¨×›×ª ×”××•×“×œ (××™××•×ª ×¦×•×œ×‘ - Cross-Validation)\n",
    "            model_cv = LinearRegression()\n",
    "            kfold = KFold(n_splits=N_SPLITS, shuffle=True, random_state=RANDOM_STATE)\n",
    "            scoring = {'r_squared': 'r2', 'neg_mse': 'neg_mean_squared_error'}\n",
    "\n",
    "            cv_scores = cross_validate(model_cv, X, y, cv=kfold, scoring=scoring)\n",
    "\n",
    "            mean_r2 = np.mean(cv_scores['test_r_squared'])\n",
    "            std_r2 = np.std(cv_scores['test_r_squared'])\n",
    "            mean_rmse = np.sqrt(-np.mean(cv_scores['test_neg_mse']))\n",
    "            print(f\"  RÂ² (CV): {mean_r2:.3f} | RMSE (CV): {mean_rmse:.3f} | N = {len(y)}\")\n",
    "\n",
    "            # 6. ×©×œ×‘ ×‘': ××§×“××™× ×¡×•×¤×™×™× (××ª×•×š stats.linregress)\n",
    "            alpha = intercept\n",
    "            beta = slope\n",
    "            print(f\"  Intercept (Alpha): {alpha:.4f} | Slope (Beta): {beta:.4f}\")\n",
    "            print(f\"  P-value (Beta): {p_value:.4f}\")\n",
    "\n",
    "            # ===============================================================\n",
    "            #               ğŸ’¡ğŸ’¡ğŸ’¡ ×ª× ××™: ×”×¦×’×” ×¨×§ ×× RÂ² ×—×™×•×‘×™ ğŸ’¡ğŸ’¡ğŸ’¡\n",
    "            # ===============================================================\n",
    "            if mean_r2 > 0:\n",
    "                print(f\"  âœ… RÂ² is positive ({mean_r2:.3f}). Plotting graph.\")\n",
    "\n",
    "                # 7. ×©×œ×‘ ×’': ×©×¨×˜×•×˜ ×”×’×¨×£ (×’×¨×£ ×¤×™×–×•×¨)\n",
    "                plt.figure(figsize=(8, 6))\n",
    "\n",
    "                # ×’×¨×£ ×¤×™×–×•×¨ ×©×œ ×”× ×ª×•× ×™×\n",
    "                sns.scatterplot(x=predictor_col_name, y=y_col, data=data_clean, color='darkblue', alpha=0.7)\n",
    "\n",
    "                # ×”×•×¡×¤×ª ×§×• ×”×¨×’×¨×¡×™×”\n",
    "                sns.regplot(x=predictor_col_name, y=y_col, data=data_clean, scatter=False, color='red', line_kws={'lw': 2, 'linestyle': '-'})\n",
    "\n",
    "                plt.title(f'Prediction: {y_col} by {predictor_col_name}')\n",
    "                plt.xlabel(f'{predictor_col_name}')\n",
    "                plt.ylabel(f'{y_col}')\n",
    "\n",
    "                plt.text(0.05, 0.95,\n",
    "                         f'$R^2$ (CV) = {mean_r2:.3f}\\nSlope (Beta) = {beta:.3f}\\n$P$ (Beta) = {p_value:.4f}',\n",
    "                         transform=plt.gca().transAxes,\n",
    "                         verticalalignment='top',\n",
    "                         bbox=dict(boxstyle='round,pad=0.5', fc='white', alpha=0.7))\n",
    "\n",
    "                plt.tight_layout()\n",
    "\n",
    "                # ×©××™×¨×ª ×”×’×¨×£ ×¢× ×©× ×™×™×—×•×“×™\n",
    "                plot_save_path = os.path.join(PLOTS_SAVE_DIR, f\"simple_reg_{y_col}_vs_{predictor_col_name}.png\")\n",
    "                plt.savefig(plot_save_path, dpi=100)\n",
    "                plt.close()\n",
    "                print(f\"  Plot saved to {plot_save_path}\")\n",
    "            else:\n",
    "                print(f\"  âŒ RÂ² is not positive ({mean_r2:.3f}). Skipping graph plotting.\")\n",
    "            # ===============================================================\n",
    "\n",
    "            # 8. ×©××™×¨×ª ×”×ª×•×¦××•×ª ×œ×¨×©×™××”\n",
    "            all_results_list.append({\n",
    "                'Y_Variable': y_col,\n",
    "                'X_Variable': predictor_col_name,\n",
    "                'R_Squared_CV': mean_r2,\n",
    "                'R_Squared_Std': std_r2,\n",
    "                'RMSE_CV': mean_rmse,\n",
    "                'Alpha_Intercept': alpha,\n",
    "                'Beta_Slope': beta,\n",
    "                'T_Stat': t_stat,\n",
    "                'P_Value': p_value,\n",
    "                'N': len(y),\n",
    "                'Plotted': mean_r2 > 0\n",
    "            })\n",
    "\n",
    "    print(\"\\n\\n--- ×›×œ ×”× ×™×ª×•×—×™× ×”×¡×ª×™×™××• ---\")\n",
    "\n",
    "    # ===================================================================\n",
    "    #           ×—×œ×§ 3: ×™×¦×™×¨×ª ×˜×‘×œ×ª ×¡×™×›×•×\n",
    "    # ===================================================================\n",
    "\n",
    "    if all_results_list:\n",
    "        summary_df = pd.DataFrame(all_results_list)\n",
    "        # × ××™×™×Ÿ ×œ×¤×™ R^2 ×™×•×¨×“\n",
    "        summary_df = summary_df.sort_values(by=['Y_Variable', 'R_Squared_CV'], ascending=[True, False])\n",
    "\n",
    "        print(\"\\n--- ×˜×‘×œ×ª ×¡×™×›×•× ×¡×•×¤×™×ª (×¨×’×¨×¡×™×” ×¤×©×•×˜×” ×× ×‘××™× ××•×ª×××™× ××™×©×™×ª) ---\")\n",
    "\n",
    "        summary_df.to_csv(SUMMARY_TABLE_SAVE_PATH, index=False, encoding='utf-8-sig')\n",
    "        print(f\"\\nâœ… ×˜×‘×œ×ª ×”×¡×™×›×•× × ×©××¨×” ×‘: {SUMMARY_TABLE_SAVE_PATH}\")\n",
    "    else:\n",
    "        print(\"\\n--- ×œ× × ×•×¦×¨×• ×ª×•×¦××•×ª ---\")\n",
    "\n",
    "else:\n",
    "    print(\"×”× ×™×ª×•×— ×œ× ×¨×¥ ×›×™ ×”× ×ª×•× ×™× ×œ× × ×˜×¢× ×• ×›×¨××•×™.\")"
   ],
   "id": "79daf6df63c862ee",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['subject_code', 'b_ders_total', 'b_des_average', 'after_des_total', 'after_ders_total', 'after_ders_nonacceptance_emotional_responses', 'after_ders_goal_directed_behavior', 'after_ders_impulse_control', 'after_ders_lack_emotional_awareness', 'after_ders_emotion_regulation_strategies', 'after_ders_lack_emotional_clarity', 'diff_des', 'diff_ders', 'dmn_gm', 'fpn_gm', 'lim_gm', 'smn_gm', 'van_gm', 'vis_gm']\n",
      "Loading merged data (X and Y variables) from data/merged_no_nan.csv...\n",
      "--- Data successfully loaded (ready for regression) ---\n",
      "   b_ders_total  b_des_average  after_des_total  after_ders_total   diff_des  \\\n",
      "0          68.0       2.142857         0.000000              91.0  -2.142857   \n",
      "1          67.0       4.642857         7.500000              69.0   2.857143   \n",
      "2          95.0       7.142857         5.000000              87.0  -2.142857   \n",
      "3          70.0      23.928571        10.357143              72.0 -13.571429   \n",
      "4          69.0       2.500000         1.785714              47.0  -0.714286   \n",
      "\n",
      "   diff_ders    dmn_gm   fpn_gm   lim_gm   smn_gm   van_gm   vis_gm  \n",
      "0       23.0  159872.0  47224.0  66238.0  88987.0  50939.0  72078.0  \n",
      "1        2.0  172948.0  54126.0  67313.0  90927.0  65302.0  73557.0  \n",
      "2       -8.0  127745.0  35090.0  55938.0  74339.0  52224.0  65011.0  \n",
      "3        2.0  142435.0  42930.0  59068.0  79272.0  56471.0  67061.0  \n",
      "4      -22.0  143723.0  38971.0  53522.0  82554.0  56459.0  73596.0  \n",
      "\n",
      "=======================================================\n",
      "  Processing Y-Variable: b_des_average\n",
      "=======================================================\n",
      "\n",
      "--- Running Simple Regression: 'b_des_average' ~ 'dmn_gm' ---\n",
      "  RÂ² (CV): -0.042 | RMSE (CV): 4.979 | N = 94\n",
      "  Intercept (Alpha): 5.7032 | Slope (Beta): 0.0000\n",
      "  P-value (Beta): 0.9654\n",
      "  âŒ RÂ² is not positive (-0.042). Skipping graph plotting.\n",
      "\n",
      "--- Running Simple Regression: 'b_des_average' ~ 'fpn_gm' ---\n",
      "  RÂ² (CV): -0.034 | RMSE (CV): 4.966 | N = 94\n",
      "  Intercept (Alpha): 3.7241 | Slope (Beta): 0.0001\n",
      "  P-value (Beta): 0.6735\n",
      "  âŒ RÂ² is not positive (-0.034). Skipping graph plotting.\n",
      "\n",
      "--- Running Simple Regression: 'b_des_average' ~ 'lim_gm' ---\n",
      "  RÂ² (CV): -0.027 | RMSE (CV): 4.955 | N = 94\n",
      "  Intercept (Alpha): 9.2591 | Slope (Beta): -0.0001\n",
      "  P-value (Beta): 0.6171\n",
      "  âŒ RÂ² is not positive (-0.027). Skipping graph plotting.\n",
      "\n",
      "--- Running Simple Regression: 'b_des_average' ~ 'smn_gm' ---\n",
      "  RÂ² (CV): -0.055 | RMSE (CV): 4.998 | N = 94\n",
      "  Intercept (Alpha): 5.8815 | Slope (Beta): 0.0000\n",
      "  P-value (Beta): 0.9861\n",
      "  âŒ RÂ² is not positive (-0.055). Skipping graph plotting.\n",
      "\n",
      "--- Running Simple Regression: 'b_des_average' ~ 'van_gm' ---\n",
      "  RÂ² (CV): -0.023 | RMSE (CV): 4.946 | N = 94\n",
      "  Intercept (Alpha): 3.0793 | Slope (Beta): 0.0001\n",
      "  P-value (Beta): 0.6071\n",
      "  âŒ RÂ² is not positive (-0.023). Skipping graph plotting.\n",
      "\n",
      "--- Running Simple Regression: 'b_des_average' ~ 'vis_gm' ---\n",
      "  RÂ² (CV): -0.045 | RMSE (CV): 4.988 | N = 94\n",
      "  Intercept (Alpha): 4.1340 | Slope (Beta): 0.0000\n",
      "  P-value (Beta): 0.7687\n",
      "  âŒ RÂ² is not positive (-0.045). Skipping graph plotting.\n",
      "\n",
      "=======================================================\n",
      "  Processing Y-Variable: after_des_total\n",
      "=======================================================\n",
      "\n",
      "--- Running Simple Regression: 'after_des_total' ~ 'dmn_gm' ---\n",
      "  RÂ² (CV): -0.157 | RMSE (CV): 5.182 | N = 94\n",
      "  Intercept (Alpha): 1.6499 | Slope (Beta): 0.0000\n",
      "  P-value (Beta): 0.6441\n",
      "  âŒ RÂ² is not positive (-0.157). Skipping graph plotting.\n",
      "\n",
      "--- Running Simple Regression: 'after_des_total' ~ 'fpn_gm' ---\n",
      "  RÂ² (CV): -0.117 | RMSE (CV): 5.142 | N = 94\n",
      "  Intercept (Alpha): -1.0778 | Slope (Beta): 0.0001\n",
      "  P-value (Beta): 0.2903\n",
      "  âŒ RÂ² is not positive (-0.117). Skipping graph plotting.\n",
      "\n",
      "--- Running Simple Regression: 'after_des_total' ~ 'lim_gm' ---\n",
      "  RÂ² (CV): -0.142 | RMSE (CV): 5.167 | N = 94\n",
      "  Intercept (Alpha): 1.2936 | Slope (Beta): 0.0001\n",
      "  P-value (Beta): 0.6101\n",
      "  âŒ RÂ² is not positive (-0.142). Skipping graph plotting.\n",
      "\n",
      "--- Running Simple Regression: 'after_des_total' ~ 'smn_gm' ---\n",
      "  RÂ² (CV): -0.164 | RMSE (CV): 5.210 | N = 94\n",
      "  Intercept (Alpha): 2.7176 | Slope (Beta): 0.0000\n",
      "  P-value (Beta): 0.7399\n",
      "  âŒ RÂ² is not positive (-0.164). Skipping graph plotting.\n",
      "\n",
      "--- Running Simple Regression: 'after_des_total' ~ 'van_gm' ---\n",
      "  RÂ² (CV): -0.146 | RMSE (CV): 5.188 | N = 94\n",
      "  Intercept (Alpha): -1.7726 | Slope (Beta): 0.0001\n",
      "  P-value (Beta): 0.2606\n",
      "  âŒ RÂ² is not positive (-0.146). Skipping graph plotting.\n",
      "\n",
      "--- Running Simple Regression: 'after_des_total' ~ 'vis_gm' ---\n",
      "  RÂ² (CV): -0.142 | RMSE (CV): 5.176 | N = 94\n",
      "  Intercept (Alpha): 1.0906 | Slope (Beta): 0.0001\n",
      "  P-value (Beta): 0.5735\n",
      "  âŒ RÂ² is not positive (-0.142). Skipping graph plotting.\n",
      "\n",
      "=======================================================\n",
      "  Processing Y-Variable: b_ders_total\n",
      "=======================================================\n",
      "\n",
      "--- Running Simple Regression: 'b_ders_total' ~ 'dmn_gm' ---\n",
      "  RÂ² (CV): -0.082 | RMSE (CV): 17.525 | N = 94\n",
      "  Intercept (Alpha): 76.5354 | Slope (Beta): -0.0000\n",
      "  P-value (Beta): 0.8560\n",
      "  âŒ RÂ² is not positive (-0.082). Skipping graph plotting.\n",
      "\n",
      "--- Running Simple Regression: 'b_ders_total' ~ 'fpn_gm' ---\n",
      "  RÂ² (CV): -0.098 | RMSE (CV): 17.666 | N = 94\n",
      "  Intercept (Alpha): 70.3648 | Slope (Beta): 0.0000\n",
      "  P-value (Beta): 0.9125\n",
      "  âŒ RÂ² is not positive (-0.098). Skipping graph plotting.\n",
      "\n",
      "--- Running Simple Regression: 'b_ders_total' ~ 'lim_gm' ---\n",
      "  RÂ² (CV): -0.088 | RMSE (CV): 17.584 | N = 94\n",
      "  Intercept (Alpha): 71.3295 | Slope (Beta): 0.0000\n",
      "  P-value (Beta): 0.9618\n",
      "  âŒ RÂ² is not positive (-0.088). Skipping graph plotting.\n",
      "\n",
      "--- Running Simple Regression: 'b_ders_total' ~ 'smn_gm' ---\n",
      "  RÂ² (CV): -0.074 | RMSE (CV): 17.457 | N = 94\n",
      "  Intercept (Alpha): 89.6641 | Slope (Beta): -0.0002\n",
      "  P-value (Beta): 0.3997\n",
      "  âŒ RÂ² is not positive (-0.074). Skipping graph plotting.\n",
      "\n",
      "--- Running Simple Regression: 'b_ders_total' ~ 'van_gm' ---\n",
      "  RÂ² (CV): -0.074 | RMSE (CV): 17.484 | N = 94\n",
      "  Intercept (Alpha): 62.6633 | Slope (Beta): 0.0002\n",
      "  P-value (Beta): 0.6208\n",
      "  âŒ RÂ² is not positive (-0.074). Skipping graph plotting.\n",
      "\n",
      "--- Running Simple Regression: 'b_ders_total' ~ 'vis_gm' ---\n",
      "  RÂ² (CV): -0.099 | RMSE (CV): 17.634 | N = 94\n",
      "  Intercept (Alpha): 62.2615 | Slope (Beta): 0.0001\n",
      "  P-value (Beta): 0.6436\n",
      "  âŒ RÂ² is not positive (-0.099). Skipping graph plotting.\n",
      "\n",
      "=======================================================\n",
      "  Processing Y-Variable: after_ders_total\n",
      "=======================================================\n",
      "\n",
      "--- Running Simple Regression: 'after_ders_total' ~ 'dmn_gm' ---\n",
      "  RÂ² (CV): -0.048 | RMSE (CV): 18.980 | N = 94\n",
      "  Intercept (Alpha): 91.4732 | Slope (Beta): -0.0001\n",
      "  P-value (Beta): 0.3821\n",
      "  âŒ RÂ² is not positive (-0.048). Skipping graph plotting.\n",
      "\n",
      "--- Running Simple Regression: 'after_ders_total' ~ 'fpn_gm' ---\n",
      "  RÂ² (CV): -0.055 | RMSE (CV): 19.072 | N = 94\n",
      "  Intercept (Alpha): 70.5492 | Slope (Beta): -0.0000\n",
      "  P-value (Beta): 0.9761\n",
      "  âŒ RÂ² is not positive (-0.055). Skipping graph plotting.\n",
      "\n",
      "--- Running Simple Regression: 'after_ders_total' ~ 'lim_gm' ---\n",
      "  RÂ² (CV): -0.051 | RMSE (CV): 19.060 | N = 94\n",
      "  Intercept (Alpha): 68.7140 | Slope (Beta): 0.0000\n",
      "  P-value (Beta): 0.9610\n",
      "  âŒ RÂ² is not positive (-0.051). Skipping graph plotting.\n",
      "\n",
      "--- Running Simple Regression: 'after_ders_total' ~ 'smn_gm' ---\n",
      "  RÂ² (CV): -0.046 | RMSE (CV): 18.923 | N = 94\n",
      "  Intercept (Alpha): 94.4255 | Slope (Beta): -0.0003\n",
      "  P-value (Beta): 0.2719\n",
      "  âŒ RÂ² is not positive (-0.046). Skipping graph plotting.\n",
      "\n",
      "--- Running Simple Regression: 'after_ders_total' ~ 'van_gm' ---\n",
      "  RÂ² (CV): -0.075 | RMSE (CV): 19.114 | N = 94\n",
      "  Intercept (Alpha): 94.8560 | Slope (Beta): -0.0004\n",
      "  P-value (Beta): 0.2455\n",
      "  âŒ RÂ² is not positive (-0.075). Skipping graph plotting.\n",
      "\n",
      "--- Running Simple Regression: 'after_ders_total' ~ 'vis_gm' ---\n",
      "  RÂ² (CV): -0.063 | RMSE (CV): 19.165 | N = 94\n",
      "  Intercept (Alpha): 62.8593 | Slope (Beta): 0.0001\n",
      "  P-value (Beta): 0.7678\n",
      "  âŒ RÂ² is not positive (-0.063). Skipping graph plotting.\n",
      "\n",
      "=======================================================\n",
      "  Processing Y-Variable: diff_ders\n",
      "=======================================================\n",
      "\n",
      "--- Running Simple Regression: 'diff_ders' ~ 'dmn_gm' ---\n",
      "  RÂ² (CV): -0.033 | RMSE (CV): 15.559 | N = 94\n",
      "  Intercept (Alpha): 14.9378 | Slope (Beta): -0.0001\n",
      "  P-value (Beta): 0.3909\n",
      "  âŒ RÂ² is not positive (-0.033). Skipping graph plotting.\n",
      "\n",
      "--- Running Simple Regression: 'diff_ders' ~ 'fpn_gm' ---\n",
      "  RÂ² (CV): -0.060 | RMSE (CV): 15.718 | N = 94\n",
      "  Intercept (Alpha): 0.1844 | Slope (Beta): -0.0001\n",
      "  P-value (Beta): 0.8739\n",
      "  âŒ RÂ² is not positive (-0.060). Skipping graph plotting.\n",
      "\n",
      "--- Running Simple Regression: 'diff_ders' ~ 'lim_gm' ---\n",
      "  RÂ² (CV): -0.041 | RMSE (CV): 15.601 | N = 94\n",
      "  Intercept (Alpha): -2.6155 | Slope (Beta): 0.0000\n",
      "  P-value (Beta): 0.9951\n",
      "  âŒ RÂ² is not positive (-0.041). Skipping graph plotting.\n",
      "\n",
      "--- Running Simple Regression: 'diff_ders' ~ 'smn_gm' ---\n",
      "  RÂ² (CV): -0.049 | RMSE (CV): 15.647 | N = 94\n",
      "  Intercept (Alpha): 4.7614 | Slope (Beta): -0.0001\n",
      "  P-value (Beta): 0.6939\n",
      "  âŒ RÂ² is not positive (-0.049). Skipping graph plotting.\n",
      "\n",
      "--- Running Simple Regression: 'diff_ders' ~ 'van_gm' ---\n",
      "  RÂ² (CV): -0.064 | RMSE (CV): 15.630 | N = 94\n",
      "  Intercept (Alpha): 32.1927 | Slope (Beta): -0.0006\n",
      "  P-value (Beta): 0.0483\n",
      "  âŒ RÂ² is not positive (-0.064). Skipping graph plotting.\n",
      "\n",
      "--- Running Simple Regression: 'diff_ders' ~ 'vis_gm' ---\n",
      "  RÂ² (CV): -0.039 | RMSE (CV): 15.597 | N = 94\n",
      "  Intercept (Alpha): 0.5978 | Slope (Beta): -0.0000\n",
      "  P-value (Beta): 0.8758\n",
      "  âŒ RÂ² is not positive (-0.039). Skipping graph plotting.\n",
      "\n",
      "=======================================================\n",
      "  Processing Y-Variable: diff_des\n",
      "=======================================================\n",
      "\n",
      "--- Running Simple Regression: 'diff_des' ~ 'dmn_gm' ---\n",
      "  RÂ² (CV): -0.106 | RMSE (CV): 5.374 | N = 94\n",
      "  Intercept (Alpha): -4.0533 | Slope (Beta): 0.0000\n",
      "  P-value (Beta): 0.6868\n",
      "  âŒ RÂ² is not positive (-0.106). Skipping graph plotting.\n",
      "\n",
      "--- Running Simple Regression: 'diff_des' ~ 'fpn_gm' ---\n",
      "  RÂ² (CV): -0.077 | RMSE (CV): 5.301 | N = 94\n",
      "  Intercept (Alpha): -4.8019 | Slope (Beta): 0.0001\n",
      "  P-value (Beta): 0.5363\n",
      "  âŒ RÂ² is not positive (-0.077). Skipping graph plotting.\n",
      "\n",
      "--- Running Simple Regression: 'diff_des' ~ 'lim_gm' ---\n",
      "  RÂ² (CV): -0.125 | RMSE (CV): 5.342 | N = 94\n",
      "  Intercept (Alpha): -7.9654 | Slope (Beta): 0.0001\n",
      "  P-value (Beta): 0.3362\n",
      "  âŒ RÂ² is not positive (-0.125). Skipping graph plotting.\n",
      "\n",
      "--- Running Simple Regression: 'diff_des' ~ 'smn_gm' ---\n",
      "  RÂ² (CV): -0.112 | RMSE (CV): 5.389 | N = 94\n",
      "  Intercept (Alpha): -3.1639 | Slope (Beta): 0.0000\n",
      "  P-value (Beta): 0.7621\n",
      "  âŒ RÂ² is not positive (-0.112). Skipping graph plotting.\n",
      "\n",
      "--- Running Simple Regression: 'diff_des' ~ 'van_gm' ---\n",
      "  RÂ² (CV): -0.134 | RMSE (CV): 5.412 | N = 94\n",
      "  Intercept (Alpha): -4.8519 | Slope (Beta): 0.0001\n",
      "  P-value (Beta): 0.5515\n",
      "  âŒ RÂ² is not positive (-0.134). Skipping graph plotting.\n",
      "\n",
      "--- Running Simple Regression: 'diff_des' ~ 'vis_gm' ---\n",
      "  RÂ² (CV): -0.110 | RMSE (CV): 5.398 | N = 94\n",
      "  Intercept (Alpha): -3.0435 | Slope (Beta): 0.0000\n",
      "  P-value (Beta): 0.7914\n",
      "  âŒ RÂ² is not positive (-0.110). Skipping graph plotting.\n",
      "\n",
      "\n",
      "--- ×›×œ ×”× ×™×ª×•×—×™× ×”×¡×ª×™×™××• ---\n",
      "\n",
      "--- ×˜×‘×œ×ª ×¡×™×›×•× ×¡×•×¤×™×ª (×¨×’×¨×¡×™×” ×¤×©×•×˜×” ×× ×‘××™× ××•×ª×××™× ××™×©×™×ª) ---\n",
      "\n",
      "âœ… ×˜×‘×œ×ª ×”×¡×™×›×•× × ×©××¨×” ×‘: data/only_Q_outputs/combined/T1_REGRESSION_CUSTOM_PREDICTORS_summary_table.csv\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## pc2 prediction\n",
   "id": "656bad629a546568"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-18T08:15:02.203879Z",
     "start_time": "2025-11-18T08:15:02.180321Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# from sklearn.linear_model import LinearRegression\n",
    "# from sklearn.model_selection import KFold, cross_validate\n",
    "# from sklearn.metrics import mean_squared_error, r2_score\n",
    "# import os\n",
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "# from scipy import stats # ××©××© ×œ×—×™×©×•×‘ P-value\n",
    "#\n",
    "# # ===================================================================\n",
    "# #           ×—×œ×§ 1: ×”×’×“×¨×•×ª × ×ª×™×‘×™× ×•×¤×¨××˜×¨×™×\n",
    "# # ===================================================================\n",
    "#\n",
    "# # × ×ª×™×‘×™ ×”×§×‘×¦×™× - ×—×•×‘×” ×œ×¢×“×›×Ÿ ××ª × ×ª×™×‘ × ×ª×•× ×™ ×”-PC!\n",
    "# # ×§×•×‘×¥ ×–×” ×”×•× ×‘×¤×•×¨××˜ LONG: (Subject_Code | timepoint | PC1 | PC2 |...)\n",
    "# PC_DATA_LONG_PATH = \"data/only_Q_outputs/combined/combined_pca_components.csv\"\n",
    "# raw_data_path = \"data/only_Q_outputs/combined/regression_parameters.csv\"\n",
    "#\n",
    "# # ×ª×™×§×™×™×” ×œ×©××™×¨×ª ×›×œ ×”×’×¨×¤×™×\n",
    "# PLOTS_SAVE_DIR = \"data/only_Q_outputs/combined/regression_PC2_SIMPLE_plots_PIVOTED\"\n",
    "# # ×§×•×‘×¥ ×œ×©××™×¨×ª ×˜×‘×œ×ª ×”×¡×™×›×•×\n",
    "# SUMMARY_TABLE_SAVE_PATH = \"data/only_Q_outputs/combined/regression_PC2_SIMPLE_summary_table_PIVOTED.csv\"\n",
    "#\n",
    "# # ğŸ’¡ğŸ’¡ğŸ’¡\n",
    "# # --- ×”×’×“×¨ ×›××Ÿ ××ª ×”×¤×¨××˜×¨×™× ---\n",
    "# # ğŸ’¡ğŸ’¡ğŸ’¡\n",
    "#\n",
    "# # 1. ×¨×©×™××ª ×”××©×ª× ×™× *×”×§×‘×•×¢×™×* ×©××ª×” ×¨×•×¦×” ×œ× ×‘× (Y)\n",
    "# Y_VARIABLES_TO_PREDICT = [\n",
    "#     'b_DES_average',\n",
    "#     'after_DES_total',\n",
    "#     \"b_DERS_total\",\n",
    "#     \"after_DERS_total\",\n",
    "#     \"diff_DERS\",\n",
    "#     \"diff_DES\"\n",
    "# ]\n",
    "#\n",
    "# # 2. ×¨×©×™××ª × ×§×•×“×•×ª ×”×–××Ÿ ×•×”-PC's ×œ×©×™××•×©\n",
    "# PC_TIMEPOINTS = ['b', 't1', 't2', 't3', 'after']\n",
    "# PC_COMPONENT = 'PC2' # *** ××©×ª× ×” ×× ×‘× ×™×—×™×“: PC1 ***\n",
    "#\n",
    "# # 3. ×”×’×“×¨×•×ª ×œ××™××•×ª ×¦×•×œ×‘\n",
    "# N_SPLITS = 5\n",
    "# RANDOM_STATE = 42\n",
    "#\n",
    "# df_for_regression = None\n",
    "#\n",
    "# try:\n",
    "#     # ===================================================================\n",
    "#     #           ×—×œ×§ 1: ×”×›× ×ª ×”× ×ª×•× ×™× (×˜×¢×™× ×”, Pivot ×•××™×–×•×’)\n",
    "#     # ===================================================================\n",
    "#\n",
    "#     # --- 1×: ×˜×¢×™× ×ª × ×ª×•× ×™ ×”-PC ×‘-LONG FORMAT ---\n",
    "#     print(f\"Loading PC data in Long Format from {PC_DATA_LONG_PATH}...\")\n",
    "#     pc_df_long = pd.read_csv(PC_DATA_LONG_PATH)\n",
    "#\n",
    "#     # --- 1×‘: ×™×¦×™×¨×ª WIDE FORMAT (Pivot) ×¨×§ ×¢×‘×•×¨ PC1 ---\n",
    "#     print(f\"Pivoting to Wide Format using '{PC_COMPONENT}' values...\")\n",
    "#\n",
    "#     # ×•×“× ×©×›×œ ×”××™×“×¢ ×”×“×¨×•×© ×§×™×™× ×œ×¤× ×™ ×”×¤×™×•×•×˜\n",
    "#     if 'Subject_Code' not in pc_df_long.columns or 'timepoint' not in pc_df_long.columns or PC_COMPONENT not in pc_df_long.columns:\n",
    "#         raise ValueError(f\"Missing essential columns (Subject_Code, timepoint, or {PC_COMPONENT}) in the PC data.\")\n",
    "#\n",
    "#     pc_df_wide = pc_df_long.pivot(\n",
    "#         index='Subject_Code',\n",
    "#         columns='timepoint',\n",
    "#         values=PC_COMPONENT # ××©×ª××©×™× ×¨×§ ×‘-PC1\n",
    "#     ).reset_index()\n",
    "#\n",
    "#     # ×•×“× ×©×©××•×ª ×”×¢××•×“×•×ª ×œ××—×¨ ×”-Pivot ×”× ×›××• ×‘-PC_TIMEPOINTS (b, t1,...)\n",
    "#     # ××™×Ÿ ×¦×•×¨×š ×œ×©× ×•×ª ×©××•×ª ××›×™×•×•×Ÿ ×©-Pivot ×¢×•×©×” ×–××ª ××•×˜×•××˜×™×ª ×× ×™×© ×¨×§ ×¢××•×“×ª ×¢×¨×š ××—×ª\n",
    "#\n",
    "#     # ×”××¨×” ×œ-float64\n",
    "#     for tp in PC_TIMEPOINTS:\n",
    "#         if tp in pc_df_wide.columns:\n",
    "#             pc_df_wide[tp] = pc_df_wide[tp].astype(np.float64, errors='ignore')\n",
    "#\n",
    "#     # --- 1×’: ×”×›× ×ª × ×ª×•× ×™ ×”-Y ×•××™×–×•×’ ---\n",
    "#     print(\"Loading Y variables and merging...\")\n",
    "#     columns_to_load = ['Subject_Code'] + Y_VARIABLES_TO_PREDICT\n",
    "#     raw_df = pd.read_csv(raw_data_path, usecols=lambda c: c in columns_to_load)\n",
    "#\n",
    "#     # ×”××¨×” ×œ-float64\n",
    "#     for y_col in Y_VARIABLES_TO_PREDICT:\n",
    "#         if y_col in raw_df.columns:\n",
    "#             raw_df[y_col] = raw_df[y_col].astype(np.float64, errors='ignore')\n",
    "#\n",
    "#     df_for_regression = pd.merge(\n",
    "#         pc_df_wide,\n",
    "#         raw_df,\n",
    "#         on='Subject_Code',\n",
    "#         how='inner'\n",
    "#     )\n",
    "#\n",
    "#     print(\"--- Data successfully merged (Wide Format for PC1) ---\")\n",
    "#     print(df_for_regression.head())\n",
    "#\n",
    "#     # ×™×¦×™×¨×ª ×ª×™×§×™×™×ª ×”×¤×œ×˜ ×œ×’×¨×¤×™×\n",
    "#     os.makedirs(PLOTS_SAVE_DIR, exist_ok=True)\n",
    "#\n",
    "# except FileNotFoundError:\n",
    "#     print(f\"×©×’×™××”: ××—×“ ××§×•×‘×¦×™ ×”× ×ª×•× ×™× ×œ× × ××¦×. ×•×“× × ×ª×™×‘×™×.\")\n",
    "#     df_for_regression = None\n",
    "# except Exception as e:\n",
    "#     # ×”×¦×’×ª ×”×©×’×™××” ×©×”×ª×¨×—×©×” (×›×“×™ ×œ×“×¢×ª ××™×¤×” ×”×‘×¢×™×”)\n",
    "#     print(f\"××™×¨×¢×” ×©×’×™××”: {e}\")\n",
    "#     df_for_regression = None\n",
    "#\n",
    "# # ===================================================================\n",
    "# #           ×—×œ×§ 2: ×”×¨×¦×ª ×”× ×™×ª×•×— ×‘×œ×•×œ××” (×¨×’×¨×¡×™×” ×¤×©×•×˜×” ×•-CV)\n",
    "# # ===================================================================\n",
    "#\n",
    "# all_results_list = []\n",
    "#\n",
    "# if df_for_regression is not None:\n",
    "#\n",
    "#     # --- ×”×ª×—×œ×ª ×”×œ×•×œ××•×ª ---\n",
    "#     for y_col in Y_VARIABLES_TO_PREDICT:\n",
    "#         print(f\"\\n=======================================================\")\n",
    "#         print(f\"  Processing Y-Variable: {y_col}\")\n",
    "#         print(f\"=======================================================\")\n",
    "#\n",
    "#         # *** ×”×œ×•×œ××” ×¨×¦×” ×¢×œ ×›×œ × ×§×•×“×ª ×–××Ÿ ×›×¢××•×“×ª ×× ×‘× ***\n",
    "#         for predictor_col_name in PC_TIMEPOINTS:\n",
    "#\n",
    "#             if predictor_col_name not in df_for_regression.columns:\n",
    "#                 print(f\"--- Skipping: Timepoint column '{predictor_col_name}' not found after pivot.\")\n",
    "#                 continue\n",
    "#\n",
    "#             timepoint_name = predictor_col_name # ×©× ×”×¢××•×“×” (×œ×“×•×’××” 'b') ×”×•× ×©× × ×§×•×“×ª ×”×–××Ÿ\n",
    "#\n",
    "#             print(f\"\\n--- Running Simple Regression: '{y_col}' ~ '{predictor_col_name}' ({PC_COMPONENT} at {timepoint_name}) ---\")\n",
    "#\n",
    "#             # 4. ×”×›× ×ª X ×•-Y, ×•× ×™×§×•×™ ×¢×¨×›×™× ×—×¡×¨×™×\n",
    "#             data_clean = df_for_regression[[predictor_col_name, y_col]].dropna()\n",
    "#\n",
    "#             if len(data_clean) < N_SPLITS * 2:\n",
    "#                 print(f\"  Skipping: Not enough data (N={len(data_clean)})\")\n",
    "#                 continue\n",
    "#\n",
    "#             # X ×—×™×™×‘ ×œ×”×™×•×ª ××˜×¨×™×¦×” ×“×•-×××“×™×ª ×¢×‘×•×¨ sklearn\n",
    "#             X = data_clean[[predictor_col_name]]\n",
    "#             y = data_clean[y_col]\n",
    "#\n",
    "#             # --- ğŸ’¡ ×—×™×©×•×‘ P-value (P-value ×¢×‘×•×¨ ××§×“× ×‘×˜× ×©×œ ×”×¨×’×¨×¡×™×”)\n",
    "#             try:\n",
    "#                 slope, intercept, r_value, p_value, std_err = stats.linregress(X[predictor_col_name], y)\n",
    "#                 t_stat = slope / std_err\n",
    "#             except ValueError:\n",
    "#                 t_stat, p_value, slope, intercept = np.nan, np.nan, np.nan, np.nan\n",
    "#             # -------------------------------------------------------------\n",
    "#\n",
    "#             # 5. ×©×œ×‘ ×': ×”×¢×¨×›×ª ×”××•×“×œ (××™××•×ª ×¦×•×œ×‘)\n",
    "#             model_cv = LinearRegression()\n",
    "#             kfold = KFold(n_splits=N_SPLITS, shuffle=True, random_state=RANDOM_STATE)\n",
    "#             scoring = {'r_squared': 'r2', 'neg_mse': 'neg_mean_squared_error'}\n",
    "#\n",
    "#             cv_scores = cross_validate(model_cv, X, y, cv=kfold, scoring=scoring)\n",
    "#\n",
    "#             mean_r2 = np.mean(cv_scores['test_r_squared'])\n",
    "#             std_r2 = np.std(cv_scores['test_r_squared'])\n",
    "#             mean_rmse = np.sqrt(-np.mean(cv_scores['test_neg_mse']))\n",
    "#             print(f\"  RÂ² (CV): {mean_r2:.3f} | RMSE (CV): {mean_rmse:.3f} | N = {len(y)}\")\n",
    "#\n",
    "#             # 6. ×©×œ×‘ ×‘': ××§×“××™× ×¡×•×¤×™×™×\n",
    "#             alpha = intercept\n",
    "#             beta = slope\n",
    "#             print(f\"  Intercept (Alpha): {alpha:.4f} | Slope (Beta): {beta:.4f}\")\n",
    "#             print(f\"  P-value (Beta): {p_value:.4f}\")\n",
    "#\n",
    "#             # ===============================================================\n",
    "#             #               ğŸ’¡ğŸ’¡ğŸ’¡ ×ª× ××™: ×”×¦×’×” ×¨×§ ×× RÂ² ×—×™×•×‘×™ ğŸ’¡ğŸ’¡ğŸ’¡\n",
    "#             # ===============================================================\n",
    "#             if mean_r2 > 0:\n",
    "#                 print(f\"  âœ… RÂ² is positive ({mean_r2:.3f}). Plotting graph.\")\n",
    "#\n",
    "#                 # 7. ×©×œ×‘ ×’': ×©×¨×˜×•×˜ ×”×’×¨×£ (×’×¨×£ ×¤×™×–×•×¨)\n",
    "#                 plt.figure(figsize=(8, 6))\n",
    "#\n",
    "#                 # ×’×¨×£ ×¤×™×–×•×¨ ×©×œ ×”× ×ª×•× ×™×\n",
    "#                 sns.scatterplot(x=predictor_col_name, y=y_col, data=data_clean, color='darkblue', alpha=0.7)\n",
    "#\n",
    "#                 # ×”×•×¡×¤×ª ×§×• ×”×¨×’×¨×¡×™×”\n",
    "#                 sns.regplot(x=predictor_col_name, y=y_col, data=data_clean, scatter=False, color='red', line_kws={'lw': 2, 'linestyle': '-'})\n",
    "#\n",
    "#                 plt.title(f'Prediction: {y_col} by {PC_COMPONENT} at Timepoint {timepoint_name}')\n",
    "#                 plt.xlabel(f'{PC_COMPONENT} ({timepoint_name})')\n",
    "#                 plt.ylabel(f'{y_col}')\n",
    "#\n",
    "#                 plt.text(0.05, 0.95,\n",
    "#                          f'$R^2$ (CV) = {mean_r2:.3f}\\nSlope (Beta) = {beta:.3f}\\n$P$ (Beta) = {p_value:.4f}',\n",
    "#                          transform=plt.gca().transAxes,\n",
    "#                          verticalalignment='top',\n",
    "#                          bbox=dict(boxstyle='round,pad=0.5', fc='white', alpha=0.7))\n",
    "#\n",
    "#                 plt.tight_layout()\n",
    "#\n",
    "#                 # ×©××™×¨×ª ×”×’×¨×£ ×¢× ×©× ×™×™×—×•×“×™\n",
    "#                 plot_save_path = os.path.join(PLOTS_SAVE_DIR, f\"simple_reg_{y_col}_vs_{PC_COMPONENT}_{predictor_col_name}.png\")\n",
    "#                 plt.savefig(plot_save_path, dpi=100)\n",
    "#                 plt.close()\n",
    "#                 print(f\"  Plot saved to {plot_save_path}\")\n",
    "#             else:\n",
    "#                 print(f\"  âŒ RÂ² is not positive ({mean_r2:.3f}). Skipping graph plotting.\")\n",
    "#             # ===============================================================\n",
    "#\n",
    "#             # 8. ×©××™×¨×ª ×”×ª×•×¦××•×ª ×œ×¨×©×™××”\n",
    "#             all_results_list.append({\n",
    "#                 'Y_Variable': y_col,\n",
    "#                 'X_Variable (PC1_Timepoint)': predictor_col_name,\n",
    "#                 'PC_Component': PC_COMPONENT,\n",
    "#                 'Timepoint': timepoint_name,\n",
    "#                 'R_Squared_CV': mean_r2,\n",
    "#                 'R_Squared_Std': std_r2,\n",
    "#                 'RMSE_CV': mean_rmse,\n",
    "#                 'Alpha_Intercept': alpha,\n",
    "#                 'Beta_Slope': beta,\n",
    "#                 'T_Stat': t_stat,\n",
    "#                 'P_Value': p_value,\n",
    "#                 'N': len(y),\n",
    "#                 'Plotted': mean_r2 > 0\n",
    "#             })\n",
    "#\n",
    "#     print(\"\\n\\n--- ×›×œ ×”× ×™×ª×•×—×™× ×”×¡×ª×™×™××• ---\")\n",
    "#\n",
    "#     # ===================================================================\n",
    "#     #           ×—×œ×§ 3: ×™×¦×™×¨×ª ×˜×‘×œ×ª ×¡×™×›×•×\n",
    "#     # ===================================================================\n",
    "#\n",
    "#     if all_results_list:\n",
    "#         summary_df = pd.DataFrame(all_results_list)\n",
    "#         # × ××™×™×Ÿ ×œ×¤×™ R^2 ×™×•×¨×“\n",
    "#         summary_df = summary_df.sort_values(by=['Y_Variable', 'R_Squared_CV'], ascending=[True, False])\n",
    "#\n",
    "#         print(\"\\n--- ×˜×‘×œ×ª ×¡×™×›×•× ×¡×•×¤×™×ª (×¨×’×¨×¡×™×” ×¤×©×•×˜×” PC1) ---\")\n",
    "#\n",
    "#         summary_df.to_csv(SUMMARY_TABLE_SAVE_PATH, index=False, encoding='utf-8-sig')\n",
    "#         print(f\"\\nâœ… ×˜×‘×œ×ª ×”×¡×™×›×•× × ×©××¨×” ×‘: {SUMMARY_TABLE_SAVE_PATH}\")\n",
    "#     else:\n",
    "#         print(\"\\n--- ×œ× × ×•×¦×¨×• ×ª×•×¦××•×ª ---\")\n",
    "#\n",
    "# else:\n",
    "#     print(\"×”× ×™×ª×•×— ×œ× ×¨×¥ ×›×™ ×”× ×ª×•× ×™× ×œ× × ×˜×¢× ×• ×›×¨××•×™.\")"
   ],
   "id": "e005bc04020c4b73",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading PC data in Long Format from data/only_Q_outputs/combined/combined_pca_components.csv...\n",
      "×©×’×™××”: ××—×“ ××§×•×‘×¦×™ ×”× ×ª×•× ×™× ×œ× × ××¦×. ×•×“× × ×ª×™×‘×™×.\n",
      "×”× ×™×ª×•×— ×œ× ×¨×¥ ×›×™ ×”× ×ª×•× ×™× ×œ× × ×˜×¢× ×• ×›×¨××•×™.\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "9793d3ded31f17b3"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## only T1 lasso prediction clinical scores",
   "id": "8280df9a9259b269"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-18T08:15:03.877712Z",
     "start_time": "2025-11-18T08:15:02.282986Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# ×™×™×‘×•× ××•×“×œ Lasso ×‘××§×•× LinearRegression\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.model_selection import KFold, cross_validate\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "# ×”×¢×¨×”: × ×©××•×¨ ×¢×œ sns ×œ×¦×•×¨×š ×’×¨×£ ×”×¤×™×–×•×¨, ××š ×§×• ×”×¨×’×¨×¡×™×” ×©×œ sns.regplot ×™×ª×‘×¡×¡ ×¢×œ ××•×“×œ ×œ×™× ×™××¨×™ ×§×œ××¡×™ (×œ× ××¨×•×’×•×œ×¨)\n",
    "import seaborn as sns\n",
    "# × ×¡×™×¨ ××ª stats ×›×™ ×œ× × ×—×©×‘ P-value ×§×œ××¡×™\n",
    "# from scipy import stats\n",
    "\n",
    "# ===================================================================\n",
    "#           ×—×œ×§ 1: ×”×’×“×¨×•×ª × ×ª×™×‘×™× ×•×¤×¨××˜×¨×™×\n",
    "# ===================================================================\n",
    "\n",
    "# × ×ª×™×‘ ×”×§×•×‘×¥ - ×”×§×•×‘×¥ ××›×™×œ ××ª ×›×œ ×”× ×ª×•× ×™× ×”× ×“×¨×©×™× (X ×•-Y)\n",
    "DATA_PATH = \"data/merged_no_nan.csv\"\n",
    "\n",
    "# ×ª×™×§×™×™×” ×œ×©××™×¨×ª ×›×œ ×”×’×¨×¤×™×\n",
    "PLOTS_SAVE_DIR = \"data/only_Q_outputs/combined/LASSO_REGRESSION_CUSTOM_PREDICTORS_plots\" # ×©×•× ×”\n",
    "# ×§×•×‘×¥ ×œ×©××™×¨×ª ×˜×‘×œ×ª ×”×¡×™×›×•×\n",
    "SUMMARY_TABLE_SAVE_PATH = \"data/only_Q_outputs/combined/LASSO_REGRESSION_CUSTOM_PREDICTORS_summary_table.csv\" # ×©×•× ×”\n",
    "\n",
    "# ğŸ’¡ğŸ’¡ğŸ’¡\n",
    "# --- ×”×’×“×¨ ×›××Ÿ ××ª ×”×¤×¨××˜×¨×™× ---\n",
    "# ğŸ’¡ğŸ’¡ğŸ’¡\n",
    "\n",
    "# 1. ×¨×©×™××ª ×”××©×ª× ×™× *×”×§×‘×•×¢×™×* ×©××ª×” ×¨×•×¦×” ×œ× ×‘× (Y) - × ×©×ª××© ×‘×©××•×ª ×”××ª×•×§× ×™× (lowercase)\n",
    "Y_VARIABLES_TO_PREDICT = [\n",
    "    'b_des_average',\n",
    "    'after_des_total',\n",
    "    \"b_ders_total\",\n",
    "    \"after_ders_total\",\n",
    "    \"diff_ders\",\n",
    "    \"diff_des\"\n",
    "]\n",
    "\n",
    "# 2. ×¨×©×™××ª ×”××©×ª× ×™× ×”×× ×‘××™× (X) ×©××ª×” ×¨×•×¦×” ×œ×”×©×ª××© ×‘×”×\n",
    "X_PREDICTORS = [\n",
    "    'dmn_gm',\n",
    "    'fpn_gm',\n",
    "    'lim_gm',\n",
    "    'smn_gm',\n",
    "    'van_gm',\n",
    "    'vis_gm'\n",
    "]\n",
    "\n",
    "# 3. ×¤×¨××˜×¨ ×¨×’×•×œ×¨×™×–×¦×™×” ×©×œ ×œ××¡×• (Alpha)\n",
    "# ğŸ’¡ ××œ×¤× = 0 ××—×–×™×¨ ×¨×’×¨×¡×™×” ×œ×™× ×™××¨×™×ª ×¨×’×™×œ×”. ×¢×¨×š ×§×˜×Ÿ (×›××• 0.01) ××¤×¢×™×œ ×¨×’×•×œ×¨×™×–×¦×™×” ×¢×“×™× ×”.\n",
    "LASSO_ALPHA = 0.01\n",
    "\n",
    "# 4. ×”×’×“×¨×•×ª ×œ××™××•×ª ×¦×•×œ×‘\n",
    "N_SPLITS = 5\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "df_for_regression = None\n",
    "\n",
    "try:\n",
    "    # ===================================================================\n",
    "    #           ×—×œ×§ 1: ×”×›× ×ª ×”× ×ª×•× ×™× (×˜×¢×™× ×” ×•× ×™×§×•×™)\n",
    "    # ===================================================================\n",
    "\n",
    "    print(f\"Loading merged data (X and Y variables) from {DATA_PATH}...\")\n",
    "\n",
    "    # ×˜×•×¢× ×™× ××ª ×›×œ ×”×¢××•×“×•×ª ×”×“×¨×•×©×•×ª: subject_code (×ª×•×§×Ÿ ×œ-lowercase), X ×•-Y\n",
    "    columns_to_load = ['subject_code'] + Y_VARIABLES_TO_PREDICT + X_PREDICTORS\n",
    "\n",
    "    # ×˜×¢×™× ×ª ×”× ×ª×•× ×™×.\n",
    "    df_for_regression = pd.read_csv(DATA_PATH, usecols=lambda c: c in columns_to_load)\n",
    "\n",
    "    # ×”××¨×” ×œ-float64 ×œ×›×œ ×”×¢××•×“×•×ª ×”×¨×œ×•×•× ×˜×™×•×ª\n",
    "    all_var_cols = Y_VARIABLES_TO_PREDICT + X_PREDICTORS\n",
    "    for col in all_var_cols:\n",
    "        if col in df_for_regression.columns:\n",
    "            df_for_regression[col] = pd.to_numeric(df_for_regression[col], errors='coerce').astype(np.float64)\n",
    "\n",
    "    print(\"--- Data successfully loaded (ready for regression) ---\")\n",
    "    print(df_for_regression.head())\n",
    "\n",
    "    # ×™×¦×™×¨×ª ×ª×™×§×™×™×ª ×”×¤×œ×˜ ×œ×’×¨×¤×™×\n",
    "    os.makedirs(PLOTS_SAVE_DIR, exist_ok=True)\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"×©×’×™××”: ×§×•×‘×¥ ×”× ×ª×•× ×™× ×œ× × ××¦×. ×•×“× × ×ª×™×‘: {DATA_PATH}\")\n",
    "    df_for_regression = None\n",
    "except Exception as e:\n",
    "    print(f\"××™×¨×¢×” ×©×’×™××”: {e}\")\n",
    "    df_for_regression = None\n",
    "\n",
    "# ===================================================================\n",
    "#           ×—×œ×§ 2: ×”×¨×¦×ª ×”× ×™×ª×•×— ×‘×œ×•×œ××” (×¨×’×¨×¡×™×™×ª ×œ××¡×• ×•-CV)\n",
    "# ===================================================================\n",
    "\n",
    "all_results_list = []\n",
    "\n",
    "if df_for_regression is not None:\n",
    "\n",
    "    # --- ×”×ª×—×œ×ª ×”×œ×•×œ××•×ª ---\n",
    "    for y_col in Y_VARIABLES_TO_PREDICT:\n",
    "        print(f\"\\n=======================================================\")\n",
    "        print(f\"  Processing Y-Variable: {y_col}\")\n",
    "        print(f\"=======================================================\")\n",
    "\n",
    "        # *** ×”×œ×•×œ××” ×¨×¦×” ×¢×œ ×›×œ ××©×ª× ×” ×× ×‘× (X) ××•×ª×× ××™×©×™×ª ***\n",
    "        for predictor_col_name in X_PREDICTORS:\n",
    "\n",
    "            if predictor_col_name not in df_for_regression.columns:\n",
    "                print(f\"--- Skipping: Predictor column '{predictor_col_name}' not found in data.\")\n",
    "                continue\n",
    "\n",
    "            print(f\"\\n--- Running Simple LASSO Regression (Alpha={LASSO_ALPHA}): '{y_col}' ~ '{predictor_col_name}' ---\")\n",
    "\n",
    "            # 4. ×”×›× ×ª X ×•-Y, ×•× ×™×§×•×™ ×¢×¨×›×™× ×—×¡×¨×™× (NaN)\n",
    "            data_clean = df_for_regression[[predictor_col_name, y_col]].dropna()\n",
    "\n",
    "            if len(data_clean) < N_SPLITS * 2:\n",
    "                print(f\"  Skipping: Not enough data (N={len(data_clean)}). Need at least {N_SPLITS*2} for CV.\")\n",
    "                continue\n",
    "\n",
    "            # X ×—×™×™×‘ ×œ×”×™×•×ª ××˜×¨×™×¦×” ×“×•-×××“×™×ª ×¢×‘×•×¨ sklearn\n",
    "            X = data_clean[[predictor_col_name]]\n",
    "            y = data_clean[y_col]\n",
    "\n",
    "            # --- ğŸ’¡ ×©×œ×‘ 5×: ×”×¢×¨×›×ª ×”××•×“×œ (××™××•×ª ×¦×•×œ×‘) ×‘×××¦×¢×•×ª Lasso\n",
    "            # ×©×™××•×© ×‘-Lasso ×¢× ×”×¤×¨××˜×¨ Alpha\n",
    "            model_cv = Lasso(alpha=LASSO_ALPHA, random_state=RANDOM_STATE, max_iter=10000)\n",
    "            kfold = KFold(n_splits=N_SPLITS, shuffle=True, random_state=RANDOM_STATE)\n",
    "            scoring = {'r_squared': 'r2', 'neg_mse': 'neg_mean_squared_error'}\n",
    "\n",
    "            cv_scores = cross_validate(model_cv, X, y, cv=kfold, scoring=scoring)\n",
    "\n",
    "            mean_r2 = np.mean(cv_scores['test_r_squared'])\n",
    "            std_r2 = np.std(cv_scores['test_r_squared'])\n",
    "            mean_rmse = np.sqrt(-np.mean(cv_scores['test_neg_mse']))\n",
    "            print(f\"  RÂ² (CV): {mean_r2:.3f} | RMSE (CV): {mean_rmse:.3f} | N = {len(y)}\")\n",
    "\n",
    "            # -------------------------------------------------------------\n",
    "            # --- ×©×œ×‘ 5×‘: ××™××•×Ÿ ×”××•×“×œ ×¢×œ ×›×œ ×”× ×ª×•× ×™× ×›×“×™ ×œ×§×‘×œ ××§×“××™× ×¡×•×¤×™×™× ---\n",
    "            final_model = Lasso(alpha=LASSO_ALPHA, random_state=RANDOM_STATE, max_iter=10000)\n",
    "            final_model.fit(X, y)\n",
    "\n",
    "            # ××§×“××™×\n",
    "            alpha_intercept = final_model.intercept_\n",
    "            beta_slope = final_model.coef_[0]\n",
    "\n",
    "            # P-value: ×œ× ××—×•×©×‘ ×¢×‘×•×¨ ××•×“×œ×™× ××¨×•×’×•×œ×¨×™×. × ×©×ª××© ×‘-NaN.\n",
    "            t_stat, p_value = np.nan, np.nan\n",
    "\n",
    "            print(f\"  Intercept (Alpha): {alpha_intercept:.4f} | Slope (Beta, LASSO): {beta_slope:.4f}\")\n",
    "            print(f\"  Note: P-value is not calculated for Regularized models.\")\n",
    "            # -------------------------------------------------------------\n",
    "\n",
    "            # ===============================================================\n",
    "            #               ğŸ’¡ğŸ’¡ğŸ’¡ ×ª× ××™: ×”×¦×’×” ×¨×§ ×× RÂ² ×—×™×•×‘×™ ğŸ’¡ğŸ’¡ğŸ’¡\n",
    "            # ===============================================================\n",
    "            if mean_r2 > 0:\n",
    "                print(f\"  âœ… RÂ² is positive ({mean_r2:.3f}). Plotting graph.\")\n",
    "\n",
    "                # 7. ×©×œ×‘ ×’': ×©×¨×˜×•×˜ ×”×’×¨×£ (×’×¨×£ ×¤×™×–×•×¨)\n",
    "                plt.figure(figsize=(8, 6))\n",
    "\n",
    "                # ×’×¨×£ ×¤×™×–×•×¨ ×©×œ ×”× ×ª×•× ×™×\n",
    "                sns.scatterplot(x=predictor_col_name, y=y_col, data=data_clean, color='darkblue', alpha=0.7)\n",
    "\n",
    "                # ×”×•×¡×¤×ª ×§×• ×”×¨×’×¨×¡×™×” ×©×œ ×”-LASSO:\n",
    "                # × ×©×ª××© ×‘× ×•×¡×—×ª ×”×§×• (y = Beta*X + Alpha)\n",
    "                x_fit = np.linspace(X[predictor_col_name].min(), X[predictor_col_name].max(), 100).reshape(-1, 1)\n",
    "                y_fit = final_model.predict(x_fit)\n",
    "\n",
    "                plt.plot(x_fit, y_fit, color='red', linestyle='-', linewidth=2, label=f'LASSO Fit (Alpha={LASSO_ALPHA})')\n",
    "\n",
    "                plt.title(f'LASSO Prediction: {y_col} by {predictor_col_name}')\n",
    "                plt.xlabel(f'{predictor_col_name}')\n",
    "                plt.ylabel(f'{y_col}')\n",
    "\n",
    "                plt.text(0.05, 0.95,\n",
    "                         f'$R^2$ (CV) = {mean_r2:.3f}\\nSlope (Beta, LASSO) = {beta_slope:.3f}\\nAlpha (LASSO) = {LASSO_ALPHA}',\n",
    "                         transform=plt.gca().transAxes,\n",
    "                         verticalalignment='top',\n",
    "                         bbox=dict(boxstyle='round,pad=0.5', fc='white', alpha=0.7))\n",
    "\n",
    "                plt.tight_layout()\n",
    "\n",
    "                # ×©××™×¨×ª ×”×’×¨×£ ×¢× ×©× ×™×™×—×•×“×™\n",
    "                plot_save_path = os.path.join(PLOTS_SAVE_DIR, f\"lasso_reg_{y_col}_vs_{predictor_col_name}.png\")\n",
    "                plt.savefig(plot_save_path, dpi=100)\n",
    "                plt.close()\n",
    "                print(f\"  Plot saved to {plot_save_path}\")\n",
    "            else:\n",
    "                print(f\"  âŒ RÂ² is not positive ({mean_r2:.3f}). Skipping graph plotting.\")\n",
    "            # ===============================================================\n",
    "\n",
    "            # 8. ×©××™×¨×ª ×”×ª×•×¦××•×ª ×œ×¨×©×™××”\n",
    "            all_results_list.append({\n",
    "                'Y_Variable': y_col,\n",
    "                'X_Variable': predictor_col_name,\n",
    "                'Model': 'LASSO',\n",
    "                'Alpha_Lasso': LASSO_ALPHA,\n",
    "                'R_Squared_CV': mean_r2,\n",
    "                'R_Squared_Std': std_r2,\n",
    "                'RMSE_CV': mean_rmse,\n",
    "                'Alpha_Intercept': alpha_intercept,\n",
    "                'Beta_Slope': beta_slope,\n",
    "                'T_Stat': t_stat, # NaN\n",
    "                'P_Value': p_value, # NaN\n",
    "                'N': len(y),\n",
    "                'Plotted': mean_r2 > 0\n",
    "            })\n",
    "\n",
    "    print(\"\\n\\n--- ×›×œ ×”× ×™×ª×•×—×™× ×”×¡×ª×™×™××• ---\")\n",
    "\n",
    "    # ===================================================================\n",
    "    #           ×—×œ×§ 3: ×™×¦×™×¨×ª ×˜×‘×œ×ª ×¡×™×›×•×\n",
    "    # ===================================================================\n",
    "\n",
    "    if all_results_list:\n",
    "        summary_df = pd.DataFrame(all_results_list)\n",
    "        # × ××™×™×Ÿ ×œ×¤×™ R^2 ×™×•×¨×“\n",
    "        summary_df = summary_df.sort_values(by=['Y_Variable', 'R_Squared_CV'], ascending=[True, False])\n",
    "\n",
    "        print(\"\\n--- ×˜×‘×œ×ª ×¡×™×›×•× ×¡×•×¤×™×ª (×¨×’×¨×¡×™×™×ª ×œ××¡×• ×× ×‘××™× ××•×ª×××™× ××™×©×™×ª) ---\")\n",
    "\n",
    "        summary_df.to_csv(SUMMARY_TABLE_SAVE_PATH, index=False, encoding='utf-8-sig')\n",
    "        print(f\"\\nâœ… ×˜×‘×œ×ª ×”×¡×™×›×•× × ×©××¨×” ×‘: {SUMMARY_TABLE_SAVE_PATH}\")\n",
    "    else:\n",
    "        print(\"\\n--- ×œ× × ×•×¦×¨×• ×ª×•×¦××•×ª ---\")\n",
    "\n",
    "else:\n",
    "    print(\"×”× ×™×ª×•×— ×œ× ×¨×¥ ×›×™ ×”× ×ª×•× ×™× ×œ× × ×˜×¢× ×• ×›×¨××•×™.\")"
   ],
   "id": "52ba1a2b190c7ac3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading merged data (X and Y variables) from data/merged_no_nan.csv...\n",
      "--- Data successfully loaded (ready for regression) ---\n",
      "  subject_code  b_ders_total  b_des_average  after_des_total  \\\n",
      "0        CT003          68.0       2.142857         0.000000   \n",
      "1        CT004          67.0       4.642857         7.500000   \n",
      "2        CT005          95.0       7.142857         5.000000   \n",
      "3        CT007          70.0      23.928571        10.357143   \n",
      "4        CT008          69.0       2.500000         1.785714   \n",
      "\n",
      "   after_ders_total   diff_des  diff_ders    dmn_gm   fpn_gm   lim_gm  \\\n",
      "0              91.0  -2.142857       23.0  159872.0  47224.0  66238.0   \n",
      "1              69.0   2.857143        2.0  172948.0  54126.0  67313.0   \n",
      "2              87.0  -2.142857       -8.0  127745.0  35090.0  55938.0   \n",
      "3              72.0 -13.571429        2.0  142435.0  42930.0  59068.0   \n",
      "4              47.0  -0.714286      -22.0  143723.0  38971.0  53522.0   \n",
      "\n",
      "    smn_gm   van_gm   vis_gm  \n",
      "0  88987.0  50939.0  72078.0  \n",
      "1  90927.0  65302.0  73557.0  \n",
      "2  74339.0  52224.0  65011.0  \n",
      "3  79272.0  56471.0  67061.0  \n",
      "4  82554.0  56459.0  73596.0  \n",
      "\n",
      "=======================================================\n",
      "  Processing Y-Variable: b_des_average\n",
      "=======================================================\n",
      "\n",
      "--- Running Simple LASSO Regression (Alpha=0.01): 'b_des_average' ~ 'dmn_gm' ---\n",
      "  RÂ² (CV): -0.042 | RMSE (CV): 4.979 | N = 94\n",
      "  Intercept (Alpha): 5.7032 | Slope (Beta, LASSO): 0.0000\n",
      "  Note: P-value is not calculated for Regularized models.\n",
      "  âŒ RÂ² is not positive (-0.042). Skipping graph plotting.\n",
      "\n",
      "--- Running Simple LASSO Regression (Alpha=0.01): 'b_des_average' ~ 'fpn_gm' ---\n",
      "  RÂ² (CV): -0.034 | RMSE (CV): 4.966 | N = 94\n",
      "  Intercept (Alpha): 3.7241 | Slope (Beta, LASSO): 0.0001\n",
      "  Note: P-value is not calculated for Regularized models.\n",
      "  âŒ RÂ² is not positive (-0.034). Skipping graph plotting.\n",
      "\n",
      "--- Running Simple LASSO Regression (Alpha=0.01): 'b_des_average' ~ 'lim_gm' ---\n",
      "  RÂ² (CV): -0.027 | RMSE (CV): 4.955 | N = 94\n",
      "  Intercept (Alpha): 9.2590 | Slope (Beta, LASSO): -0.0001\n",
      "  Note: P-value is not calculated for Regularized models.\n",
      "  âŒ RÂ² is not positive (-0.027). Skipping graph plotting.\n",
      "\n",
      "--- Running Simple LASSO Regression (Alpha=0.01): 'b_des_average' ~ 'smn_gm' ---\n",
      "  RÂ² (CV): -0.055 | RMSE (CV): 4.998 | N = 94\n",
      "  Intercept (Alpha): 5.8815 | Slope (Beta, LASSO): 0.0000\n",
      "  Note: P-value is not calculated for Regularized models.\n",
      "  âŒ RÂ² is not positive (-0.055). Skipping graph plotting.\n",
      "\n",
      "--- Running Simple LASSO Regression (Alpha=0.01): 'b_des_average' ~ 'van_gm' ---\n",
      "  RÂ² (CV): -0.023 | RMSE (CV): 4.946 | N = 94\n",
      "  Intercept (Alpha): 3.0793 | Slope (Beta, LASSO): 0.0001\n",
      "  Note: P-value is not calculated for Regularized models.\n",
      "  âŒ RÂ² is not positive (-0.023). Skipping graph plotting.\n",
      "\n",
      "--- Running Simple LASSO Regression (Alpha=0.01): 'b_des_average' ~ 'vis_gm' ---\n",
      "  RÂ² (CV): -0.045 | RMSE (CV): 4.988 | N = 94\n",
      "  Intercept (Alpha): 4.1340 | Slope (Beta, LASSO): 0.0000\n",
      "  Note: P-value is not calculated for Regularized models.\n",
      "  âŒ RÂ² is not positive (-0.045). Skipping graph plotting.\n",
      "\n",
      "=======================================================\n",
      "  Processing Y-Variable: after_des_total\n",
      "=======================================================\n",
      "\n",
      "--- Running Simple LASSO Regression (Alpha=0.01): 'after_des_total' ~ 'dmn_gm' ---\n",
      "  RÂ² (CV): -0.157 | RMSE (CV): 5.182 | N = 94\n",
      "  Intercept (Alpha): 1.6499 | Slope (Beta, LASSO): 0.0000\n",
      "  Note: P-value is not calculated for Regularized models.\n",
      "  âŒ RÂ² is not positive (-0.157). Skipping graph plotting.\n",
      "\n",
      "--- Running Simple LASSO Regression (Alpha=0.01): 'after_des_total' ~ 'fpn_gm' ---\n",
      "  RÂ² (CV): -0.117 | RMSE (CV): 5.142 | N = 94\n",
      "  Intercept (Alpha): -1.0778 | Slope (Beta, LASSO): 0.0001\n",
      "  Note: P-value is not calculated for Regularized models.\n",
      "  âŒ RÂ² is not positive (-0.117). Skipping graph plotting.\n",
      "\n",
      "--- Running Simple LASSO Regression (Alpha=0.01): 'after_des_total' ~ 'lim_gm' ---\n",
      "  RÂ² (CV): -0.142 | RMSE (CV): 5.167 | N = 94\n",
      "  Intercept (Alpha): 1.2937 | Slope (Beta, LASSO): 0.0001\n",
      "  Note: P-value is not calculated for Regularized models.\n",
      "  âŒ RÂ² is not positive (-0.142). Skipping graph plotting.\n",
      "\n",
      "--- Running Simple LASSO Regression (Alpha=0.01): 'after_des_total' ~ 'smn_gm' ---\n",
      "  RÂ² (CV): -0.164 | RMSE (CV): 5.210 | N = 94\n",
      "  Intercept (Alpha): 2.7177 | Slope (Beta, LASSO): 0.0000\n",
      "  Note: P-value is not calculated for Regularized models.\n",
      "  âŒ RÂ² is not positive (-0.164). Skipping graph plotting.\n",
      "\n",
      "--- Running Simple LASSO Regression (Alpha=0.01): 'after_des_total' ~ 'van_gm' ---\n",
      "  RÂ² (CV): -0.146 | RMSE (CV): 5.188 | N = 94\n",
      "  Intercept (Alpha): -1.7726 | Slope (Beta, LASSO): 0.0001\n",
      "  Note: P-value is not calculated for Regularized models.\n",
      "  âŒ RÂ² is not positive (-0.146). Skipping graph plotting.\n",
      "\n",
      "--- Running Simple LASSO Regression (Alpha=0.01): 'after_des_total' ~ 'vis_gm' ---\n",
      "  RÂ² (CV): -0.142 | RMSE (CV): 5.176 | N = 94\n",
      "  Intercept (Alpha): 1.0906 | Slope (Beta, LASSO): 0.0001\n",
      "  Note: P-value is not calculated for Regularized models.\n",
      "  âŒ RÂ² is not positive (-0.142). Skipping graph plotting.\n",
      "\n",
      "=======================================================\n",
      "  Processing Y-Variable: b_ders_total\n",
      "=======================================================\n",
      "\n",
      "--- Running Simple LASSO Regression (Alpha=0.01): 'b_ders_total' ~ 'dmn_gm' ---\n",
      "  RÂ² (CV): -0.082 | RMSE (CV): 17.525 | N = 94\n",
      "  Intercept (Alpha): 76.5354 | Slope (Beta, LASSO): -0.0000\n",
      "  Note: P-value is not calculated for Regularized models.\n",
      "  âŒ RÂ² is not positive (-0.082). Skipping graph plotting.\n",
      "\n",
      "--- Running Simple LASSO Regression (Alpha=0.01): 'b_ders_total' ~ 'fpn_gm' ---\n",
      "  RÂ² (CV): -0.098 | RMSE (CV): 17.666 | N = 94\n",
      "  Intercept (Alpha): 70.3648 | Slope (Beta, LASSO): 0.0000\n",
      "  Note: P-value is not calculated for Regularized models.\n",
      "  âŒ RÂ² is not positive (-0.098). Skipping graph plotting.\n",
      "\n",
      "--- Running Simple LASSO Regression (Alpha=0.01): 'b_ders_total' ~ 'lim_gm' ---\n",
      "  RÂ² (CV): -0.088 | RMSE (CV): 17.584 | N = 94\n",
      "  Intercept (Alpha): 71.3296 | Slope (Beta, LASSO): 0.0000\n",
      "  Note: P-value is not calculated for Regularized models.\n",
      "  âŒ RÂ² is not positive (-0.088). Skipping graph plotting.\n",
      "\n",
      "--- Running Simple LASSO Regression (Alpha=0.01): 'b_ders_total' ~ 'smn_gm' ---\n",
      "  RÂ² (CV): -0.074 | RMSE (CV): 17.457 | N = 94\n",
      "  Intercept (Alpha): 89.6641 | Slope (Beta, LASSO): -0.0002\n",
      "  Note: P-value is not calculated for Regularized models.\n",
      "  âŒ RÂ² is not positive (-0.074). Skipping graph plotting.\n",
      "\n",
      "--- Running Simple LASSO Regression (Alpha=0.01): 'b_ders_total' ~ 'van_gm' ---\n",
      "  RÂ² (CV): -0.074 | RMSE (CV): 17.484 | N = 94\n",
      "  Intercept (Alpha): 62.6634 | Slope (Beta, LASSO): 0.0002\n",
      "  Note: P-value is not calculated for Regularized models.\n",
      "  âŒ RÂ² is not positive (-0.074). Skipping graph plotting.\n",
      "\n",
      "--- Running Simple LASSO Regression (Alpha=0.01): 'b_ders_total' ~ 'vis_gm' ---\n",
      "  RÂ² (CV): -0.099 | RMSE (CV): 17.634 | N = 94\n",
      "  Intercept (Alpha): 62.2615 | Slope (Beta, LASSO): 0.0001\n",
      "  Note: P-value is not calculated for Regularized models.\n",
      "  âŒ RÂ² is not positive (-0.099). Skipping graph plotting.\n",
      "\n",
      "=======================================================\n",
      "  Processing Y-Variable: after_ders_total\n",
      "=======================================================\n",
      "\n",
      "--- Running Simple LASSO Regression (Alpha=0.01): 'after_ders_total' ~ 'dmn_gm' ---\n",
      "  RÂ² (CV): -0.048 | RMSE (CV): 18.980 | N = 94\n",
      "  Intercept (Alpha): 91.4732 | Slope (Beta, LASSO): -0.0001\n",
      "  Note: P-value is not calculated for Regularized models.\n",
      "  âŒ RÂ² is not positive (-0.048). Skipping graph plotting.\n",
      "\n",
      "--- Running Simple LASSO Regression (Alpha=0.01): 'after_ders_total' ~ 'fpn_gm' ---\n",
      "  RÂ² (CV): -0.055 | RMSE (CV): 19.072 | N = 94\n",
      "  Intercept (Alpha): 70.5492 | Slope (Beta, LASSO): -0.0000\n",
      "  Note: P-value is not calculated for Regularized models.\n",
      "  âŒ RÂ² is not positive (-0.055). Skipping graph plotting.\n",
      "\n",
      "--- Running Simple LASSO Regression (Alpha=0.01): 'after_ders_total' ~ 'lim_gm' ---\n",
      "  RÂ² (CV): -0.051 | RMSE (CV): 19.060 | N = 94\n",
      "  Intercept (Alpha): 68.7141 | Slope (Beta, LASSO): 0.0000\n",
      "  Note: P-value is not calculated for Regularized models.\n",
      "  âŒ RÂ² is not positive (-0.051). Skipping graph plotting.\n",
      "\n",
      "--- Running Simple LASSO Regression (Alpha=0.01): 'after_ders_total' ~ 'smn_gm' ---\n",
      "  RÂ² (CV): -0.046 | RMSE (CV): 18.923 | N = 94\n",
      "  Intercept (Alpha): 94.4255 | Slope (Beta, LASSO): -0.0003\n",
      "  Note: P-value is not calculated for Regularized models.\n",
      "  âŒ RÂ² is not positive (-0.046). Skipping graph plotting.\n",
      "\n",
      "--- Running Simple LASSO Regression (Alpha=0.01): 'after_ders_total' ~ 'van_gm' ---\n",
      "  RÂ² (CV): -0.075 | RMSE (CV): 19.114 | N = 94\n",
      "  Intercept (Alpha): 94.8560 | Slope (Beta, LASSO): -0.0004\n",
      "  Note: P-value is not calculated for Regularized models.\n",
      "  âŒ RÂ² is not positive (-0.075). Skipping graph plotting.\n",
      "\n",
      "--- Running Simple LASSO Regression (Alpha=0.01): 'after_ders_total' ~ 'vis_gm' ---\n",
      "  RÂ² (CV): -0.063 | RMSE (CV): 19.165 | N = 94\n",
      "  Intercept (Alpha): 62.8593 | Slope (Beta, LASSO): 0.0001\n",
      "  Note: P-value is not calculated for Regularized models.\n",
      "  âŒ RÂ² is not positive (-0.063). Skipping graph plotting.\n",
      "\n",
      "=======================================================\n",
      "  Processing Y-Variable: diff_ders\n",
      "=======================================================\n",
      "\n",
      "--- Running Simple LASSO Regression (Alpha=0.01): 'diff_ders' ~ 'dmn_gm' ---\n",
      "  RÂ² (CV): -0.033 | RMSE (CV): 15.559 | N = 94\n",
      "  Intercept (Alpha): 14.9378 | Slope (Beta, LASSO): -0.0001\n",
      "  Note: P-value is not calculated for Regularized models.\n",
      "  âŒ RÂ² is not positive (-0.033). Skipping graph plotting.\n",
      "\n",
      "--- Running Simple LASSO Regression (Alpha=0.01): 'diff_ders' ~ 'fpn_gm' ---\n",
      "  RÂ² (CV): -0.060 | RMSE (CV): 15.718 | N = 94\n",
      "  Intercept (Alpha): 0.1844 | Slope (Beta, LASSO): -0.0001\n",
      "  Note: P-value is not calculated for Regularized models.\n",
      "  âŒ RÂ² is not positive (-0.060). Skipping graph plotting.\n",
      "\n",
      "--- Running Simple LASSO Regression (Alpha=0.01): 'diff_ders' ~ 'lim_gm' ---\n",
      "  RÂ² (CV): -0.041 | RMSE (CV): 15.601 | N = 94\n",
      "  Intercept (Alpha): -2.6155 | Slope (Beta, LASSO): 0.0000\n",
      "  Note: P-value is not calculated for Regularized models.\n",
      "  âŒ RÂ² is not positive (-0.041). Skipping graph plotting.\n",
      "\n",
      "--- Running Simple LASSO Regression (Alpha=0.01): 'diff_ders' ~ 'smn_gm' ---\n",
      "  RÂ² (CV): -0.049 | RMSE (CV): 15.647 | N = 94\n",
      "  Intercept (Alpha): 4.7614 | Slope (Beta, LASSO): -0.0001\n",
      "  Note: P-value is not calculated for Regularized models.\n",
      "  âŒ RÂ² is not positive (-0.049). Skipping graph plotting.\n",
      "\n",
      "--- Running Simple LASSO Regression (Alpha=0.01): 'diff_ders' ~ 'van_gm' ---\n",
      "  RÂ² (CV): -0.064 | RMSE (CV): 15.630 | N = 94\n",
      "  Intercept (Alpha): 32.1927 | Slope (Beta, LASSO): -0.0006\n",
      "  Note: P-value is not calculated for Regularized models.\n",
      "  âŒ RÂ² is not positive (-0.064). Skipping graph plotting.\n",
      "\n",
      "--- Running Simple LASSO Regression (Alpha=0.01): 'diff_ders' ~ 'vis_gm' ---\n",
      "  RÂ² (CV): -0.039 | RMSE (CV): 15.597 | N = 94\n",
      "  Intercept (Alpha): 0.5978 | Slope (Beta, LASSO): -0.0000\n",
      "  Note: P-value is not calculated for Regularized models.\n",
      "  âŒ RÂ² is not positive (-0.039). Skipping graph plotting.\n",
      "\n",
      "=======================================================\n",
      "  Processing Y-Variable: diff_des\n",
      "=======================================================\n",
      "\n",
      "--- Running Simple LASSO Regression (Alpha=0.01): 'diff_des' ~ 'dmn_gm' ---\n",
      "  RÂ² (CV): -0.106 | RMSE (CV): 5.374 | N = 94\n",
      "  Intercept (Alpha): -4.0533 | Slope (Beta, LASSO): 0.0000\n",
      "  Note: P-value is not calculated for Regularized models.\n",
      "  âŒ RÂ² is not positive (-0.106). Skipping graph plotting.\n",
      "\n",
      "--- Running Simple LASSO Regression (Alpha=0.01): 'diff_des' ~ 'fpn_gm' ---\n",
      "  RÂ² (CV): -0.077 | RMSE (CV): 5.301 | N = 94\n",
      "  Intercept (Alpha): -4.8019 | Slope (Beta, LASSO): 0.0001\n",
      "  Note: P-value is not calculated for Regularized models.\n",
      "  âŒ RÂ² is not positive (-0.077). Skipping graph plotting.\n",
      "\n",
      "--- Running Simple LASSO Regression (Alpha=0.01): 'diff_des' ~ 'lim_gm' ---\n",
      "  RÂ² (CV): -0.125 | RMSE (CV): 5.342 | N = 94\n",
      "  Intercept (Alpha): -7.9654 | Slope (Beta, LASSO): 0.0001\n",
      "  Note: P-value is not calculated for Regularized models.\n",
      "  âŒ RÂ² is not positive (-0.125). Skipping graph plotting.\n",
      "\n",
      "--- Running Simple LASSO Regression (Alpha=0.01): 'diff_des' ~ 'smn_gm' ---\n",
      "  RÂ² (CV): -0.112 | RMSE (CV): 5.389 | N = 94\n",
      "  Intercept (Alpha): -3.1639 | Slope (Beta, LASSO): 0.0000\n",
      "  Note: P-value is not calculated for Regularized models.\n",
      "  âŒ RÂ² is not positive (-0.112). Skipping graph plotting.\n",
      "\n",
      "--- Running Simple LASSO Regression (Alpha=0.01): 'diff_des' ~ 'van_gm' ---\n",
      "  RÂ² (CV): -0.134 | RMSE (CV): 5.412 | N = 94\n",
      "  Intercept (Alpha): -4.8519 | Slope (Beta, LASSO): 0.0001\n",
      "  Note: P-value is not calculated for Regularized models.\n",
      "  âŒ RÂ² is not positive (-0.134). Skipping graph plotting.\n",
      "\n",
      "--- Running Simple LASSO Regression (Alpha=0.01): 'diff_des' ~ 'vis_gm' ---\n",
      "  RÂ² (CV): -0.110 | RMSE (CV): 5.398 | N = 94\n",
      "  Intercept (Alpha): -3.0434 | Slope (Beta, LASSO): 0.0000\n",
      "  Note: P-value is not calculated for Regularized models.\n",
      "  âŒ RÂ² is not positive (-0.110). Skipping graph plotting.\n",
      "\n",
      "\n",
      "--- ×›×œ ×”× ×™×ª×•×—×™× ×”×¡×ª×™×™××• ---\n",
      "\n",
      "--- ×˜×‘×œ×ª ×¡×™×›×•× ×¡×•×¤×™×ª (×¨×’×¨×¡×™×™×ª ×œ××¡×• ×× ×‘××™× ××•×ª×××™× ××™×©×™×ª) ---\n",
      "\n",
      "âœ… ×˜×‘×œ×ª ×”×¡×™×›×•× × ×©××¨×” ×‘: data/only_Q_outputs/combined/LASSO_REGRESSION_CUSTOM_PREDICTORS_summary_table.csv\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## lasso t1 network and pc's",
   "id": "9a032dea30c27e0f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-18T08:15:03.999229Z",
     "start_time": "2025-11-18T08:15:03.954592Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.model_selection import KFold, cross_validate\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "\n",
    "# ===================================================================\n",
    "#           ×—×œ×§ 1: ×”×’×“×¨×•×ª × ×ª×™×‘×™× ×•×¤×¨××˜×¨×™×\n",
    "# ===================================================================\n",
    "\n",
    "# × ×ª×™×‘ ×”×§×•×‘×¥ ×”×¨××©×™ (X ×•-Y)\n",
    "DATA_PATH = \"data/merged_no_nan.csv\"\n",
    "\n",
    "# ×”×’×“×¨×•×ª ×§×•×‘×¥ ×”-PC\n",
    "PC_DATA_PATH = \"data/only_Q_outputs/combined/combined_pca_components.csv\"\n",
    "\n",
    "# ×ª×™×§×™×•×ª ×©××™×¨×”\n",
    "PLOTS_SAVE_DIR = \"data/only_Q_outputs/combined/LASSO_MULTIPLE_REGRESSION_PC_PREDICTORS_plots\"\n",
    "SUMMARY_TABLE_SAVE_PATH = \"data/only_Q_outputs/combined/LASSO_MULTIPLE_REGRESSION_PC_PREDICTORS_summary_table.csv\"\n",
    "\n",
    "# ğŸ’¡ğŸ’¡ğŸ’¡\n",
    "# --- ×”×’×“×¨ ×›××Ÿ ××ª ×”×¤×¨××˜×¨×™× ---\n",
    "# ğŸ’¡ğŸ’¡ğŸ’¡\n",
    "\n",
    "# 1. ×¨×©×™××ª ×”××©×ª× ×™× ×œ× ×™×‘×•×™ (Y)\n",
    "Y_VARIABLES_TO_PREDICT = [\n",
    "    'b_des_average',\n",
    "    'after_des_total',\n",
    "    \"b_ders_total\",\n",
    "    \"after_ders_total\",\n",
    "    \"diff_ders\",\n",
    "    \"diff_des\"\n",
    "]\n",
    "\n",
    "# 2. ×¨×©×™××ª ×”××©×ª× ×™× ×”×× ×‘××™× (X) ×”××§×•×¨×™×ª - ×™×ª×•×•×¡×¤×• ××œ×™×” ×¨×›×™×‘×™ ×”-PC ×‘×”××©×š!\n",
    "X_PREDICTORS = [\n",
    "    'dmn_gm',\n",
    "    'fpn_gm',\n",
    "    'lim_gm',\n",
    "    'smn_gm',\n",
    "    'van_gm',\n",
    "    'vis_gm'\n",
    "]\n",
    "\n",
    "# 3. ×¤×¨××˜×¨ ×¨×’×•×œ×¨×™×–×¦×™×” ×©×œ ×œ××¡×•\n",
    "LASSO_ALPHA = 0.01\n",
    "\n",
    "# 4. ×”×’×“×¨×•×ª ×œ××™××•×ª ×¦×•×œ×‘\n",
    "N_SPLITS = 5\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "df_for_regression = None\n",
    "\n",
    "try:\n",
    "    # ===================================================================\n",
    "    #           ×—×œ×§ 1: ×”×›× ×ª ×”× ×ª×•× ×™× (×˜×¢×™× ×” ×•× ×™×§×•×™)\n",
    "    # ===================================================================\n",
    "\n",
    "    print(f\"Loading main data (X and Y variables) from {DATA_PATH}...\")\n",
    "\n",
    "    # ×˜×•×¢× ×™× ××ª ×›×œ ×”×¢××•×“×•×ª ×”×“×¨×•×©×•×ª: subject_code, X ×•-Y, ×‘×ª×•×¡×¤×ª timepoint ×œ×¦×•×¨×š ×¡×™× ×•×Ÿ\n",
    "    columns_to_load = ['subject_code', 'timepoint'] + Y_VARIABLES_TO_PREDICT + X_PREDICTORS\n",
    "\n",
    "    df_for_regression = pd.read_csv(DATA_PATH, usecols=lambda c: c in columns_to_load)\n",
    "    df_for_regression.columns = [c.lower() for c in df_for_regression.columns] # ×•×“× ×©×›×œ ×”×¢××•×“×•×ª ×‘-lowercase\n",
    "\n",
    "    # *** ×©×™× ×•×™ 1: ×”×¡×¨×ª ×¢××•×“×ª timepoint ××”-DataFrame ×”×¨××©×™ ***\n",
    "    if 'timepoint' in df_for_regression.columns:\n",
    "        df_for_regression = df_for_regression.drop(columns=['timepoint'])\n",
    "        print(\"--- Removed 'timepoint' column from main data. ---\")\n",
    "\n",
    "    # ×”××¨×” ×œ-float64 ×œ×›×œ ×”×¢××•×“×•×ª ×”×¨×œ×•×•× ×˜×™×•×ª\n",
    "    all_var_cols = Y_VARIABLES_TO_PREDICT + X_PREDICTORS\n",
    "    for col in all_var_cols:\n",
    "        if col in df_for_regression.columns:\n",
    "            df_for_regression[col] = pd.to_numeric(df_for_regression[col], errors='coerce').astype(np.float64)\n",
    "\n",
    "    print(\"--- Main data successfully loaded ---\")\n",
    "\n",
    "    # -------------------------------------------------------------------\n",
    "    #           ×—×œ×§ 1.5: ×˜×¢×™× ×ª ×¨×›×™×‘×™ PC ×•××™×–×•×’× (×‘×¤×•×¨××˜ ×¨×—×‘)\n",
    "    # -------------------------------------------------------------------\n",
    "    print(f\"\\nLoading ALL PC data (Wide Format) from {PC_DATA_PATH}...\")\n",
    "\n",
    "    df_pc_wide = pd.read_csv(PC_DATA_PATH)\n",
    "    df_pc_wide.columns = [c.lower() for c in df_pc_wide.columns]\n",
    "\n",
    "    subject_id_col = 'subject_code'\n",
    "\n",
    "    # *** ×©×™× ×•×™ 2: ×¡×™× ×•×Ÿ × ×ª×•× ×™ ×”-PC ×œ×¤×™ timepoint (×× ×”×¢××•×“×” ×§×™×™××ª) ***\n",
    "    if 'timepoint' in df_pc_wide.columns:\n",
    "        initial_pc_count = len(df_pc_wide)\n",
    "\n",
    "        # ×¡×™× ×•×Ÿ ×œ×©×•×¨×•×ª ×”××›×™×œ×•×ª 'b/befpr' (×‘-lowercase)\n",
    "        df_pc_wide = df_pc_wide[df_pc_wide['timepoint'].str.contains('b', na=False, case=False)]\n",
    "\n",
    "        # ×”×¡×¨×ª ×¢××•×“×ª timepoint ×œ××—×¨ ×”×¡×™× ×•×Ÿ, ×›×“×™ ×œ×× ×•×¢ ×”×•×¡×¤×ª×” ×›××©×ª× ×” ×× ×‘×\n",
    "        df_pc_wide = df_pc_wide.drop(columns=['timepoint'])\n",
    "\n",
    "        print(f\"--- PC data filtered by timepoint='b/befpr'. Rows reduced from {initial_pc_count} to {len(df_pc_wide)} ---\")\n",
    "    else:\n",
    "        print(\"--- 'timepoint' column not found in PC file. No filtering applied. ---\")\n",
    "\n",
    "\n",
    "    # ×©××™×¨×ª ×¨×©×™××ª ×©××•×ª ×”-PC ×©× ×•×¦×¨×• (×›×œ ×¢××•×“×” ×©×”×™× ×œ× subject_code)\n",
    "    pc_columns_list = [col for col in df_pc_wide.columns if col != subject_id_col]\n",
    "\n",
    "    # ×”××¨×” ×œ-float64 ×¢×‘×•×¨ ×¢××•×“×•×ª ×”-PC\n",
    "    for col in pc_columns_list:\n",
    "        df_pc_wide[col] = pd.to_numeric(df_pc_wide[col], errors='coerce').astype(np.float64)\n",
    "\n",
    "    # ××™×–×•×’ ×”-PC ×¢× ×”-DataFrame ×”×¨××©×™\n",
    "    df_for_regression = pd.merge(\n",
    "        df_for_regression,\n",
    "        df_pc_wide,\n",
    "        on=subject_id_col,\n",
    "        how='left'\n",
    "    )\n",
    "    print(f\"--- All PC components successfully merged. New shape: {df_for_regression.shape} ---\")\n",
    "\n",
    "    # -------------------------------------------------------------------\n",
    "    #           ×¢×“×›×•×Ÿ ×¨×©×™××ª ×”×× ×‘××™× (X) ×œ×›×œ×•×œ ××ª ×›×œ ×”-PC\n",
    "    # -------------------------------------------------------------------\n",
    "    X_PREDICTORS.extend(pc_columns_list)\n",
    "    print(f\"\\nUpdated X Predictors (Total {len(X_PREDICTORS)}): {X_PREDICTORS}\")\n",
    "\n",
    "    # ×™×¦×™×¨×ª ×ª×™×§×™×™×ª ×”×¤×œ×˜ ×œ×’×¨×¤×™×\n",
    "    os.makedirs(PLOTS_SAVE_DIR, exist_ok=True)\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"×©×’×™××”: ×§×•×‘×¥ ×”× ×ª×•× ×™× ×”×¨××©×™ ××• ×§×•×‘×¥ ×”-PC ×œ× × ××¦×. ×•×“× × ×ª×™×‘×™×: {DATA_PATH} ×•- {PC_DATA_PATH}\")\n",
    "    df_for_regression = None\n",
    "except Exception as e:\n",
    "    print(f\"××™×¨×¢×” ×©×’×™××”: {e}\")\n",
    "    df_for_regression = None\n",
    "\n",
    "# ===================================================================\n",
    "#           ×—×œ×§ 2: ×”×¨×¦×ª ×”× ×™×ª×•×— ×‘×œ×•×œ××” (×¨×’×¨×¡×™×™×ª LASSO ××¨×•×‘×ª ××©×ª× ×™×)\n",
    "# ===================================================================\n",
    "\n",
    "all_results_list = []\n",
    "\n",
    "if df_for_regression is not None and not df_for_regression.empty:\n",
    "\n",
    "    # 1. × ×™×§×•×™ ×”× ×ª×•× ×™× ×”×—×¡×¨×™× (NaN) ××¨××© ×¢×œ ×›×œ ×”-X ×•×›×œ ×”-Y\n",
    "    columns_to_keep = Y_VARIABLES_TO_PREDICT + X_PREDICTORS\n",
    "    df_clean_data = df_for_regression[columns_to_keep].dropna()\n",
    "\n",
    "    if df_clean_data.empty:\n",
    "        print(\"--- Error: No complete data rows remaining after dropping NaNs. Analysis stopped. ---\")\n",
    "    else:\n",
    "        print(f\"\\n--- Data cleaned. N={len(df_clean_data)} subjects used in all models. ---\")\n",
    "\n",
    "        # X ×”××©×•×ª×£ ×œ×›×œ ×”×¨×’×¨×¡×™×•×ª (×›×œ ×”×× ×‘××™× ×™×—×“)\n",
    "        X_full = df_clean_data[X_PREDICTORS]\n",
    "\n",
    "        # --- ×”×ª×—×œ×ª ×”×œ×•×œ××” ×¢×œ ××©×ª× ×™ ×”-Y ×‘×œ×‘×“ ---\n",
    "        for y_col in Y_VARIABLES_TO_PREDICT:\n",
    "            print(f\"\\n=======================================================\")\n",
    "            print(f\"  Processing Y-Variable: {y_col} (LASSO Multiple Regression)\")\n",
    "            print(f\"=======================================================\")\n",
    "\n",
    "            y = df_clean_data[y_col]\n",
    "\n",
    "            # -------------------------------------------------------------\n",
    "            # --- ×©×œ×‘ 5×: ×”×¢×¨×›×ª ×”××•×“×œ (××™××•×ª ×¦×•×œ×‘) ×‘×××¦×¢×•×ª Lasso\n",
    "            # -------------------------------------------------------------\n",
    "            model_cv = Lasso(alpha=LASSO_ALPHA, random_state=RANDOM_STATE, max_iter=10000)\n",
    "            kfold = KFold(n_splits=N_SPLITS, shuffle=True, random_state=RANDOM_STATE)\n",
    "            scoring = {'r_squared': 'r2', 'neg_mse': 'neg_mean_squared_error'}\n",
    "\n",
    "            cv_scores = cross_validate(model_cv, X_full, y, cv=kfold, scoring=scoring)\n",
    "\n",
    "            mean_r2 = np.mean(cv_scores['test_r_squared'])\n",
    "            std_r2 = np.std(cv_scores['test_r_squared'])\n",
    "            mean_rmse = np.sqrt(-np.mean(cv_scores['test_neg_mse']))\n",
    "\n",
    "            print(f\"  RÂ² (CV): {mean_r2:.3f} | RMSE (CV): {mean_rmse:.3f} | N = {len(y)}\")\n",
    "\n",
    "            # -------------------------------------------------------------\n",
    "            # --- ×©×œ×‘ 5×‘: ××™××•×Ÿ ×”××•×“×œ ×¢×œ ×›×œ ×”× ×ª×•× ×™× ×›×“×™ ×œ×§×‘×œ ××§×“××™× ×¡×•×¤×™×™× ---\n",
    "            # -------------------------------------------------------------\n",
    "            final_model = Lasso(alpha=LASSO_ALPHA, random_state=RANDOM_STATE, max_iter=10000)\n",
    "            final_model.fit(X_full, y)\n",
    "\n",
    "            alpha_intercept = final_model.intercept_\n",
    "            betas = final_model.coef_\n",
    "\n",
    "            print(f\"  Intercept (Alpha): {alpha_intercept:.4f}\")\n",
    "\n",
    "            # ===============================================================\n",
    "            #               ×©××™×¨×ª ×ª×•×¦××•×ª (××¢×‘×¨ ×¢×œ ×›×œ ××§×“× ×‘× ×¤×¨×“)\n",
    "            # ===============================================================\n",
    "\n",
    "            for i, predictor_name in enumerate(X_PREDICTORS):\n",
    "                all_results_list.append({\n",
    "                    'Y_Variable': y_col,\n",
    "                    'X_Variable': predictor_name,\n",
    "                    'Model': 'LASSO_Multiple',\n",
    "                    'Alpha_Lasso_Reg': LASSO_ALPHA,\n",
    "                    'R_Squared_CV': mean_r2,\n",
    "                    'R_Squared_Std': std_r2,\n",
    "                    'RMSE_CV': mean_rmse,\n",
    "                    'Alpha_Intercept': alpha_intercept,\n",
    "                    'Beta_Slope': betas[i],\n",
    "                    'T_Stat': np.nan,\n",
    "                    'P_Value': np.nan,\n",
    "                    'N': len(y),\n",
    "                    'Plotted': False\n",
    "                })\n",
    "                if abs(betas[i]) > 1e-9:\n",
    "                    print(f\"    -> Beta({predictor_name}): {betas[i]:.4f}\")\n",
    "\n",
    "\n",
    "        print(\"\\n\\n--- ×›×œ × ×™×ª×•×—×™ ×”-LASSO ×”××¨×•×‘×™× ×”×¡×ª×™×™××• ---\")\n",
    "\n",
    "        # ===================================================================\n",
    "        #           ×—×œ×§ 3: ×™×¦×™×¨×ª ×˜×‘×œ×ª ×¡×™×›×•×\n",
    "        # ===================================================================\n",
    "\n",
    "        if all_results_list:\n",
    "            summary_df = pd.DataFrame(all_results_list)\n",
    "            summary_df = summary_df.sort_values(by=['Y_Variable', 'Beta_Slope'], ascending=[True, False])\n",
    "\n",
    "            print(\"\\n--- ×˜×‘×œ×ª ×¡×™×›×•× ×¡×•×¤×™×ª (×¨×’×¨×¡×™×™×ª LASSO ××¨×•×‘×ª ××©×ª× ×™×) ---\")\n",
    "\n",
    "            summary_df.to_csv(SUMMARY_TABLE_SAVE_PATH, index=False, encoding='utf-8-sig')\n",
    "            print(f\"\\nâœ… ×˜×‘×œ×ª ×”×¡×™×›×•× × ×©××¨×” ×‘: {SUMMARY_TABLE_SAVE_PATH}\")\n",
    "        else:\n",
    "            print(\"\\n--- ×œ× × ×•×¦×¨×• ×ª×•×¦××•×ª ---\")\n",
    "\n",
    "else:\n",
    "    print(\"×”× ×™×ª×•×— ×œ× ×¨×¥ ×›×™ ×”× ×ª×•× ×™× ×œ× × ×˜×¢× ×• ×›×¨××•×™.\")"
   ],
   "id": "aa08be98d6eb5aef",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading main data (X and Y variables) from data/merged_no_nan.csv...\n",
      "--- Main data successfully loaded ---\n",
      "\n",
      "Loading ALL PC data (Wide Format) from data/only_Q_outputs/combined/combined_pca_components.csv...\n",
      "×©×’×™××”: ×§×•×‘×¥ ×”× ×ª×•× ×™× ×”×¨××©×™ ××• ×§×•×‘×¥ ×”-PC ×œ× × ××¦×. ×•×“× × ×ª×™×‘×™×: data/merged_no_nan.csv ×•- data/only_Q_outputs/combined/combined_pca_components.csv\n",
      "×”× ×™×ª×•×— ×œ× ×¨×¥ ×›×™ ×”× ×ª×•× ×™× ×œ× × ×˜×¢× ×• ×›×¨××•×™.\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## lasso t1 lobes and pc's\n",
   "id": "728b5586f8aabe77"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-18T08:15:04.053246Z",
     "start_time": "2025-11-18T08:15:04.013249Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.model_selection import KFold, cross_validate\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "\n",
    "# ===================================================================\n",
    "#           ×—×œ×§ 1: ×”×’×“×¨×•×ª × ×ª×™×‘×™× ×•×¤×¨××˜×¨×™×\n",
    "# ===================================================================\n",
    "\n",
    "# × ×ª×™×‘ ×”×§×•×‘×¥ ×”×¨××©×™ (X ×•-Y)\n",
    "DATA_PATH = \"data/merged_no_nan.csv\"\n",
    "\n",
    "# ×”×’×“×¨×•×ª ×§×•×‘×¥ ×”-PC\n",
    "PC_DATA_PATH = \"data/only_Q_outputs/combined/combined_pca_components.csv\"\n",
    "\n",
    "# ×ª×™×§×™×•×ª ×©××™×¨×”\n",
    "PLOTS_SAVE_DIR = \"data/only_Q_outputs/combined/LASSO_MULTIPLE_REGRESSION_PC_PREDICTORS_plots\"\n",
    "SUMMARY_TABLE_SAVE_PATH = \"data/only_Q_outputs/combined/LASSO_MULTIPLE_REGRESSION_PC_PREDICTORS_summary_table.csv\"\n",
    "\n",
    "# ğŸ’¡ğŸ’¡ğŸ’¡\n",
    "# --- ×”×’×“×¨ ×›××Ÿ ××ª ×”×¤×¨××˜×¨×™× ---\n",
    "# ğŸ’¡ğŸ’¡ğŸ’¡\n",
    "\n",
    "# 1. ×¨×©×™××ª ×”××©×ª× ×™× ×œ× ×™×‘×•×™ (Y)\n",
    "Y_VARIABLES_TO_PREDICT = [\n",
    "    'b_des_average',\n",
    "    'after_des_total',\n",
    "    \"b_ders_total\",\n",
    "    \"after_ders_total\",\n",
    "    \"diff_ders\",\n",
    "    \"diff_des\"\n",
    "]\n",
    "\n",
    "# 2. ×¨×©×™××ª ×”××©×ª× ×™× ×”×× ×‘××™× (X) ×”××§×•×¨×™×ª - ×™×ª×•×•×¡×¤×• ××œ×™×” ×¨×›×™×‘×™ ×”-PC ×‘×”××©×š!\n",
    "X_PREDICTORS = [ \"cingulate\",\"frontal\",\"insula\",\"occipital\",\"parietal\",\"temporal\"]\n",
    "\n",
    "# 3. ×¤×¨××˜×¨ ×¨×’×•×œ×¨×™×–×¦×™×” ×©×œ ×œ××¡×•\n",
    "LASSO_ALPHA = 0.01\n",
    "\n",
    "# 4. ×”×’×“×¨×•×ª ×œ××™××•×ª ×¦×•×œ×‘\n",
    "N_SPLITS = 5\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "df_for_regression = None\n",
    "\n",
    "try:\n",
    "    # ===================================================================\n",
    "    #           ×—×œ×§ 1: ×”×›× ×ª ×”× ×ª×•× ×™× (×˜×¢×™× ×” ×•× ×™×§×•×™)\n",
    "    # ===================================================================\n",
    "\n",
    "    print(f\"Loading main data (X and Y variables) from {DATA_PATH}...\")\n",
    "\n",
    "    # ×˜×•×¢× ×™× ××ª ×›×œ ×”×¢××•×“×•×ª ×”×“×¨×•×©×•×ª: subject_code, X ×•-Y, ×‘×ª×•×¡×¤×ª timepoint ×œ×¦×•×¨×š ×¡×™× ×•×Ÿ\n",
    "    columns_to_load = ['subject_code', 'timepoint'] + Y_VARIABLES_TO_PREDICT + X_PREDICTORS\n",
    "\n",
    "    df_for_regression = pd.read_csv(DATA_PATH, usecols=lambda c: c in columns_to_load)\n",
    "    df_for_regression.columns = [c.lower() for c in df_for_regression.columns] # ×•×“× ×©×›×œ ×”×¢××•×“×•×ª ×‘-lowercase\n",
    "\n",
    "    # *** ×©×™× ×•×™ 1: ×”×¡×¨×ª ×¢××•×“×ª timepoint ××”-DataFrame ×”×¨××©×™ ***\n",
    "    if 'timepoint' in df_for_regression.columns:\n",
    "        df_for_regression = df_for_regression.drop(columns=['timepoint'])\n",
    "        print(\"--- Removed 'timepoint' column from main data. ---\")\n",
    "\n",
    "    # ×”××¨×” ×œ-float64 ×œ×›×œ ×”×¢××•×“×•×ª ×”×¨×œ×•×•× ×˜×™×•×ª\n",
    "    all_var_cols = Y_VARIABLES_TO_PREDICT + X_PREDICTORS\n",
    "    for col in all_var_cols:\n",
    "        if col in df_for_regression.columns:\n",
    "            df_for_regression[col] = pd.to_numeric(df_for_regression[col], errors='coerce').astype(np.float64)\n",
    "\n",
    "    print(\"--- Main data successfully loaded ---\")\n",
    "\n",
    "    # -------------------------------------------------------------------\n",
    "    #           ×—×œ×§ 1.5: ×˜×¢×™× ×ª ×¨×›×™×‘×™ PC ×•××™×–×•×’× (×‘×¤×•×¨××˜ ×¨×—×‘)\n",
    "    # -------------------------------------------------------------------\n",
    "    print(f\"\\nLoading ALL PC data (Wide Format) from {PC_DATA_PATH}...\")\n",
    "\n",
    "    df_pc_wide = pd.read_csv(PC_DATA_PATH)\n",
    "    df_pc_wide.columns = [c.lower() for c in df_pc_wide.columns]\n",
    "\n",
    "    subject_id_col = 'subject_code'\n",
    "\n",
    "    # *** ×©×™× ×•×™ 2: ×¡×™× ×•×Ÿ × ×ª×•× ×™ ×”-PC ×œ×¤×™ timepoint (×× ×”×¢××•×“×” ×§×™×™××ª) ***\n",
    "    if 'timepoint' in df_pc_wide.columns:\n",
    "        initial_pc_count = len(df_pc_wide)\n",
    "\n",
    "        # ×¡×™× ×•×Ÿ ×œ×©×•×¨×•×ª ×”××›×™×œ×•×ª 'b/befpr' (×‘-lowercase)\n",
    "        df_pc_wide = df_pc_wide[df_pc_wide['timepoint'].str.contains('b', na=False, case=False)]\n",
    "\n",
    "        # ×”×¡×¨×ª ×¢××•×“×ª timepoint ×œ××—×¨ ×”×¡×™× ×•×Ÿ, ×›×“×™ ×œ×× ×•×¢ ×”×•×¡×¤×ª×” ×›××©×ª× ×” ×× ×‘×\n",
    "        df_pc_wide = df_pc_wide.drop(columns=['timepoint'])\n",
    "\n",
    "        print(f\"--- PC data filtered by timepoint='b/befpr'. Rows reduced from {initial_pc_count} to {len(df_pc_wide)} ---\")\n",
    "    else:\n",
    "        print(\"--- 'timepoint' column not found in PC file. No filtering applied. ---\")\n",
    "\n",
    "\n",
    "    # ×©××™×¨×ª ×¨×©×™××ª ×©××•×ª ×”-PC ×©× ×•×¦×¨×• (×›×œ ×¢××•×“×” ×©×”×™× ×œ× subject_code)\n",
    "    pc_columns_list = [col for col in df_pc_wide.columns if col != subject_id_col]\n",
    "\n",
    "    # ×”××¨×” ×œ-float64 ×¢×‘×•×¨ ×¢××•×“×•×ª ×”-PC\n",
    "    for col in pc_columns_list:\n",
    "        df_pc_wide[col] = pd.to_numeric(df_pc_wide[col], errors='coerce').astype(np.float64)\n",
    "\n",
    "    # ××™×–×•×’ ×”-PC ×¢× ×”-DataFrame ×”×¨××©×™\n",
    "    df_for_regression = pd.merge(\n",
    "        df_for_regression,\n",
    "        df_pc_wide,\n",
    "        on=subject_id_col,\n",
    "        how='left'\n",
    "    )\n",
    "    print(f\"--- All PC components successfully merged. New shape: {df_for_regression.shape} ---\")\n",
    "\n",
    "    # -------------------------------------------------------------------\n",
    "    #           ×¢×“×›×•×Ÿ ×¨×©×™××ª ×”×× ×‘××™× (X) ×œ×›×œ×•×œ ××ª ×›×œ ×”-PC\n",
    "    # -------------------------------------------------------------------\n",
    "    X_PREDICTORS.extend(pc_columns_list)\n",
    "    print(f\"\\nUpdated X Predictors (Total {len(X_PREDICTORS)}): {X_PREDICTORS}\")\n",
    "\n",
    "    # ×™×¦×™×¨×ª ×ª×™×§×™×™×ª ×”×¤×œ×˜ ×œ×’×¨×¤×™×\n",
    "    os.makedirs(PLOTS_SAVE_DIR, exist_ok=True)\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"×©×’×™××”: ×§×•×‘×¥ ×”× ×ª×•× ×™× ×”×¨××©×™ ××• ×§×•×‘×¥ ×”-PC ×œ× × ××¦×. ×•×“× × ×ª×™×‘×™×: {DATA_PATH} ×•- {PC_DATA_PATH}\")\n",
    "    df_for_regression = None\n",
    "except Exception as e:\n",
    "    print(f\"××™×¨×¢×” ×©×’×™××”: {e}\")\n",
    "    df_for_regression = None\n",
    "\n",
    "# ===================================================================\n",
    "#           ×—×œ×§ 2: ×”×¨×¦×ª ×”× ×™×ª×•×— ×‘×œ×•×œ××” (×¨×’×¨×¡×™×™×ª LASSO ××¨×•×‘×ª ××©×ª× ×™×)\n",
    "# ===================================================================\n",
    "\n",
    "all_results_list = []\n",
    "\n",
    "if df_for_regression is not None and not df_for_regression.empty:\n",
    "\n",
    "    # 1. × ×™×§×•×™ ×”× ×ª×•× ×™× ×”×—×¡×¨×™× (NaN) ××¨××© ×¢×œ ×›×œ ×”-X ×•×›×œ ×”-Y\n",
    "    columns_to_keep = Y_VARIABLES_TO_PREDICT + X_PREDICTORS\n",
    "    df_clean_data = df_for_regression[columns_to_keep].dropna()\n",
    "\n",
    "    if df_clean_data.empty:\n",
    "        print(\"--- Error: No complete data rows remaining after dropping NaNs. Analysis stopped. ---\")\n",
    "    else:\n",
    "        print(f\"\\n--- Data cleaned. N={len(df_clean_data)} subjects used in all models. ---\")\n",
    "\n",
    "        # X ×”××©×•×ª×£ ×œ×›×œ ×”×¨×’×¨×¡×™×•×ª (×›×œ ×”×× ×‘××™× ×™×—×“)\n",
    "        X_full = df_clean_data[X_PREDICTORS]\n",
    "\n",
    "        # --- ×”×ª×—×œ×ª ×”×œ×•×œ××” ×¢×œ ××©×ª× ×™ ×”-Y ×‘×œ×‘×“ ---\n",
    "        for y_col in Y_VARIABLES_TO_PREDICT:\n",
    "            print(f\"\\n=======================================================\")\n",
    "            print(f\"  Processing Y-Variable: {y_col} (LASSO Multiple Regression)\")\n",
    "            print(f\"=======================================================\")\n",
    "\n",
    "            y = df_clean_data[y_col]\n",
    "\n",
    "            # -------------------------------------------------------------\n",
    "            # --- ×©×œ×‘ 5×: ×”×¢×¨×›×ª ×”××•×“×œ (××™××•×ª ×¦×•×œ×‘) ×‘×××¦×¢×•×ª Lasso\n",
    "            # -------------------------------------------------------------\n",
    "            model_cv = Lasso(alpha=LASSO_ALPHA, random_state=RANDOM_STATE, max_iter=10000)\n",
    "            kfold = KFold(n_splits=N_SPLITS, shuffle=True, random_state=RANDOM_STATE)\n",
    "            scoring = {'r_squared': 'r2', 'neg_mse': 'neg_mean_squared_error'}\n",
    "\n",
    "            cv_scores = cross_validate(model_cv, X_full, y, cv=kfold, scoring=scoring)\n",
    "\n",
    "            mean_r2 = np.mean(cv_scores['test_r_squared'])\n",
    "            std_r2 = np.std(cv_scores['test_r_squared'])\n",
    "            mean_rmse = np.sqrt(-np.mean(cv_scores['test_neg_mse']))\n",
    "\n",
    "            print(f\"  RÂ² (CV): {mean_r2:.3f} | RMSE (CV): {mean_rmse:.3f} | N = {len(y)}\")\n",
    "\n",
    "            # -------------------------------------------------------------\n",
    "            # --- ×©×œ×‘ 5×‘: ××™××•×Ÿ ×”××•×“×œ ×¢×œ ×›×œ ×”× ×ª×•× ×™× ×›×“×™ ×œ×§×‘×œ ××§×“××™× ×¡×•×¤×™×™× ---\n",
    "            # -------------------------------------------------------------\n",
    "            final_model = Lasso(alpha=LASSO_ALPHA, random_state=RANDOM_STATE, max_iter=10000)\n",
    "            final_model.fit(X_full, y)\n",
    "\n",
    "            alpha_intercept = final_model.intercept_\n",
    "            betas = final_model.coef_\n",
    "\n",
    "            print(f\"  Intercept (Alpha): {alpha_intercept:.4f}\")\n",
    "\n",
    "            # ===============================================================\n",
    "            #               ×©××™×¨×ª ×ª×•×¦××•×ª (××¢×‘×¨ ×¢×œ ×›×œ ××§×“× ×‘× ×¤×¨×“)\n",
    "            # ===============================================================\n",
    "\n",
    "            for i, predictor_name in enumerate(X_PREDICTORS):\n",
    "                all_results_list.append({\n",
    "                    'Y_Variable': y_col,\n",
    "                    'X_Variable': predictor_name,\n",
    "                    'Model': 'LASSO_Multiple',\n",
    "                    'Alpha_Lasso_Reg': LASSO_ALPHA,\n",
    "                    'R_Squared_CV': mean_r2,\n",
    "                    'R_Squared_Std': std_r2,\n",
    "                    'RMSE_CV': mean_rmse,\n",
    "                    'Alpha_Intercept': alpha_intercept,\n",
    "                    'Beta_Slope': betas[i],\n",
    "                    'T_Stat': np.nan,\n",
    "                    'P_Value': np.nan,\n",
    "                    'N': len(y),\n",
    "                    'Plotted': False\n",
    "                })\n",
    "                if abs(betas[i]) > 1e-9:\n",
    "                    print(f\"    -> Beta({predictor_name}): {betas[i]:.4f}\")\n",
    "\n",
    "\n",
    "        print(\"\\n\\n--- ×›×œ × ×™×ª×•×—×™ ×”-LASSO ×”××¨×•×‘×™× ×”×¡×ª×™×™××• ---\")\n",
    "\n",
    "        # ===================================================================\n",
    "        #           ×—×œ×§ 3: ×™×¦×™×¨×ª ×˜×‘×œ×ª ×¡×™×›×•×\n",
    "        # ===================================================================\n",
    "\n",
    "        if all_results_list:\n",
    "            summary_df = pd.DataFrame(all_results_list)\n",
    "            summary_df = summary_df.sort_values(by=['Y_Variable', 'Beta_Slope'], ascending=[True, False])\n",
    "\n",
    "            print(\"\\n--- ×˜×‘×œ×ª ×¡×™×›×•× ×¡×•×¤×™×ª (×¨×’×¨×¡×™×™×ª LASSO ××¨×•×‘×ª ××©×ª× ×™×) ---\")\n",
    "\n",
    "            summary_df.to_csv(SUMMARY_TABLE_SAVE_PATH, index=False, encoding='utf-8-sig')\n",
    "            print(f\"\\nâœ… ×˜×‘×œ×ª ×”×¡×™×›×•× × ×©××¨×” ×‘: {SUMMARY_TABLE_SAVE_PATH}\")\n",
    "        else:\n",
    "            print(\"\\n--- ×œ× × ×•×¦×¨×• ×ª×•×¦××•×ª ---\")\n",
    "\n",
    "else:\n",
    "    print(\"×”× ×™×ª×•×— ×œ× ×¨×¥ ×›×™ ×”× ×ª×•× ×™× ×œ× × ×˜×¢× ×• ×›×¨××•×™.\")"
   ],
   "id": "f039e456bc6294a5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading main data (X and Y variables) from data/merged_no_nan.csv...\n",
      "--- Main data successfully loaded ---\n",
      "\n",
      "Loading ALL PC data (Wide Format) from data/only_Q_outputs/combined/combined_pca_components.csv...\n",
      "×©×’×™××”: ×§×•×‘×¥ ×”× ×ª×•× ×™× ×”×¨××©×™ ××• ×§×•×‘×¥ ×”-PC ×œ× × ××¦×. ×•×“× × ×ª×™×‘×™×: data/merged_no_nan.csv ×•- data/only_Q_outputs/combined/combined_pca_components.csv\n",
      "×”× ×™×ª×•×— ×œ× ×¨×¥ ×›×™ ×”× ×ª×•× ×™× ×œ× × ×˜×¢× ×• ×›×¨××•×™.\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-18T08:15:04.133251Z",
     "start_time": "2025-11-18T08:15:04.098824Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# ğŸ’¡ ×©×™× ×•×™: ×™×™×‘×•× Ridge ×‘××§×•× Lasso\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import KFold, cross_validate\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "\n",
    "# ===================================================================\n",
    "#           ×—×œ×§ 1: ×”×’×“×¨×•×ª × ×ª×™×‘×™× ×•×¤×¨××˜×¨×™×\n",
    "# ===================================================================\n",
    "\n",
    "# × ×ª×™×‘ ×”×§×•×‘×¥ ×”×¨××©×™ (X ×•-Y)\n",
    "DATA_PATH = \"data/merged_no_nan.csv\"\n",
    "\n",
    "# ×”×’×“×¨×•×ª ×§×•×‘×¥ ×”-PC\n",
    "PC_DATA_PATH = \"data/only_Q_outputs/combined/combined_pca_components.csv\"\n",
    "\n",
    "# ×ª×™×§×™×•×ª ×©××™×¨×”\n",
    "# ğŸ’¡ ×¢×“×›×•×Ÿ ×©××•×ª ×”×¤×œ×˜ ×œ-RIDGE\n",
    "PLOTS_SAVE_DIR = \"data/only_Q_outputs/combined/RIDGE_MULTIPLE_REGRESSION_PC_PREDICTORS_plots\"\n",
    "SUMMARY_TABLE_SAVE_PATH = \"data/only_Q_outputs/combined/RIDGE_MULTIPLE_REGRESSION_PC_PREDICTORS_summary_table.csv\"\n",
    "\n",
    "# ğŸ’¡ğŸ’¡ğŸ’¡\n",
    "# --- ×”×’×“×¨ ×›××Ÿ ××ª ×”×¤×¨××˜×¨×™× ---\n",
    "# ğŸ’¡ğŸ’¡ğŸ’¡\n",
    "\n",
    "# 1. ×¨×©×™××ª ×”××©×ª× ×™× ×œ× ×™×‘×•×™ (Y)\n",
    "Y_VARIABLES_TO_PREDICT = [\n",
    "    'b_des_average',\n",
    "    'after_des_total',\n",
    "    \"b_ders_total\",\n",
    "    \"after_ders_total\",\n",
    "    \"diff_ders\",\n",
    "    \"diff_des\"\n",
    "]\n",
    "\n",
    "# 2. ×¨×©×™××ª ×”××©×ª× ×™× ×”×× ×‘××™× (X) ×”××§×•×¨×™×ª - ×™×ª×•×•×¡×¤×• ××œ×™×” ×¨×›×™×‘×™ ×”-PC ×‘×”××©×š!\n",
    "X_PREDICTORS = [\n",
    "    'dmn_gm',\n",
    "    'fpn_gm',\n",
    "    'lim_gm',\n",
    "    'smn_gm',\n",
    "    'van_gm',\n",
    "    'vis_gm'\n",
    "]\n",
    "\n",
    "# 3. ×¤×¨××˜×¨ ×¨×’×•×œ×¨×™×–×¦×™×” (× ×§×¨× ×’× Alpha ××• Lambda)\n",
    "RIDGE_ALPHA = 0.01\n",
    "\n",
    "# 4. ×”×’×“×¨×•×ª ×œ××™××•×ª ×¦×•×œ×‘\n",
    "N_SPLITS = 5\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "df_for_regression = None\n",
    "\n",
    "try:\n",
    "    # ===================================================================\n",
    "    #           ×—×œ×§ 1: ×”×›× ×ª ×”× ×ª×•× ×™× (×˜×¢×™× ×” ×•× ×™×§×•×™) - ×œ×œ× ×©×™× ×•×™\n",
    "    # ===================================================================\n",
    "\n",
    "    print(f\"Loading main data (X and Y variables) from {DATA_PATH}...\")\n",
    "    columns_to_load = ['subject_code', 'timepoint'] + Y_VARIABLES_TO_PREDICT + X_PREDICTORS\n",
    "    df_for_regression = pd.read_csv(DATA_PATH, usecols=lambda c: c in columns_to_load)\n",
    "    df_for_regression.columns = [c.lower() for c in df_for_regression.columns]\n",
    "\n",
    "    # ×”×¡×¨×ª ×¢××•×“×ª timepoint ××”-DataFrame ×”×¨××©×™\n",
    "    if 'timepoint' in df_for_regression.columns:\n",
    "        df_for_regression = df_for_regression.drop(columns=['timepoint'])\n",
    "        print(\"--- Removed 'timepoint' column from main data. ---\")\n",
    "\n",
    "    all_var_cols = Y_VARIABLES_TO_PREDICT + X_PREDICTORS\n",
    "    for col in all_var_cols:\n",
    "        if col in df_for_regression.columns:\n",
    "            df_for_regression[col] = pd.to_numeric(df_for_regression[col], errors='coerce').astype(np.float64)\n",
    "\n",
    "    print(\"--- Main data successfully loaded ---\")\n",
    "\n",
    "    # -------------------------------------------------------------------\n",
    "    #           ×—×œ×§ 1.5: ×˜×¢×™× ×ª ×¨×›×™×‘×™ PC ×•××™×–×•×’× (×‘×¤×•×¨××˜ ×¨×—×‘) - ×œ×œ× ×©×™× ×•×™\n",
    "    # -------------------------------------------------------------------\n",
    "    print(f\"\\nLoading ALL PC data (Wide Format) from {PC_DATA_PATH}...\")\n",
    "\n",
    "    df_pc_wide = pd.read_csv(PC_DATA_PATH)\n",
    "    df_pc_wide.columns = [c.lower() for c in df_pc_wide.columns]\n",
    "\n",
    "    subject_id_col = 'subject_code'\n",
    "\n",
    "    # ×¡×™× ×•×Ÿ × ×ª×•× ×™ ×”-PC ×œ×¤×™ timepoint (×× ×”×¢××•×“×” ×§×™×™××ª)\n",
    "    if 'timepoint' in df_pc_wide.columns:\n",
    "        initial_pc_count = len(df_pc_wide)\n",
    "        df_pc_wide = df_pc_wide[df_pc_wide['timepoint'].str.contains('b', na=False, case=False)]\n",
    "        df_pc_wide = df_pc_wide.drop(columns=['timepoint'])\n",
    "        print(f\"--- PC data filtered by timepoint='b/befpr'. Rows reduced from {initial_pc_count} to {len(df_pc_wide)} ---\")\n",
    "    else:\n",
    "        print(\"--- 'timepoint' column not found in PC file. No filtering applied. ---\")\n",
    "\n",
    "\n",
    "    pc_columns_list = [col for col in df_pc_wide.columns if col != subject_id_col]\n",
    "\n",
    "    for col in pc_columns_list:\n",
    "        df_pc_wide[col] = pd.to_numeric(df_pc_wide[col], errors='coerce').astype(np.float64)\n",
    "\n",
    "    df_for_regression = pd.merge(\n",
    "        df_for_regression,\n",
    "        df_pc_wide,\n",
    "        on=subject_id_col,\n",
    "        how='left'\n",
    "    )\n",
    "    print(f\"--- All PC components successfully merged. New shape: {df_for_regression.shape} ---\")\n",
    "\n",
    "    X_PREDICTORS.extend(pc_columns_list)\n",
    "    print(f\"\\nUpdated X Predictors (Total {len(X_PREDICTORS)}): {X_PREDICTORS}\")\n",
    "\n",
    "    os.makedirs(PLOTS_SAVE_DIR, exist_ok=True)\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"×©×’×™××”: ×§×•×‘×¥ ×”× ×ª×•× ×™× ×”×¨××©×™ ××• ×§×•×‘×¥ ×”-PC ×œ× × ××¦×. ×•×“× × ×ª×™×‘×™×: {DATA_PATH} ×•- {PC_DATA_PATH}\")\n",
    "    df_for_regression = None\n",
    "except Exception as e:\n",
    "    print(f\"××™×¨×¢×” ×©×’×™××”: {e}\")\n",
    "    df_for_regression = None\n",
    "\n",
    "# ===================================================================\n",
    "#           ×—×œ×§ 2: ×”×¨×¦×ª ×”× ×™×ª×•×— ×‘×œ×•×œ××” (×¨×’×¨×¡×™×™×ª RIDGE ××¨×•×‘×ª ××©×ª× ×™×)\n",
    "# ===================================================================\n",
    "\n",
    "all_results_list = []\n",
    "\n",
    "if df_for_regression is not None and not df_for_regression.empty:\n",
    "\n",
    "    columns_to_keep = Y_VARIABLES_TO_PREDICT + X_PREDICTORS\n",
    "    df_clean_data = df_for_regression[columns_to_keep].dropna()\n",
    "    df_for_regression[columns_to_keep].to_csv('data/only_Q_outputs/combined/merged_pc_t1_clinical.csv')\n",
    "    if df_clean_data.empty:\n",
    "        print(\"--- Error: No complete data rows remaining after dropping NaNs. Analysis stopped. ---\")\n",
    "    else:\n",
    "        print(f\"\\n--- Data cleaned. N={len(df_clean_data)} subjects used in all models. ---\")\n",
    "\n",
    "        X_full = df_clean_data[X_PREDICTORS]\n",
    "\n",
    "        for y_col in Y_VARIABLES_TO_PREDICT:\n",
    "            print(f\"\\n=======================================================\")\n",
    "            print(f\"  Processing Y-Variable: {y_col} (RIDGE Multiple Regression)\")\n",
    "            print(f\"=======================================================\")\n",
    "\n",
    "            y = df_clean_data[y_col]\n",
    "\n",
    "            # -------------------------------------------------------------\n",
    "            # --- ×©×œ×‘ 5×: ×”×¢×¨×›×ª ×”××•×“×œ (××™××•×ª ×¦×•×œ×‘) ×‘×××¦×¢×•×ª RIDGE\n",
    "            # -------------------------------------------------------------\n",
    "            # ğŸ’¡ ×©×™× ×•×™: ×©×™××•×© ×‘-Ridge ×‘××§×•× Lasso\n",
    "            model_cv = Ridge(alpha=RIDGE_ALPHA, random_state=RANDOM_STATE)\n",
    "            kfold = KFold(n_splits=N_SPLITS, shuffle=True, random_state=RANDOM_STATE)\n",
    "            scoring = {'r_squared': 'r2', 'neg_mse': 'neg_mean_squared_error'}\n",
    "\n",
    "            cv_scores = cross_validate(model_cv, X_full, y, cv=kfold, scoring=scoring)\n",
    "\n",
    "            mean_r2 = np.mean(cv_scores['test_r_squared'])\n",
    "            std_r2 = np.std(cv_scores['test_r_squared'])\n",
    "            mean_rmse = np.sqrt(-np.mean(cv_scores['test_neg_mse']))\n",
    "\n",
    "            print(f\"  RÂ² (CV): {mean_r2:.3f} | RMSE (CV): {mean_rmse:.3f} | N = {len(y)}\")\n",
    "\n",
    "            # -------------------------------------------------------------\n",
    "            # --- ×©×œ×‘ 5×‘: ××™××•×Ÿ ×”××•×“×œ ×¢×œ ×›×œ ×”× ×ª×•× ×™× ×›×“×™ ×œ×§×‘×œ ××§×“××™× ×¡×•×¤×™×™× ---\n",
    "            # -------------------------------------------------------------\n",
    "            # ğŸ’¡ ×©×™× ×•×™: ×©×™××•×© ×‘-Ridge ×‘××§×•× Lasso\n",
    "            final_model = Ridge(alpha=RIDGE_ALPHA, random_state=RANDOM_STATE)\n",
    "            final_model.fit(X_full, y)\n",
    "\n",
    "            alpha_intercept = final_model.intercept_\n",
    "            betas = final_model.coef_\n",
    "\n",
    "            print(f\"  Intercept (Alpha): {alpha_intercept:.4f}\")\n",
    "\n",
    "            # ===============================================================\n",
    "            #               ×©××™×¨×ª ×ª×•×¦××•×ª\n",
    "            # ===============================================================\n",
    "\n",
    "            for i, predictor_name in enumerate(X_PREDICTORS):\n",
    "                all_results_list.append({\n",
    "                    'Y_Variable': y_col,\n",
    "                    'X_Variable': predictor_name,\n",
    "                    # ğŸ’¡ ×¢×“×›×•×Ÿ: ×©× ×”××•×“×œ\n",
    "                    'Model': 'RIDGE_Multiple',\n",
    "                    'Alpha_Ridge_Reg': RIDGE_ALPHA,\n",
    "                    'R_Squared_CV': mean_r2,\n",
    "                    'R_Squared_Std': std_r2,\n",
    "                    'RMSE_CV': mean_rmse,\n",
    "                    'Alpha_Intercept': alpha_intercept,\n",
    "                    'Beta_Slope': betas[i],\n",
    "                    'T_Stat': np.nan,\n",
    "                    'P_Value': np.nan,\n",
    "                    'N': len(y),\n",
    "                    'Plotted': False\n",
    "                })\n",
    "                # ×”×“×¤×¡×ª ××§×“××™× ××©××¢×•×ª×™×™×\n",
    "                if abs(betas[i]) > 1e-9:\n",
    "                    print(f\"    -> Beta({predictor_name}): {betas[i]:.4f}\")\n",
    "\n",
    "\n",
    "        print(\"\\n\\n--- ×›×œ × ×™×ª×•×—×™ ×”-RIDGE ×”××¨×•×‘×™× ×”×¡×ª×™×™××• ---\")\n",
    "\n",
    "        # ===================================================================\n",
    "        #           ×—×œ×§ 3: ×™×¦×™×¨×ª ×˜×‘×œ×ª ×¡×™×›×•×\n",
    "        # ===================================================================\n",
    "\n",
    "        if all_results_list:\n",
    "            summary_df = pd.DataFrame(all_results_list)\n",
    "            summary_df = summary_df.sort_values(by=['Y_Variable', 'Beta_Slope'], ascending=[True, False])\n",
    "\n",
    "            print(\"\\n--- ×˜×‘×œ×ª ×¡×™×›×•× ×¡×•×¤×™×ª (×¨×’×¨×¡×™×™×ª RIDGE ××¨×•×‘×ª ××©×ª× ×™×) ---\")\n",
    "\n",
    "            summary_df.to_csv(SUMMARY_TABLE_SAVE_PATH, index=False, encoding='utf-8-sig')\n",
    "            print(f\"\\nâœ… ×˜×‘×œ×ª ×”×¡×™×›×•× × ×©××¨×” ×‘: {SUMMARY_TABLE_SAVE_PATH}\")\n",
    "        else:\n",
    "            print(\"\\n--- ×œ× × ×•×¦×¨×• ×ª×•×¦××•×ª ---\")\n",
    "\n",
    "else:\n",
    "    print(\"×”× ×™×ª×•×— ×œ× ×¨×¥ ×›×™ ×”× ×ª×•× ×™× ×œ× × ×˜×¢× ×• ×›×¨××•×™.\")"
   ],
   "id": "4dba1aa8341085fe",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading main data (X and Y variables) from data/merged_no_nan.csv...\n",
      "--- Main data successfully loaded ---\n",
      "\n",
      "Loading ALL PC data (Wide Format) from data/only_Q_outputs/combined/combined_pca_components.csv...\n",
      "×©×’×™××”: ×§×•×‘×¥ ×”× ×ª×•× ×™× ×”×¨××©×™ ××• ×§×•×‘×¥ ×”-PC ×œ× × ××¦×. ×•×“× × ×ª×™×‘×™×: data/merged_no_nan.csv ×•- data/only_Q_outputs/combined/combined_pca_components.csv\n",
      "×”× ×™×ª×•×— ×œ× ×¨×¥ ×›×™ ×”× ×ª×•× ×™× ×œ× × ×˜×¢× ×• ×›×¨××•×™.\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## clusters with lasso regrssion\n",
   "id": "4e6d2d2c8574beff"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-18T08:15:04.244987Z",
     "start_time": "2025-11-18T08:15:04.217980Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# from sklearn.linear_model import LassoCV\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# from sklearn.model_selection import KFold, cross_validate\n",
    "# import os\n",
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "#\n",
    "# # ===================================================================\n",
    "# #           PART 1: Settings and Parameters\n",
    "# # ===================================================================\n",
    "#\n",
    "# # File Paths\n",
    "# CLUSTER_DATA_WIDE_PATH = \"data/only_Q_outputs/combined/timepoints_file_inverted_2.csv\"\n",
    "# raw_data_path = \"data/only_Q_outputs/combined/regression_parameters.csv\"\n",
    "#\n",
    "# # Output Directories\n",
    "# PLOTS_SAVE_DIR = \"data/only_Q_outputs/combined/regression_LASSO_Cluster_SingleTimepoint_plots\"\n",
    "# SUMMARY_TABLE_SAVE_PATH = \"data/only_Q_outputs/combined/regression_LASSO_Cluster_SingleTimepoint_summary.csv\"\n",
    "#\n",
    "# # ğŸ’¡PARAMETERS ğŸ’¡\n",
    "#\n",
    "# # 1. Y Variables\n",
    "# Y_VARIABLES_TO_PREDICT = [\n",
    "#     'b_DES_average',\n",
    "#     'after_DES_total',\n",
    "#     \"b_DERS_total\",\n",
    "#     \"after_DERS_total\",\n",
    "#     \"diff_DERS\",\n",
    "#     \"diff_DES\"\n",
    "# ]\n",
    "#\n",
    "# # 2. X Variables (Cluster Timepoints)\n",
    "# X_CLUSTER_TIMEPOINTS = ['before', 't1', 't2', 't3', 'after']\n",
    "#\n",
    "# # 3. CV Settings\n",
    "# N_SPLITS = 5\n",
    "# RANDOM_STATE = 42\n",
    "#\n",
    "# df_for_analysis = None\n",
    "#\n",
    "# try:\n",
    "#     # ===================================================================\n",
    "#     #           PART 1: Data Preparation\n",
    "#     # ===================================================================\n",
    "#\n",
    "#     # --- Load Cluster Data ---\n",
    "#     print(f\"Loading Cluster data...\")\n",
    "#     cluster_df = pd.read_csv(CLUSTER_DATA_WIDE_PATH)\n",
    "#\n",
    "#     # Ensure numeric (0/1)\n",
    "#     for tp in X_CLUSTER_TIMEPOINTS:\n",
    "#          cluster_df[tp] = pd.to_numeric(cluster_df[tp], errors='coerce')\n",
    "#\n",
    "#     # --- Load Y Data ---\n",
    "#     print(\"Loading Y variables...\")\n",
    "#     columns_to_load = ['Subject_Code'] + Y_VARIABLES_TO_PREDICT\n",
    "#     raw_df = pd.read_csv(raw_data_path, usecols=lambda c: c in columns_to_load)\n",
    "#\n",
    "#     # Ensure float\n",
    "#     for y_col in Y_VARIABLES_TO_PREDICT:\n",
    "#         if y_col in raw_df.columns:\n",
    "#             raw_df[y_col] = raw_df[y_col].astype(np.float64, errors='ignore')\n",
    "#\n",
    "#     # --- Merge ---\n",
    "#     df_merged = pd.merge(cluster_df, raw_df, on='Subject_Code', how='inner')\n",
    "#\n",
    "#     os.makedirs(PLOTS_SAVE_DIR, exist_ok=True)\n",
    "#     df_for_analysis = df_merged\n",
    "#     print(\"--- Data Merged Successfully ---\")\n",
    "#\n",
    "# except Exception as e:\n",
    "#     print(f\"Error loading data: {e}\")\n",
    "#     df_for_analysis = None\n",
    "#\n",
    "# # ===================================================================\n",
    "# #           PART 2: LASSO Loop (Single Timepoint)\n",
    "# # ===================================================================\n",
    "#\n",
    "# all_results_list = []\n",
    "#\n",
    "# if df_for_analysis is not None:\n",
    "#\n",
    "#     for y_col in Y_VARIABLES_TO_PREDICT:\n",
    "#         print(f\"\\n=======================================================\")\n",
    "#         print(f\"  Target (Y): {y_col}\")\n",
    "#         print(f\"=======================================================\")\n",
    "#\n",
    "#         # Loop through each timepoint separately\n",
    "#         for tp in X_CLUSTER_TIMEPOINTS:\n",
    "#\n",
    "#             if tp not in df_for_analysis.columns:\n",
    "#                 continue\n",
    "#\n",
    "#             # 1. Prepare Data\n",
    "#             data_clean = df_for_analysis[[tp, y_col]].dropna()\n",
    "#\n",
    "#             if len(data_clean) < N_SPLITS * 2:\n",
    "#                 continue\n",
    "#\n",
    "#             # X must be 2D for sklearn\n",
    "#             X = data_clean[[tp]]\n",
    "#             y = data_clean[y_col]\n",
    "#\n",
    "#             # Check if we actually have two clusters (0 and 1)\n",
    "#             if X[tp].nunique() < 2:\n",
    "#                 print(f\"  Skipping {tp}: Only one cluster found.\")\n",
    "#                 continue\n",
    "#\n",
    "#             # --- 2. Scaling (Mandatory for Lasso) ---\n",
    "#             scaler = StandardScaler()\n",
    "#             X_scaled = scaler.fit_transform(X)\n",
    "#\n",
    "#             # --- 3. Train LassoCV Model ---\n",
    "#             # This finds the best Alpha and fits the model\n",
    "#             lasso_model = LassoCV(cv=N_SPLITS, random_state=RANDOM_STATE, max_iter=10000)\n",
    "#             lasso_model.fit(X_scaled, y)\n",
    "#\n",
    "#             # Extract Coefs (Note: These are coefficients for the SCALED data)\n",
    "#             best_alpha = lasso_model.alpha_\n",
    "#             beta_scaled = lasso_model.coef_[0] # There is only one feature\n",
    "#             intercept = lasso_model.intercept_\n",
    "#\n",
    "#             # --- 4. Cross Validation for R2 ---\n",
    "#             kfold = KFold(n_splits=N_SPLITS, shuffle=True, random_state=RANDOM_STATE)\n",
    "#             cv_scores = cross_validate(lasso_model, X_scaled, y, cv=kfold,\n",
    "#                                      scoring={'r2': 'r2', 'neg_mse': 'neg_mean_squared_error'})\n",
    "#\n",
    "#             mean_r2 = np.mean(cv_scores['test_r2'])\n",
    "#             mean_rmse = np.sqrt(-np.mean(cv_scores['test_neg_mse']))\n",
    "#\n",
    "#             print(f\"  [{tp}] RÂ²(CV): {mean_r2:.3f} | Beta(Scaled): {beta_scaled:.3f}\")\n",
    "#\n",
    "#             # ===============================================================\n",
    "#             #           Plot: Boxplot (If R2 > 0 and Beta != 0)\n",
    "#             # ===============================================================\n",
    "#             # We check abs(beta_scaled) > 0 because Lasso might zero it out\n",
    "#             if mean_r2 > 0 and abs(beta_scaled) > 0.0001:\n",
    "#\n",
    "#                 plt.figure(figsize=(8, 6))\n",
    "#\n",
    "#                 # Boxplot of raw data (easier to interpret visually)\n",
    "#                 sns.boxplot(x=tp, y=y_col, data=data_clean, palette=\"pastel\")\n",
    "#                 sns.stripplot(x=tp, y=y_col, data=data_clean, color='black', alpha=0.6, jitter=True)\n",
    "#\n",
    "#                 plt.title(f'Lasso Prediction: {y_col} by Cluster at {tp}')\n",
    "#                 plt.xlabel(f'Cluster Assignment (0 vs 1) at {tp}')\n",
    "#                 plt.ylabel(f'{y_col}')\n",
    "#\n",
    "#                 stats_text = (f'$R^2$ (CV) = {mean_r2:.3f}\\n'\n",
    "#                               f'Lasso Beta (Scaled) = {beta_scaled:.3f}\\n'\n",
    "#                               f'Alpha (Penalty) = {best_alpha:.4f}')\n",
    "#\n",
    "#                 plt.text(0.05, 0.95, stats_text, transform=plt.gca().transAxes,\n",
    "#                          verticalalignment='top', fontsize=10,\n",
    "#                          bbox=dict(boxstyle='round,pad=0.5', fc='white', alpha=0.8))\n",
    "#\n",
    "#                 plt.tight_layout()\n",
    "#\n",
    "#                 save_name = f\"Lasso_Single_{y_col}_at_{tp}.png\"\n",
    "#                 plt.savefig(os.path.join(PLOTS_SAVE_DIR, save_name), dpi=100)\n",
    "#                 plt.close()\n",
    "#                 print(f\"    âœ… Plot saved: {save_name}\")\n",
    "#             else:\n",
    "#                 print(f\"    âŒ No plot (RÂ² <= 0 or Coef shrunk to 0)\")\n",
    "#\n",
    "#             # Save results\n",
    "#             all_results_list.append({\n",
    "#                 'Y_Variable': y_col,\n",
    "#                 'Timepoint': tp,\n",
    "#                 'R2_CV': mean_r2,\n",
    "#                 'RMSE_CV': mean_rmse,\n",
    "#                 'Lasso_Beta_Scaled': beta_scaled,\n",
    "#                 'Best_Penalty_Alpha': best_alpha,\n",
    "#                 'N_samples': len(y)\n",
    "#             })\n",
    "#\n",
    "#     # ===================================================================\n",
    "#     #           PART 3: Save Summary\n",
    "#     # ===================================================================\n",
    "#     if all_results_list:\n",
    "#         summary_df = pd.DataFrame(all_results_list)\n",
    "#         summary_df = summary_df.sort_values(by=['Y_Variable', 'R2_CV'], ascending=[True, False])\n",
    "#         summary_df.to_csv(SUMMARY_TABLE_SAVE_PATH, index=False)\n",
    "#         print(f\"\\nâœ… Summary saved to: {SUMMARY_TABLE_SAVE_PATH}\")\n",
    "#     else:\n",
    "#         print(\"No results generated.\")"
   ],
   "id": "b08673e2417e93ad",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Cluster data...\n",
      "Error loading data: [Errno 2] No such file or directory: 'data/only_Q_outputs/combined/timepoints_file_inverted_2.csv'\n"
     ]
    }
   ],
   "execution_count": 12
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
