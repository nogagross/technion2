{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-12-05T08:27:17.423665Z",
     "start_time": "2025-12-05T08:27:17.417676Z"
    }
   },
   "source": [
    "import os\n",
    "import re\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-05T08:27:17.643687Z",
     "start_time": "2025-12-05T08:27:17.636694Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# import pandas as pd\n",
    "# import sys\n",
    "#\n",
    "# # --- Configuration ---\n",
    "#\n",
    "# # The CSV file you uploaded\n",
    "# INPUT_CSV_FILE = 'data/final_merged_fmri_t1_clinical (2).csv'\n",
    "#\n",
    "# # The new Excel file we will create\n",
    "# OUTPUT_EXCEL_FILE = 'data/T1_first_session_data.xlsx'\n",
    "#\n",
    "# # The one column you want to include in EVERY sheet\n",
    "# # Based on your request, this is 'Subject_Code'\n",
    "# KEY_COLUMN = 'Subject_Code'\n",
    "#\n",
    "# # VVV --- THIS IS THE PART YOU EDIT --- VVV\n",
    "# #\n",
    "# # Define the sheets you want to create.\n",
    "# #\n",
    "# # - The 'key' is the name you want for the sheet (e.g., 'Clinical_Scores').\n",
    "# # - The 'value' is a list of all the *other* columns you want in that sheet.\n",
    "# #\n",
    "# # The KEY_COLUMN ('Subject_Code') will be added for you automatically.\n",
    "# # I've added some examples based on your CSV's column names.\n",
    "# #\n",
    "# SHEETS_TO_CREATE = {\n",
    "#     'global_parameters': [\n",
    "#     \"brainsegvol\",\n",
    "#     \"cerebralwhitemattervol\",\n",
    "#     \"cortexvol\",\n",
    "#     \"etiv\",\n",
    "#     \"lhcortexvol\",\n",
    "#     \"rhcortexvol\",\n",
    "#     \"subcortgrayvol\",\n",
    "#     \"totalgrayvol\",\n",
    "#     \"meanthickness_lh\",\n",
    "#     \"meanthickness_rh\",\n",
    "#     \"whitesurfarea_lh\",\n",
    "#     \"whitesurfarea_rh\"],\n",
    "#\n",
    "#     'subcortical_vol': [\n",
    "#     \"3rd_ventricle\",\n",
    "#     \"4th_ventricle\",\n",
    "#     \"5th_ventricle\",\n",
    "#     \"brain_stem\",\n",
    "#     \"cc_anterior\",\n",
    "#     \"cc_central\",\n",
    "#     \"cc_mid_anterior\",\n",
    "#     \"cc_mid_posterior\",\n",
    "#     \"cc_posterior\",\n",
    "#     \"csf\",\n",
    "#     \"left_accumbens_area\",\n",
    "#     \"left_amygdala\",\n",
    "#     \"left_caudate\",\n",
    "#     \"left_cerebellum_cortex\",\n",
    "#     \"left_cerebellum_white_matter\",\n",
    "#     \"left_choroid_plexus\",\n",
    "#     \"left_hippocampus\",\n",
    "#     \"left_inf_lat_vent\",\n",
    "#     \"left_lateral_ventricle\",\n",
    "#     \"left_non_wm_hypointensities\",\n",
    "#     \"left_pallidum\",\n",
    "#     \"left_putamen\",\n",
    "#     \"left_thalamus\",\n",
    "#     \"left_ventraldc\",\n",
    "#     \"left_vessel\",\n",
    "#     \"left_wm_hypointensities\",\n",
    "#     \"non_wm_hypointensities\",\n",
    "#     \"optic_chiasm\",\n",
    "#     \"right_accumbens_area\",\n",
    "#     \"right_amygdala\",\n",
    "#     \"right_caudate\",\n",
    "#     \"right_cerebellum_cortex\",\n",
    "#     \"right_cerebellum_white_matter\",\n",
    "#     \"right_choroid_plexus\",\n",
    "#     \"right_hippocampus\",\n",
    "#     \"right_inf_lat_vent\",\n",
    "#     \"right_lateral_ventricle\",\n",
    "#     \"right_non_wm_hypointensities\",\n",
    "#     \"right_pallidum\",\n",
    "#     \"right_putamen\",\n",
    "#     \"right_thalamus\",\n",
    "#     \"right_ventraldc\",\n",
    "#     \"right_vessel\",\n",
    "#     \"right_wm_hypointensities\",\n",
    "#     \"wm_hypointensities\"\n",
    "# ],\n",
    "#\n",
    "#     \"cortical_vol_lr\": [\n",
    "#     \"bankssts_lh\",\n",
    "#     \"bankssts_rh\",\n",
    "#     \"caudalanteriorcingulate_lh\",\n",
    "#     \"caudalanteriorcingulate_rh\",\n",
    "#     \"caudalmiddlefrontal_lh\",\n",
    "#     \"caudalmiddlefrontal_rh\",\n",
    "#     \"cuneus_lh\",\n",
    "#     \"cuneus_rh\",\n",
    "#     \"entorhinal_lh\",\n",
    "#     \"entorhinal_rh\",\n",
    "#     \"frontalpole_lh\",\n",
    "#     \"frontalpole_rh\",\n",
    "#     \"fusiform_lh\",\n",
    "#     \"fusiform_rh\",\n",
    "#     \"inferiorparietal_lh\",\n",
    "#     \"inferiorparietal_rh\",\n",
    "#     \"inferiortemporal_lh\",\n",
    "#     \"inferiortemporal_rh\",\n",
    "#     \"insula_lh\",\n",
    "#     \"insula_rh\",\n",
    "#     \"isthmuscingulate_lh\",\n",
    "#     \"isthmuscingulate_rh\",\n",
    "#     \"lateraloccipital_lh\",\n",
    "#     \"lateraloccipital_rh\",\n",
    "#     \"lateralorbitofrontal_lh\",\n",
    "#     \"lateralorbitofrontal_rh\",\n",
    "#     \"lingual_lh\",\n",
    "#     \"lingual_rh\",\n",
    "#     \"medialorbitofrontal_lh\",\n",
    "#     \"medialorbitofrontal_rh\",\n",
    "#     \"middletemporal_lh\",\n",
    "#     \"middletemporal_rh\",\n",
    "#     \"paracentral_lh\",\n",
    "#     \"paracentral_rh\",\n",
    "#     \"parahippocampal_lh\",\n",
    "#     \"parahippocampal_rh\",\n",
    "#     \"parsopercularis_lh\",\n",
    "#     \"parsopercularis_rh\",\n",
    "#     \"parsorbitalis_lh\",\n",
    "#     \"parsorbitalis_rh\",\n",
    "#     \"parstriangularis_lh\",\n",
    "#     \"parstriangularis_rh\",\n",
    "#     \"pericalcarine_lh\",\n",
    "#     \"pericalcarine_rh\",\n",
    "#     \"postcentral_lh\",\n",
    "#     \"postcentral_rh\",\n",
    "#     \"posteriorcingulate_lh\",\n",
    "#     \"posteriorcingulate_rh\",\n",
    "#     \"precentral_lh\",\n",
    "#     \"precentral_rh\",\n",
    "#     \"precuneus_lh\",\n",
    "#     \"precuneus_rh\",\n",
    "#     \"rostralanteriorcingulate_lh\",\n",
    "#     \"rostralanteriorcingulate_rh\",\n",
    "#     \"rostralmiddlefrontal_lh\",\n",
    "#     \"rostralmiddlefrontal_rh\",\n",
    "#     \"superiorfrontal_lh\",\n",
    "#     \"superiorfrontal_rh\",\n",
    "#     \"superiorparietal_lh\",\n",
    "#     \"superiorparietal_rh\",\n",
    "#     \"superiortemporal_lh\",\n",
    "#     \"superiortemporal_rh\",\n",
    "#     \"supramarginal_lh\",\n",
    "#     \"supramarginal_rh\",\n",
    "#     \"temporalpole_lh\",\n",
    "#     \"temporalpole_rh\",\n",
    "#     \"transversetemporal_lh\",\n",
    "#     \"transversetemporal_rh\"\n",
    "# ]\n",
    "# ,\n",
    "#     'cortical_lobes_lr': [\n",
    "#     \"Cingulate_lh\",\n",
    "#     \"Cingulate_rh\",\n",
    "#     \"Frontal_lh\",\n",
    "#     \"Frontal_rh\",\n",
    "#     \"Insula_lh\",\n",
    "#     \"Insula_rh\",\n",
    "#     \"Occipital_lh\",\n",
    "#     \"Occipital_rh\",\n",
    "#     \"Parietal_lh\",\n",
    "#     \"Parietal_rh\",\n",
    "#     \"Temporal_lh\",\n",
    "#     \"Temporal_rh\"\n",
    "# ],\n",
    "#\n",
    "#\n",
    "#     'cortical_lobes_full_brain': [\n",
    "#     \"cingulate\",\n",
    "#     \"frontal\",\n",
    "#     \"insula\",\n",
    "#     \"occipital\",\n",
    "#     \"parietal\",\n",
    "#     \"temporal\"\n",
    "# ],\n",
    "#     'cortical_networks_full_brain': [\n",
    "#     \"DMN_GM\",\n",
    "#     \"DA_GM\",\n",
    "#     \"FPN_GM\",\n",
    "#     \"LIM_GM\",\n",
    "#     \"SMN_GM\",\n",
    "#     \"VAN_GM\",\n",
    "#     \"VIS_GM\"\n",
    "# ]\n",
    "#\n",
    "# }\n",
    "# # ^^^ --- THIS IS THE PART YOU EDIT --- ^^^\n",
    "#\n",
    "#\n"
   ],
   "id": "4df746b29fcbe7a7",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-05T08:27:17.672172Z",
     "start_time": "2025-12-05T08:27:17.665964Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# \"\"\"\n",
    "# Main function to read CSV and write to a multi-sheet Excel file.\n",
    "# \"\"\"\n",
    "# try:\n",
    "#     # 1. Load the entire CSV into a pandas DataFrame\n",
    "#     print(f\"Reading input file: {INPUT_CSV_FILE}...\")\n",
    "#     main_df = pd.read_csv(INPUT_CSV_FILE)\n",
    "#     print(\"CSV file loaded successfully.\")\n",
    "#\n",
    "#     # Build a case-insensitive mapping: lower_name -> original_name\n",
    "#     col_map = {c.lower(): c for c in main_df.columns}\n",
    "#\n",
    "#     # 2. Check that the key column exists (case-insensitive)\n",
    "#     key_lower = KEY_COLUMN.lower()\n",
    "#     if key_lower not in col_map:\n",
    "#         print(f\"Error: The key column '{KEY_COLUMN}' was not found in the CSV (case-insensitive search).\")\n",
    "#         print(\"Please check the KEY_COLUMN variable.\")\n",
    "#         print(f\"Available columns are: {main_df.columns.tolist()}\")\n",
    "#         sys.exit(1)\n",
    "#\n",
    "#     key_actual = col_map[key_lower]  # actual column name in the DataFrame\n",
    "#\n",
    "#     # 3. Create an ExcelWriter object to handle writing to multiple sheets\n",
    "#     with pd.ExcelWriter(OUTPUT_EXCEL_FILE, engine='openpyxl') as writer:\n",
    "#         print(f\"Creating Excel file: {OUTPUT_EXCEL_FILE}...\")\n",
    "#\n",
    "#         # 4. Loop through your configuration\n",
    "#         for sheet_name, column_list in SHEETS_TO_CREATE.items():\n",
    "#\n",
    "#             # 5. Build the final list of columns for this sheet\n",
    "#             final_columns = []\n",
    "#\n",
    "#             # Check if key column is already in the list (case-insensitive)\n",
    "#             column_list_lower = [c.lower() for c in column_list]\n",
    "#             if key_lower not in column_list_lower:\n",
    "#                 final_columns.append(KEY_COLUMN)   # we'll resolve to real name below\n",
    "#\n",
    "#             final_columns.extend(column_list)\n",
    "#\n",
    "#             # 6. Check for missing columns and create the sheet DataFrame\n",
    "#             valid_columns = []\n",
    "#             seen_lowers = set()  # to avoid duplicates with different cases\n",
    "#\n",
    "#             for col in final_columns:\n",
    "#                 col_lower = col.lower()\n",
    "#                 if col_lower in seen_lowers:\n",
    "#                     continue  # skip duplicates\n",
    "#                 if col_lower in col_map:\n",
    "#                     valid_columns.append(col_map[col_lower])  # use actual name from CSV\n",
    "#                     seen_lowers.add(col_lower)\n",
    "#                 else:\n",
    "#                     print(f\"  - Warning: Column '{col}' (for sheet '{sheet_name}') \"\n",
    "#                           f\"not found in CSV (case-insensitive). It will be skipped.\")\n",
    "#\n",
    "#             if not valid_columns:\n",
    "#                 print(f\"  - Error: No valid columns found for sheet '{sheet_name}'. \"\n",
    "#                       f\"This sheet will be empty or skipped.\")\n",
    "#                 continue\n",
    "#\n",
    "#             # 7. Create the new DataFrame for this sheet\n",
    "#             sheet_df = main_df[valid_columns]\n",
    "#\n",
    "#             # 8. Write this DataFrame to the Excel file\n",
    "#             sheet_df.to_excel(writer, sheet_name=sheet_name, index=False)\n",
    "#             print(f\"  -> Successfully created sheet: '{sheet_name}' with {len(valid_columns)} columns.\")\n",
    "#\n",
    "#     print(f\"\\nAll done! Your file '{OUTPUT_EXCEL_FILE}' has been created.\")\n",
    "#\n",
    "# except FileNotFoundError:\n",
    "#     print(f\"Error: The file '{INPUT_CSV_FILE}' was not found.\")\n",
    "#     print(\"Please make sure the CSV file is in the same directory as this script.\")\n",
    "# except Exception as e:\n",
    "#     print(f\"An unexpected error occurred: {e}\")\n"
   ],
   "id": "9bb88a6c8a6961c4",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# functions",
   "id": "3e0816d217670a8d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-05T08:27:17.702027Z",
     "start_time": "2025-12-05T08:27:17.695981Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def collect_files(folder: Path, recursive: bool = False):\n",
    "    if recursive:\n",
    "        return [p for p in folder.rglob(\"*.xlsx\") if p.is_file()]\n",
    "    return [p for p in folder.iterdir() if p.is_file() and p.suffix.lower() == \".xlsx\"]\n"
   ],
   "id": "55c78a624065a74a",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-05T08:27:17.725041Z",
     "start_time": "2025-12-05T08:27:17.719041Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "def list_excel_files(folder: Path, recursive: bool = False):\n",
    "    if recursive:\n",
    "        return sorted([p for p in folder.rglob(\"*.xlsx\") if p.is_file()])\n",
    "    return sorted([p for p in folder.iterdir() if p.is_file() and p.suffix.lower() == \".xlsx\"])\n",
    "\n"
   ],
   "id": "e05dd3622b1dc561",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-05T08:27:17.742753Z",
     "start_time": "2025-12-05T08:27:17.736608Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def pick_column(df: pd.DataFrame, candidates):\n",
    "    \"\"\"Return the first matching column name in df (case-insensitive), else None.\"\"\"\n",
    "    cols_map = {c.lower(): c for c in df.columns}\n",
    "    for c in candidates:\n",
    "        if c.lower() in cols_map:\n",
    "            return cols_map[c.lower()]\n",
    "    # try partial matches (e.g., \"grayvol\" inside \"grayvol (mm3)\")\n",
    "    for c in candidates:\n",
    "        for k, v in cols_map.items():\n",
    "            if c.lower() in k:\n",
    "                return v\n",
    "    return None\n"
   ],
   "id": "31d03ed7dd7ebe61",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-05T08:27:17.763910Z",
     "start_time": "2025-12-05T08:27:17.758914Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def slugify(name: str) -> str:\n",
    "    \"\"\"lowercase + replace non-alnum with underscores + collapse repeats.\"\"\"\n",
    "    s = re.sub(r\"\\W+\", \"_\", str(name).strip().lower())\n",
    "    s = re.sub(r\"_+\", \"_\", s).strip(\"_\")\n",
    "    return s"
   ],
   "id": "676783dba8aeee02",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-05T08:27:17.781258Z",
     "start_time": "2025-12-05T08:27:17.775978Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create a stable, pretty column order:\n",
    "#   subject_code first, then all lh/rh ses1 followed by ses2 (alphabetical by struct)\n",
    "def col_sort_key(c):\n",
    "    # subject_code stays first\n",
    "    if c == \"subject_code\":\n",
    "        return (0, \"\", \"\", 0)\n",
    "    # parse pattern: <struct>_<hemi>_ses<1|2>\n",
    "    m = re.match(r\"^(.*)_(lh|rh)_ses([12])$\", c)\n",
    "    if m:\n",
    "        struct, hemi, ses = m.group(1), m.group(2), int(m.group(3))\n",
    "        return (1, struct, hemi, ses)\n",
    "    # anything unexpected goes to the end\n",
    "    return (2, c, \"\", 99)"
   ],
   "id": "5c6c0b609fdc9208",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-05T08:27:17.804138Z",
     "start_time": "2025-12-05T08:27:17.799140Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def merge_two_cols(dframe, cols, how=\"sum\"):\n",
    "    # cols is a list of existing columns (1 or 2). We want:\n",
    "    # - NaN if both missing\n",
    "    # - sum/mean ignoring NaNs otherwise\n",
    "    cols = [c for c in cols if c is not None and c in dframe.columns]\n",
    "    if not cols:\n",
    "        return pd.Series(np.nan, index=dframe.index)\n",
    "    if how == \"mean\":\n",
    "        return dframe[cols].mean(axis=1)\n",
    "    # default sum\n",
    "    return dframe[cols].sum(axis=1, min_count=1)\n"
   ],
   "id": "6a08d1d12b64940a",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-05T08:27:17.820853Z",
     "start_time": "2025-12-05T08:27:17.815484Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def reduce_cols(dframe, cols, how=\"sum\"):\n",
    "    cols = [c for c in cols if c in dframe.columns]\n",
    "    if not cols:\n",
    "        return pd.Series(np.nan, index=dframe.index)\n",
    "    return dframe[cols].sum(axis=1, min_count=1)"
   ],
   "id": "67116c40bc109a7b",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-05T08:27:17.845080Z",
     "start_time": "2025-12-05T08:27:17.839085Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# --- 4) Order columns nicely: subject_code, then lobe alpha, ses1 before ses2, lh before rh\n",
    "def order_key_lobe(c):\n",
    "    if c == \"subject_code\":\n",
    "        return (0, \"\", 0, \"\")\n",
    "    m = re.match(r\"^(?P<lobe>.+)_(?P<hemi>lh|rh)_ses(?P<ses>\\d+)$\", c)\n",
    "    if m:\n",
    "        lobe = m.group(\"lobe\")\n",
    "        hemi = m.group(\"hemi\")\n",
    "        ses  = int(m.group(\"ses\"))\n",
    "        hemi_order = 0 if hemi == \"lh\" else 1\n",
    "        return (1, lobe, ses, hemi_order)\n",
    "    return (2, c, 99, 99)\n"
   ],
   "id": "7ead2c8a9b7d15a7",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-05T08:27:17.864948Z",
     "start_time": "2025-12-05T08:27:17.858749Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def _read_csv(path: Path, merge_key: str) -> pd.DataFrame:\n",
    "    if not path.exists():\n",
    "        print(f\"WARNING: file not found -> {path}\")\n",
    "        return pd.DataFrame(columns=[merge_key])\n",
    "    df = pd.read_csv(path)\n",
    "    # normalize key dtype for safe merging/sorting\n",
    "    if merge_key in df.columns:\n",
    "        df[merge_key] = df[merge_key].astype(str)\n",
    "    return df\n",
    "\n"
   ],
   "id": "160933e0e621478c",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-05T08:27:17.887052Z",
     "start_time": "2025-12-05T08:27:17.881983Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def _order_columns_subject_first(df: pd.DataFrame, key: str = \"subject_code\") -> pd.DataFrame:\n",
    "    cols = list(df.columns)\n",
    "    if key in cols:\n",
    "        return df[[key] + [c for c in cols if c != key]]\n",
    "    return df"
   ],
   "id": "8f58dbcb089ecddc",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-05T08:27:17.904753Z",
     "start_time": "2025-12-05T08:27:17.898657Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def _sort_consistent(df: pd.DataFrame, key: str = \"subject_code\") -> pd.DataFrame:\n",
    "    \"\"\"Alphabetical by key; if numbers exist, use them as a secondary natural sort.\"\"\"\n",
    "    if key not in df.columns:\n",
    "        return df\n",
    "    key_series = df[key].astype(str)\n",
    "    # Extract first number if present; fall back to NaN\n",
    "    num = key_series.str.extract(r\"(\\d+)\")[0].astype(float)\n",
    "    # Primary: alphabetical by key; Secondary: numeric ascending (NaN last)\n",
    "    return (df.assign(_num=num)\n",
    "              .sort_values(by=[key, \"_num\"], kind=\"mergesort\")\n",
    "              .drop(columns=\"_num\"))\n"
   ],
   "id": "b46bdc5d167286b8",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-05T08:27:17.930169Z",
     "start_time": "2025-12-05T08:27:17.923173Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def _autosize_columns(writer: pd.ExcelWriter, df: pd.DataFrame, sheet_name: str, max_width: int = 60):\n",
    "    \"\"\"Best-effort autosize; harmless no-op if engine doesn't support.\"\"\"\n",
    "    try:\n",
    "        ws = writer.sheets[sheet_name]\n",
    "        for idx, col in enumerate(df.columns, 1):\n",
    "            s = df[col].astype(str)\n",
    "            longest = max([len(str(col))] + [len(x) for x in s.tolist()] + [10])\n",
    "            ws.column_dimensions[ws.cell(row=1, column=idx).column_letter].width = min(longest + 2, max_width)\n",
    "    except Exception:\n",
    "        pass"
   ],
   "id": "35b75b6006f850c0",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-05T08:27:17.949558Z",
     "start_time": "2025-12-05T08:27:17.943508Z"
    }
   },
   "cell_type": "code",
   "source": [
    "records = []\n",
    "sheet_names_ref = None\n",
    "# --- CONFIG --- #\n",
    "FOLDER = Path(\"data/stats_t1_fs\")  # change to your folder\n",
    "SUMMARY_CSV = Path(\"data/stats_t1_fs/ses1_and_ses2_T1_summary.csv\")  # change if you want\n",
    "RECURSIVE = False  # set True if files are in subfolders\n",
    "# --------------- #\n"
   ],
   "id": "f8574c0b5df94989",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# first session",
   "id": "4bd79afac7aa68e3"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## extracting from the subject file the cortical volumes and merge nto one csv file",
   "id": "885388ebfc85963a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-05T08:27:22.912644Z",
     "start_time": "2025-12-05T08:27:17.979022Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# ---------- CONFIG ----------\n",
    "FOLDER = Path(\"data/stats_t1_fs\")  # change to your folder\n",
    "OUT_CSV = Path(\"data/stats_t1_fs/ses1/ses1_aparc_voxels_lh_rh.csv\")  # output file\n",
    "SHEET_NAME = \"aparc_voxels\"  # sheet to read\n",
    "RECURSIVE = False            # set True if files are in subfolders\n",
    "# ----------------------------\n",
    "\n",
    "file_regex = re.compile(\n",
    "    r\"sub-(?P<subject>\\d{3})_(?P<group>CT|NT)_ses-(?P<session>[12])_merged\\.xlsx$\",\n",
    "    re.IGNORECASE,\n",
    ")\n",
    "\n",
    "# Accumulate rows keyed by subject_code\n",
    "rows_by_subject = {}\n",
    "all_feature_cols = set()\n",
    "files = list_excel_files(FOLDER, RECURSIVE)\n",
    "for path in files:\n",
    "    print(\"FULL PATH :\", repr(str(path)))\n",
    "    print(\"NAME ONLY :\", repr(path.name))\n",
    "    m = file_regex.match(path.name)\n",
    "    print(m)\n",
    "    if not m:\n",
    "        continue\n",
    "\n",
    "    subject = m.group(\"subject\")\n",
    "    group = m.group(\"group\").upper()\n",
    "    session = int(m.group(\"session\"))\n",
    "    print(session)\n",
    "\n",
    "    # --- ONLY PROCESS SESSION 1 ---\n",
    "    if session != 1:\n",
    "        continue\n",
    "\n",
    "    subject_code = f\"{group}{subject}\"\n",
    "\n",
    "    try:\n",
    "        df = pd.read_excel(path, sheet_name=SHEET_NAME)\n",
    "    except Exception as e:\n",
    "        print(f\"Warning: couldn't read sheet '{SHEET_NAME}' in {path.name}: {e}\")\n",
    "        continue\n",
    "\n",
    "    # Locate columns\n",
    "    col_struct = pick_column(df, [\"StructName\"])\n",
    "    col_hemi   = pick_column(df, [\"Hemisphere\"])\n",
    "    col_gray   = pick_column(df, [\"GrayVol\"])\n",
    "\n",
    "    if not all([col_struct, col_hemi, col_gray]):\n",
    "        print(f\"Warning: missing needed columns in {path.name}. \"\n",
    "              f\"StructName={col_struct}, Hemisphere={col_hemi}, GrayVol={col_gray}\")\n",
    "        continue\n",
    "\n",
    "    # Initialize row\n",
    "    if subject_code not in rows_by_subject:\n",
    "        rows_by_subject[subject_code] = {\"subject_code\": subject_code}\n",
    "\n",
    "    # Process rows\n",
    "    for _, row in df.iterrows():\n",
    "        struct = slugify(row[col_struct])\n",
    "        hemi = slugify(row[col_hemi])\n",
    "\n",
    "        if hemi in (\"left\", \"l\"): hemi = \"lh\"\n",
    "        if hemi in (\"right\", \"r\"): hemi = \"rh\"\n",
    "\n",
    "        if not struct or hemi not in (\"lh\", \"rh\"):\n",
    "            continue\n",
    "\n",
    "        # --- NEW: COLUMN NAME WITHOUT SESSION ---\n",
    "        col_name = f\"{struct}_{hemi}\"\n",
    "\n",
    "        # Convert to numeric\n",
    "        val = row[col_gray]\n",
    "        try:\n",
    "            val = pd.to_numeric(val)\n",
    "        except:\n",
    "            val = np.nan\n",
    "\n",
    "        rows_by_subject[subject_code][col_name] = val\n",
    "        all_feature_cols.add(col_name)\n",
    "\n",
    "all_columns = [\"subject_code\"] + sorted(all_feature_cols, key=col_sort_key)\n",
    "\n",
    "# Build DataFrame\n",
    "df_out = pd.DataFrame(rows_by_subject.values())\n",
    "for c in all_columns:\n",
    "    if c not in df_out.columns:\n",
    "        df_out[c] = np.nan\n",
    "df_out = df_out[all_columns]\n",
    "\n",
    "# Save\n",
    "OUT_CSV.parent.mkdir(parents=True, exist_ok=True)\n",
    "df_out.to_csv(OUT_CSV, index=False)\n",
    "\n",
    "print(f\"Saved: {OUT_CSV}\")\n",
    "display(df_out.head(5))\n",
    "\n"
   ],
   "id": "9f7b0a03850ec10b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FULL PATH : 'data\\\\stats_t1_fs\\\\mapping_lobes_networks.xlsx'\n",
      "NAME ONLY : 'mapping_lobes_networks.xlsx'\n",
      "None\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-002_CT_ses-1_merged.xlsx'\n",
      "NAME ONLY : 'sub-002_CT_ses-1_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-002_CT_ses-1_merged.xlsx'>\n",
      "1\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-002_NT_ses-1_merged.xlsx'\n",
      "NAME ONLY : 'sub-002_NT_ses-1_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-002_NT_ses-1_merged.xlsx'>\n",
      "1\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-002_NT_ses-2_merged.xlsx'\n",
      "NAME ONLY : 'sub-002_NT_ses-2_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-002_NT_ses-2_merged.xlsx'>\n",
      "2\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-003_CT_ses-1_merged.xlsx'\n",
      "NAME ONLY : 'sub-003_CT_ses-1_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-003_CT_ses-1_merged.xlsx'>\n",
      "1\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-003_CT_ses-2_merged.xlsx'\n",
      "NAME ONLY : 'sub-003_CT_ses-2_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-003_CT_ses-2_merged.xlsx'>\n",
      "2\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-003_NT_ses-1_merged.xlsx'\n",
      "NAME ONLY : 'sub-003_NT_ses-1_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-003_NT_ses-1_merged.xlsx'>\n",
      "1\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-004_CT_ses-1_merged.xlsx'\n",
      "NAME ONLY : 'sub-004_CT_ses-1_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-004_CT_ses-1_merged.xlsx'>\n",
      "1\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-005_CT_ses-1_merged.xlsx'\n",
      "NAME ONLY : 'sub-005_CT_ses-1_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-005_CT_ses-1_merged.xlsx'>\n",
      "1\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-005_NT_ses-1_merged.xlsx'\n",
      "NAME ONLY : 'sub-005_NT_ses-1_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-005_NT_ses-1_merged.xlsx'>\n",
      "1\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-005_NT_ses-2_merged.xlsx'\n",
      "NAME ONLY : 'sub-005_NT_ses-2_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-005_NT_ses-2_merged.xlsx'>\n",
      "2\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-006_NT_ses-1_merged.xlsx'\n",
      "NAME ONLY : 'sub-006_NT_ses-1_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-006_NT_ses-1_merged.xlsx'>\n",
      "1\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-007_CT_ses-1_merged.xlsx'\n",
      "NAME ONLY : 'sub-007_CT_ses-1_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-007_CT_ses-1_merged.xlsx'>\n",
      "1\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-007_CT_ses-2_merged.xlsx'\n",
      "NAME ONLY : 'sub-007_CT_ses-2_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-007_CT_ses-2_merged.xlsx'>\n",
      "2\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-007_NT_ses-1_merged.xlsx'\n",
      "NAME ONLY : 'sub-007_NT_ses-1_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-007_NT_ses-1_merged.xlsx'>\n",
      "1\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-008_CT_ses-1_merged.xlsx'\n",
      "NAME ONLY : 'sub-008_CT_ses-1_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-008_CT_ses-1_merged.xlsx'>\n",
      "1\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-010_CT_ses-1_merged.xlsx'\n",
      "NAME ONLY : 'sub-010_CT_ses-1_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-010_CT_ses-1_merged.xlsx'>\n",
      "1\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-010_CT_ses-2_merged.xlsx'\n",
      "NAME ONLY : 'sub-010_CT_ses-2_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-010_CT_ses-2_merged.xlsx'>\n",
      "2\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-010_NT_ses-1_merged.xlsx'\n",
      "NAME ONLY : 'sub-010_NT_ses-1_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-010_NT_ses-1_merged.xlsx'>\n",
      "1\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-012_CT_ses-1_merged.xlsx'\n",
      "NAME ONLY : 'sub-012_CT_ses-1_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-012_CT_ses-1_merged.xlsx'>\n",
      "1\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-012_CT_ses-2_merged.xlsx'\n",
      "NAME ONLY : 'sub-012_CT_ses-2_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-012_CT_ses-2_merged.xlsx'>\n",
      "2\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-013_CT_ses-1_merged.xlsx'\n",
      "NAME ONLY : 'sub-013_CT_ses-1_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-013_CT_ses-1_merged.xlsx'>\n",
      "1\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-013_CT_ses-2_merged.xlsx'\n",
      "NAME ONLY : 'sub-013_CT_ses-2_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-013_CT_ses-2_merged.xlsx'>\n",
      "2\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-013_NT_ses-1_merged.xlsx'\n",
      "NAME ONLY : 'sub-013_NT_ses-1_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-013_NT_ses-1_merged.xlsx'>\n",
      "1\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-015_CT_ses-1_merged.xlsx'\n",
      "NAME ONLY : 'sub-015_CT_ses-1_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-015_CT_ses-1_merged.xlsx'>\n",
      "1\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-015_NT_ses-1_merged.xlsx'\n",
      "NAME ONLY : 'sub-015_NT_ses-1_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-015_NT_ses-1_merged.xlsx'>\n",
      "1\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-015_NT_ses-2_merged.xlsx'\n",
      "NAME ONLY : 'sub-015_NT_ses-2_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-015_NT_ses-2_merged.xlsx'>\n",
      "2\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-015_NT_ses-3_merged.xlsx'\n",
      "NAME ONLY : 'sub-015_NT_ses-3_merged.xlsx'\n",
      "None\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-016_CT_ses-1_merged.xlsx'\n",
      "NAME ONLY : 'sub-016_CT_ses-1_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-016_CT_ses-1_merged.xlsx'>\n",
      "1\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-016_NT_ses-1_merged.xlsx'\n",
      "NAME ONLY : 'sub-016_NT_ses-1_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-016_NT_ses-1_merged.xlsx'>\n",
      "1\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-016_NT_ses-2_merged.xlsx'\n",
      "NAME ONLY : 'sub-016_NT_ses-2_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-016_NT_ses-2_merged.xlsx'>\n",
      "2\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-017_CT_ses-1_merged.xlsx'\n",
      "NAME ONLY : 'sub-017_CT_ses-1_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-017_CT_ses-1_merged.xlsx'>\n",
      "1\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-017_NT_ses-1_merged.xlsx'\n",
      "NAME ONLY : 'sub-017_NT_ses-1_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-017_NT_ses-1_merged.xlsx'>\n",
      "1\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-017_NT_ses-2_merged.xlsx'\n",
      "NAME ONLY : 'sub-017_NT_ses-2_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-017_NT_ses-2_merged.xlsx'>\n",
      "2\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-018_CT_ses-1_merged.xlsx'\n",
      "NAME ONLY : 'sub-018_CT_ses-1_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-018_CT_ses-1_merged.xlsx'>\n",
      "1\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-018_CT_ses-2_merged.xlsx'\n",
      "NAME ONLY : 'sub-018_CT_ses-2_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-018_CT_ses-2_merged.xlsx'>\n",
      "2\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-019_NT_ses-1_merged.xlsx'\n",
      "NAME ONLY : 'sub-019_NT_ses-1_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-019_NT_ses-1_merged.xlsx'>\n",
      "1\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-020_CT_ses-1_merged.xlsx'\n",
      "NAME ONLY : 'sub-020_CT_ses-1_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-020_CT_ses-1_merged.xlsx'>\n",
      "1\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-020_NT_ses-1_merged.xlsx'\n",
      "NAME ONLY : 'sub-020_NT_ses-1_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-020_NT_ses-1_merged.xlsx'>\n",
      "1\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-020_NT_ses-2_merged.xlsx'\n",
      "NAME ONLY : 'sub-020_NT_ses-2_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-020_NT_ses-2_merged.xlsx'>\n",
      "2\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-021_CT_ses-1_merged.xlsx'\n",
      "NAME ONLY : 'sub-021_CT_ses-1_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-021_CT_ses-1_merged.xlsx'>\n",
      "1\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-023_CT_ses-1_merged.xlsx'\n",
      "NAME ONLY : 'sub-023_CT_ses-1_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-023_CT_ses-1_merged.xlsx'>\n",
      "1\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-024_CT_ses-1_merged.xlsx'\n",
      "NAME ONLY : 'sub-024_CT_ses-1_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-024_CT_ses-1_merged.xlsx'>\n",
      "1\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-025_CT_ses-1_merged.xlsx'\n",
      "NAME ONLY : 'sub-025_CT_ses-1_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-025_CT_ses-1_merged.xlsx'>\n",
      "1\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-025_NT_ses-1_merged.xlsx'\n",
      "NAME ONLY : 'sub-025_NT_ses-1_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-025_NT_ses-1_merged.xlsx'>\n",
      "1\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-025_NT_ses-2_merged.xlsx'\n",
      "NAME ONLY : 'sub-025_NT_ses-2_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-025_NT_ses-2_merged.xlsx'>\n",
      "2\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-026_CT_ses-1_merged.xlsx'\n",
      "NAME ONLY : 'sub-026_CT_ses-1_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-026_CT_ses-1_merged.xlsx'>\n",
      "1\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-026_NT_ses-1_merged.xlsx'\n",
      "NAME ONLY : 'sub-026_NT_ses-1_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-026_NT_ses-1_merged.xlsx'>\n",
      "1\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-026_NT_ses-2_merged.xlsx'\n",
      "NAME ONLY : 'sub-026_NT_ses-2_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-026_NT_ses-2_merged.xlsx'>\n",
      "2\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-027_CT_ses-1_merged.xlsx'\n",
      "NAME ONLY : 'sub-027_CT_ses-1_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-027_CT_ses-1_merged.xlsx'>\n",
      "1\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-027_CT_ses-2_merged.xlsx'\n",
      "NAME ONLY : 'sub-027_CT_ses-2_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-027_CT_ses-2_merged.xlsx'>\n",
      "2\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-027_NT_ses-1_merged.xlsx'\n",
      "NAME ONLY : 'sub-027_NT_ses-1_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-027_NT_ses-1_merged.xlsx'>\n",
      "1\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-027_NT_ses-2_merged.xlsx'\n",
      "NAME ONLY : 'sub-027_NT_ses-2_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-027_NT_ses-2_merged.xlsx'>\n",
      "2\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-028_CT_ses-1_merged.xlsx'\n",
      "NAME ONLY : 'sub-028_CT_ses-1_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-028_CT_ses-1_merged.xlsx'>\n",
      "1\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-028_NT_ses-1_merged.xlsx'\n",
      "NAME ONLY : 'sub-028_NT_ses-1_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-028_NT_ses-1_merged.xlsx'>\n",
      "1\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-029_CT_ses-1_merged.xlsx'\n",
      "NAME ONLY : 'sub-029_CT_ses-1_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-029_CT_ses-1_merged.xlsx'>\n",
      "1\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-029_CT_ses-2_merged.xlsx'\n",
      "NAME ONLY : 'sub-029_CT_ses-2_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-029_CT_ses-2_merged.xlsx'>\n",
      "2\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-029_NT_ses-1_merged.xlsx'\n",
      "NAME ONLY : 'sub-029_NT_ses-1_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-029_NT_ses-1_merged.xlsx'>\n",
      "1\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-030_CT_ses-1_merged.xlsx'\n",
      "NAME ONLY : 'sub-030_CT_ses-1_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-030_CT_ses-1_merged.xlsx'>\n",
      "1\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-030_NT_ses-1_merged.xlsx'\n",
      "NAME ONLY : 'sub-030_NT_ses-1_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-030_NT_ses-1_merged.xlsx'>\n",
      "1\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-031_NT_ses-1_merged.xlsx'\n",
      "NAME ONLY : 'sub-031_NT_ses-1_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-031_NT_ses-1_merged.xlsx'>\n",
      "1\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-031_NT_ses-2_merged.xlsx'\n",
      "NAME ONLY : 'sub-031_NT_ses-2_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-031_NT_ses-2_merged.xlsx'>\n",
      "2\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-032_CT_ses-1_merged.xlsx'\n",
      "NAME ONLY : 'sub-032_CT_ses-1_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-032_CT_ses-1_merged.xlsx'>\n",
      "1\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-032_CT_ses-2_merged.xlsx'\n",
      "NAME ONLY : 'sub-032_CT_ses-2_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-032_CT_ses-2_merged.xlsx'>\n",
      "2\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-032_NT_ses-1_merged.xlsx'\n",
      "NAME ONLY : 'sub-032_NT_ses-1_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-032_NT_ses-1_merged.xlsx'>\n",
      "1\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-033_CT_ses-1_merged.xlsx'\n",
      "NAME ONLY : 'sub-033_CT_ses-1_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-033_CT_ses-1_merged.xlsx'>\n",
      "1\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-033_NT_ses-1_merged.xlsx'\n",
      "NAME ONLY : 'sub-033_NT_ses-1_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-033_NT_ses-1_merged.xlsx'>\n",
      "1\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-033_NT_ses-2_merged.xlsx'\n",
      "NAME ONLY : 'sub-033_NT_ses-2_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-033_NT_ses-2_merged.xlsx'>\n",
      "2\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-034_CT_ses-1_merged.xlsx'\n",
      "NAME ONLY : 'sub-034_CT_ses-1_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-034_CT_ses-1_merged.xlsx'>\n",
      "1\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-035_CT_ses-1_merged.xlsx'\n",
      "NAME ONLY : 'sub-035_CT_ses-1_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-035_CT_ses-1_merged.xlsx'>\n",
      "1\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-035_NT_ses-1_merged.xlsx'\n",
      "NAME ONLY : 'sub-035_NT_ses-1_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-035_NT_ses-1_merged.xlsx'>\n",
      "1\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-036_NT_ses-1_merged.xlsx'\n",
      "NAME ONLY : 'sub-036_NT_ses-1_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-036_NT_ses-1_merged.xlsx'>\n",
      "1\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-036_NT_ses-2_merged.xlsx'\n",
      "NAME ONLY : 'sub-036_NT_ses-2_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-036_NT_ses-2_merged.xlsx'>\n",
      "2\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-038_NT_ses-1_merged.xlsx'\n",
      "NAME ONLY : 'sub-038_NT_ses-1_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-038_NT_ses-1_merged.xlsx'>\n",
      "1\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-039_CT_ses-1_merged.xlsx'\n",
      "NAME ONLY : 'sub-039_CT_ses-1_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-039_CT_ses-1_merged.xlsx'>\n",
      "1\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-039_CT_ses-2_merged.xlsx'\n",
      "NAME ONLY : 'sub-039_CT_ses-2_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-039_CT_ses-2_merged.xlsx'>\n",
      "2\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-039_NT_ses-1_merged.xlsx'\n",
      "NAME ONLY : 'sub-039_NT_ses-1_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-039_NT_ses-1_merged.xlsx'>\n",
      "1\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-040_NT_ses-1_merged.xlsx'\n",
      "NAME ONLY : 'sub-040_NT_ses-1_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-040_NT_ses-1_merged.xlsx'>\n",
      "1\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-040_NT_ses-2_merged.xlsx'\n",
      "NAME ONLY : 'sub-040_NT_ses-2_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-040_NT_ses-2_merged.xlsx'>\n",
      "2\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-041_CT_ses-1_merged.xlsx'\n",
      "NAME ONLY : 'sub-041_CT_ses-1_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-041_CT_ses-1_merged.xlsx'>\n",
      "1\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-041_CT_ses-2_merged.xlsx'\n",
      "NAME ONLY : 'sub-041_CT_ses-2_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-041_CT_ses-2_merged.xlsx'>\n",
      "2\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-041_NT_ses-1_merged.xlsx'\n",
      "NAME ONLY : 'sub-041_NT_ses-1_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-041_NT_ses-1_merged.xlsx'>\n",
      "1\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-041_NT_ses-2_merged.xlsx'\n",
      "NAME ONLY : 'sub-041_NT_ses-2_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-041_NT_ses-2_merged.xlsx'>\n",
      "2\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-042_CT_ses-1_merged.xlsx'\n",
      "NAME ONLY : 'sub-042_CT_ses-1_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-042_CT_ses-1_merged.xlsx'>\n",
      "1\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-042_NT_ses-1_merged.xlsx'\n",
      "NAME ONLY : 'sub-042_NT_ses-1_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-042_NT_ses-1_merged.xlsx'>\n",
      "1\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-043_CT_ses-1_merged.xlsx'\n",
      "NAME ONLY : 'sub-043_CT_ses-1_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-043_CT_ses-1_merged.xlsx'>\n",
      "1\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-043_CT_ses-2_merged.xlsx'\n",
      "NAME ONLY : 'sub-043_CT_ses-2_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-043_CT_ses-2_merged.xlsx'>\n",
      "2\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-043_NT_ses-1_merged.xlsx'\n",
      "NAME ONLY : 'sub-043_NT_ses-1_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-043_NT_ses-1_merged.xlsx'>\n",
      "1\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-044_NT_ses-1_merged.xlsx'\n",
      "NAME ONLY : 'sub-044_NT_ses-1_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-044_NT_ses-1_merged.xlsx'>\n",
      "1\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-044_NT_ses-2_merged.xlsx'\n",
      "NAME ONLY : 'sub-044_NT_ses-2_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-044_NT_ses-2_merged.xlsx'>\n",
      "2\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-046_CT_ses-1_merged.xlsx'\n",
      "NAME ONLY : 'sub-046_CT_ses-1_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-046_CT_ses-1_merged.xlsx'>\n",
      "1\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-046_CT_ses-2_merged.xlsx'\n",
      "NAME ONLY : 'sub-046_CT_ses-2_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-046_CT_ses-2_merged.xlsx'>\n",
      "2\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-047_NT_ses-1_merged.xlsx'\n",
      "NAME ONLY : 'sub-047_NT_ses-1_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-047_NT_ses-1_merged.xlsx'>\n",
      "1\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-047_NT_ses-2_merged.xlsx'\n",
      "NAME ONLY : 'sub-047_NT_ses-2_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-047_NT_ses-2_merged.xlsx'>\n",
      "2\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-047_NT_ses-3_merged.xlsx'\n",
      "NAME ONLY : 'sub-047_NT_ses-3_merged.xlsx'\n",
      "None\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-048_NT_ses-1_merged.xlsx'\n",
      "NAME ONLY : 'sub-048_NT_ses-1_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-048_NT_ses-1_merged.xlsx'>\n",
      "1\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-049_NT_ses-1_merged.xlsx'\n",
      "NAME ONLY : 'sub-049_NT_ses-1_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-049_NT_ses-1_merged.xlsx'>\n",
      "1\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-049_NT_ses-2_merged.xlsx'\n",
      "NAME ONLY : 'sub-049_NT_ses-2_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-049_NT_ses-2_merged.xlsx'>\n",
      "2\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-051_CT_ses-1_merged.xlsx'\n",
      "NAME ONLY : 'sub-051_CT_ses-1_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-051_CT_ses-1_merged.xlsx'>\n",
      "1\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-051_NT_ses-1_merged.xlsx'\n",
      "NAME ONLY : 'sub-051_NT_ses-1_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-051_NT_ses-1_merged.xlsx'>\n",
      "1\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-051_NT_ses-2_merged.xlsx'\n",
      "NAME ONLY : 'sub-051_NT_ses-2_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-051_NT_ses-2_merged.xlsx'>\n",
      "2\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-052_NT_ses-1_merged.xlsx'\n",
      "NAME ONLY : 'sub-052_NT_ses-1_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-052_NT_ses-1_merged.xlsx'>\n",
      "1\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-053_NT_ses-1_merged.xlsx'\n",
      "NAME ONLY : 'sub-053_NT_ses-1_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-053_NT_ses-1_merged.xlsx'>\n",
      "1\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-055_NT_ses-1_merged.xlsx'\n",
      "NAME ONLY : 'sub-055_NT_ses-1_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-055_NT_ses-1_merged.xlsx'>\n",
      "1\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-056_CT_ses-1_merged.xlsx'\n",
      "NAME ONLY : 'sub-056_CT_ses-1_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-056_CT_ses-1_merged.xlsx'>\n",
      "1\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-056_NT_ses-1_merged.xlsx'\n",
      "NAME ONLY : 'sub-056_NT_ses-1_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-056_NT_ses-1_merged.xlsx'>\n",
      "1\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-056_NT_ses-2_merged.xlsx'\n",
      "NAME ONLY : 'sub-056_NT_ses-2_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-056_NT_ses-2_merged.xlsx'>\n",
      "2\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-057_CT_ses-1_merged.xlsx'\n",
      "NAME ONLY : 'sub-057_CT_ses-1_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-057_CT_ses-1_merged.xlsx'>\n",
      "1\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-057_NT_ses-1_merged.xlsx'\n",
      "NAME ONLY : 'sub-057_NT_ses-1_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-057_NT_ses-1_merged.xlsx'>\n",
      "1\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-058_CT_ses-1_merged.xlsx'\n",
      "NAME ONLY : 'sub-058_CT_ses-1_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-058_CT_ses-1_merged.xlsx'>\n",
      "1\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-058_CT_ses-2_merged.xlsx'\n",
      "NAME ONLY : 'sub-058_CT_ses-2_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-058_CT_ses-2_merged.xlsx'>\n",
      "2\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-059_NT_ses-1_merged.xlsx'\n",
      "NAME ONLY : 'sub-059_NT_ses-1_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-059_NT_ses-1_merged.xlsx'>\n",
      "1\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-059_NT_ses-2_merged.xlsx'\n",
      "NAME ONLY : 'sub-059_NT_ses-2_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-059_NT_ses-2_merged.xlsx'>\n",
      "2\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-060_NT_ses-1_merged.xlsx'\n",
      "NAME ONLY : 'sub-060_NT_ses-1_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-060_NT_ses-1_merged.xlsx'>\n",
      "1\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-062_CT_ses-1_merged.xlsx'\n",
      "NAME ONLY : 'sub-062_CT_ses-1_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-062_CT_ses-1_merged.xlsx'>\n",
      "1\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-062_CT_ses-2_merged.xlsx'\n",
      "NAME ONLY : 'sub-062_CT_ses-2_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-062_CT_ses-2_merged.xlsx'>\n",
      "2\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-063_NT_ses-1_merged.xlsx'\n",
      "NAME ONLY : 'sub-063_NT_ses-1_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-063_NT_ses-1_merged.xlsx'>\n",
      "1\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-065_CT_ses-1_merged.xlsx'\n",
      "NAME ONLY : 'sub-065_CT_ses-1_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-065_CT_ses-1_merged.xlsx'>\n",
      "1\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-065_NT_ses-1_merged.xlsx'\n",
      "NAME ONLY : 'sub-065_NT_ses-1_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-065_NT_ses-1_merged.xlsx'>\n",
      "1\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-066_NT_ses-1_merged.xlsx'\n",
      "NAME ONLY : 'sub-066_NT_ses-1_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-066_NT_ses-1_merged.xlsx'>\n",
      "1\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-067_NT_ses-1_merged.xlsx'\n",
      "NAME ONLY : 'sub-067_NT_ses-1_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-067_NT_ses-1_merged.xlsx'>\n",
      "1\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-068_NT_ses-1_merged.xlsx'\n",
      "NAME ONLY : 'sub-068_NT_ses-1_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-068_NT_ses-1_merged.xlsx'>\n",
      "1\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-069_NT_ses-1_merged.xlsx'\n",
      "NAME ONLY : 'sub-069_NT_ses-1_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-069_NT_ses-1_merged.xlsx'>\n",
      "1\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-070_NT_ses-1_merged.xlsx'\n",
      "NAME ONLY : 'sub-070_NT_ses-1_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-070_NT_ses-1_merged.xlsx'>\n",
      "1\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-070_NT_ses-2_merged.xlsx'\n",
      "NAME ONLY : 'sub-070_NT_ses-2_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-070_NT_ses-2_merged.xlsx'>\n",
      "2\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-074_NT_ses-1_merged.xlsx'\n",
      "NAME ONLY : 'sub-074_NT_ses-1_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-074_NT_ses-1_merged.xlsx'>\n",
      "1\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-075_NT_ses-1_merged.xlsx'\n",
      "NAME ONLY : 'sub-075_NT_ses-1_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-075_NT_ses-1_merged.xlsx'>\n",
      "1\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-077_NT_ses-1_merged.xlsx'\n",
      "NAME ONLY : 'sub-077_NT_ses-1_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-077_NT_ses-1_merged.xlsx'>\n",
      "1\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-078_NT_ses-1_merged.xlsx'\n",
      "NAME ONLY : 'sub-078_NT_ses-1_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-078_NT_ses-1_merged.xlsx'>\n",
      "1\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-080_NT_ses-1_merged.xlsx'\n",
      "NAME ONLY : 'sub-080_NT_ses-1_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-080_NT_ses-1_merged.xlsx'>\n",
      "1\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-081_NT_ses-1_merged.xlsx'\n",
      "NAME ONLY : 'sub-081_NT_ses-1_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-081_NT_ses-1_merged.xlsx'>\n",
      "1\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-081_NT_ses-2_merged.xlsx'\n",
      "NAME ONLY : 'sub-081_NT_ses-2_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-081_NT_ses-2_merged.xlsx'>\n",
      "2\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-082_NT_ses-1_merged.xlsx'\n",
      "NAME ONLY : 'sub-082_NT_ses-1_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-082_NT_ses-1_merged.xlsx'>\n",
      "1\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-082_NT_ses-2_merged.xlsx'\n",
      "NAME ONLY : 'sub-082_NT_ses-2_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-082_NT_ses-2_merged.xlsx'>\n",
      "2\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-082_NT_ses-3_merged.xlsx'\n",
      "NAME ONLY : 'sub-082_NT_ses-3_merged.xlsx'\n",
      "None\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-083_NT_ses-1_merged.xlsx'\n",
      "NAME ONLY : 'sub-083_NT_ses-1_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-083_NT_ses-1_merged.xlsx'>\n",
      "1\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-087_NT_ses-1_merged.xlsx'\n",
      "NAME ONLY : 'sub-087_NT_ses-1_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-087_NT_ses-1_merged.xlsx'>\n",
      "1\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-088_NT_ses-1_merged.xlsx'\n",
      "NAME ONLY : 'sub-088_NT_ses-1_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-088_NT_ses-1_merged.xlsx'>\n",
      "1\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-090_NT_ses-1_merged.xlsx'\n",
      "NAME ONLY : 'sub-090_NT_ses-1_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-090_NT_ses-1_merged.xlsx'>\n",
      "1\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-090_NT_ses-2_merged.xlsx'\n",
      "NAME ONLY : 'sub-090_NT_ses-2_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-090_NT_ses-2_merged.xlsx'>\n",
      "2\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-093_NT_ses-1_merged.xlsx'\n",
      "NAME ONLY : 'sub-093_NT_ses-1_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-093_NT_ses-1_merged.xlsx'>\n",
      "1\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-093_NT_ses-2_merged.xlsx'\n",
      "NAME ONLY : 'sub-093_NT_ses-2_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-093_NT_ses-2_merged.xlsx'>\n",
      "2\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-096_NT_ses-1_merged.xlsx'\n",
      "NAME ONLY : 'sub-096_NT_ses-1_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-096_NT_ses-1_merged.xlsx'>\n",
      "1\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-096_NT_ses-2_merged.xlsx'\n",
      "NAME ONLY : 'sub-096_NT_ses-2_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-096_NT_ses-2_merged.xlsx'>\n",
      "2\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-100_NT_ses-1_merged.xlsx'\n",
      "NAME ONLY : 'sub-100_NT_ses-1_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-100_NT_ses-1_merged.xlsx'>\n",
      "1\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-106_NT_ses-1_merged.xlsx'\n",
      "NAME ONLY : 'sub-106_NT_ses-1_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-106_NT_ses-1_merged.xlsx'>\n",
      "1\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-112_NT_ses-1_merged.xlsx'\n",
      "NAME ONLY : 'sub-112_NT_ses-1_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-112_NT_ses-1_merged.xlsx'>\n",
      "1\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-113_NT_ses-1_merged.xlsx'\n",
      "NAME ONLY : 'sub-113_NT_ses-1_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-113_NT_ses-1_merged.xlsx'>\n",
      "1\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-114_NT_ses-1_merged.xlsx'\n",
      "NAME ONLY : 'sub-114_NT_ses-1_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-114_NT_ses-1_merged.xlsx'>\n",
      "1\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-118_NT_ses-1_merged.xlsx'\n",
      "NAME ONLY : 'sub-118_NT_ses-1_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-118_NT_ses-1_merged.xlsx'>\n",
      "1\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-119_NT_ses-1_merged.xlsx'\n",
      "NAME ONLY : 'sub-119_NT_ses-1_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-119_NT_ses-1_merged.xlsx'>\n",
      "1\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-121_NT_ses-1_merged.xlsx'\n",
      "NAME ONLY : 'sub-121_NT_ses-1_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-121_NT_ses-1_merged.xlsx'>\n",
      "1\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-124_NT_ses-1_merged.xlsx'\n",
      "NAME ONLY : 'sub-124_NT_ses-1_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-124_NT_ses-1_merged.xlsx'>\n",
      "1\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-125_NT_ses-1_merged.xlsx'\n",
      "NAME ONLY : 'sub-125_NT_ses-1_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-125_NT_ses-1_merged.xlsx'>\n",
      "1\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-126_NT_ses-1_merged.xlsx'\n",
      "NAME ONLY : 'sub-126_NT_ses-1_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-126_NT_ses-1_merged.xlsx'>\n",
      "1\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-131_NT_ses-1_merged.xlsx'\n",
      "NAME ONLY : 'sub-131_NT_ses-1_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-131_NT_ses-1_merged.xlsx'>\n",
      "1\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-132_NT_ses-1_merged.xlsx'\n",
      "NAME ONLY : 'sub-132_NT_ses-1_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-132_NT_ses-1_merged.xlsx'>\n",
      "1\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-134_NT_ses-1_merged.xlsx'\n",
      "NAME ONLY : 'sub-134_NT_ses-1_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-134_NT_ses-1_merged.xlsx'>\n",
      "1\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-135_NT_ses-1_merged.xlsx'\n",
      "NAME ONLY : 'sub-135_NT_ses-1_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-135_NT_ses-1_merged.xlsx'>\n",
      "1\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-137_NT_ses-1_merged.xlsx'\n",
      "NAME ONLY : 'sub-137_NT_ses-1_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-137_NT_ses-1_merged.xlsx'>\n",
      "1\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-138_NT_ses-1_merged.xlsx'\n",
      "NAME ONLY : 'sub-138_NT_ses-1_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-138_NT_ses-1_merged.xlsx'>\n",
      "1\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-142_NT_ses-1_merged.xlsx'\n",
      "NAME ONLY : 'sub-142_NT_ses-1_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-142_NT_ses-1_merged.xlsx'>\n",
      "1\n",
      "Saved: data\\stats_t1_fs\\ses1\\ses1_aparc_voxels_lh_rh.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "  subject_code  bankssts_lh  bankssts_rh  caudalanteriorcingulate_lh  \\\n",
       "0        CT002         3247         2390                        1593   \n",
       "1        NT002         2598         1986                        1424   \n",
       "2        CT003         2650         2683                        1655   \n",
       "3        NT003         2628         2827                        2389   \n",
       "4        CT004         2598         2386                        2530   \n",
       "\n",
       "   caudalanteriorcingulate_rh  caudalmiddlefrontal_lh  caudalmiddlefrontal_rh  \\\n",
       "0                        2232                    6888                    6822   \n",
       "1                        2187                    5876                    6710   \n",
       "2                        1911                    7284                    6086   \n",
       "3                        2589                    7100                    7939   \n",
       "4                        2906                    8093                    7395   \n",
       "\n",
       "   cuneus_lh  cuneus_rh  entorhinal_lh  ...  superiorparietal_lh  \\\n",
       "0       2763       3254           1433  ...                16606   \n",
       "1       3117       5185           1679  ...                13418   \n",
       "2       3045       3354           2361  ...                15518   \n",
       "3       2964       3984           2048  ...                15089   \n",
       "4       2834       3300           1767  ...                15353   \n",
       "\n",
       "   superiorparietal_rh  superiortemporal_lh  superiortemporal_rh  \\\n",
       "0                16481                15329                14010   \n",
       "1                14705                12423                12143   \n",
       "2                15468                12005                12525   \n",
       "3                15467                15034                13084   \n",
       "4                14536                14995                13529   \n",
       "\n",
       "   supramarginal_lh  supramarginal_rh  temporalpole_lh  temporalpole_rh  \\\n",
       "0             14012             11521             1484             1787   \n",
       "1             10160             10382             2314             2215   \n",
       "2              9350              9664             3098             3175   \n",
       "3             14066             12609             2633             2607   \n",
       "4             11490             10928             2404             2433   \n",
       "\n",
       "   transversetemporal_lh  transversetemporal_rh  \n",
       "0                   1362                    904  \n",
       "1                    971                    781  \n",
       "2                   1042                    776  \n",
       "3                   1289                    883  \n",
       "4                   1470                   1058  \n",
       "\n",
       "[5 rows x 69 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_code</th>\n",
       "      <th>bankssts_lh</th>\n",
       "      <th>bankssts_rh</th>\n",
       "      <th>caudalanteriorcingulate_lh</th>\n",
       "      <th>caudalanteriorcingulate_rh</th>\n",
       "      <th>caudalmiddlefrontal_lh</th>\n",
       "      <th>caudalmiddlefrontal_rh</th>\n",
       "      <th>cuneus_lh</th>\n",
       "      <th>cuneus_rh</th>\n",
       "      <th>entorhinal_lh</th>\n",
       "      <th>...</th>\n",
       "      <th>superiorparietal_lh</th>\n",
       "      <th>superiorparietal_rh</th>\n",
       "      <th>superiortemporal_lh</th>\n",
       "      <th>superiortemporal_rh</th>\n",
       "      <th>supramarginal_lh</th>\n",
       "      <th>supramarginal_rh</th>\n",
       "      <th>temporalpole_lh</th>\n",
       "      <th>temporalpole_rh</th>\n",
       "      <th>transversetemporal_lh</th>\n",
       "      <th>transversetemporal_rh</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CT002</td>\n",
       "      <td>3247</td>\n",
       "      <td>2390</td>\n",
       "      <td>1593</td>\n",
       "      <td>2232</td>\n",
       "      <td>6888</td>\n",
       "      <td>6822</td>\n",
       "      <td>2763</td>\n",
       "      <td>3254</td>\n",
       "      <td>1433</td>\n",
       "      <td>...</td>\n",
       "      <td>16606</td>\n",
       "      <td>16481</td>\n",
       "      <td>15329</td>\n",
       "      <td>14010</td>\n",
       "      <td>14012</td>\n",
       "      <td>11521</td>\n",
       "      <td>1484</td>\n",
       "      <td>1787</td>\n",
       "      <td>1362</td>\n",
       "      <td>904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NT002</td>\n",
       "      <td>2598</td>\n",
       "      <td>1986</td>\n",
       "      <td>1424</td>\n",
       "      <td>2187</td>\n",
       "      <td>5876</td>\n",
       "      <td>6710</td>\n",
       "      <td>3117</td>\n",
       "      <td>5185</td>\n",
       "      <td>1679</td>\n",
       "      <td>...</td>\n",
       "      <td>13418</td>\n",
       "      <td>14705</td>\n",
       "      <td>12423</td>\n",
       "      <td>12143</td>\n",
       "      <td>10160</td>\n",
       "      <td>10382</td>\n",
       "      <td>2314</td>\n",
       "      <td>2215</td>\n",
       "      <td>971</td>\n",
       "      <td>781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CT003</td>\n",
       "      <td>2650</td>\n",
       "      <td>2683</td>\n",
       "      <td>1655</td>\n",
       "      <td>1911</td>\n",
       "      <td>7284</td>\n",
       "      <td>6086</td>\n",
       "      <td>3045</td>\n",
       "      <td>3354</td>\n",
       "      <td>2361</td>\n",
       "      <td>...</td>\n",
       "      <td>15518</td>\n",
       "      <td>15468</td>\n",
       "      <td>12005</td>\n",
       "      <td>12525</td>\n",
       "      <td>9350</td>\n",
       "      <td>9664</td>\n",
       "      <td>3098</td>\n",
       "      <td>3175</td>\n",
       "      <td>1042</td>\n",
       "      <td>776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NT003</td>\n",
       "      <td>2628</td>\n",
       "      <td>2827</td>\n",
       "      <td>2389</td>\n",
       "      <td>2589</td>\n",
       "      <td>7100</td>\n",
       "      <td>7939</td>\n",
       "      <td>2964</td>\n",
       "      <td>3984</td>\n",
       "      <td>2048</td>\n",
       "      <td>...</td>\n",
       "      <td>15089</td>\n",
       "      <td>15467</td>\n",
       "      <td>15034</td>\n",
       "      <td>13084</td>\n",
       "      <td>14066</td>\n",
       "      <td>12609</td>\n",
       "      <td>2633</td>\n",
       "      <td>2607</td>\n",
       "      <td>1289</td>\n",
       "      <td>883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CT004</td>\n",
       "      <td>2598</td>\n",
       "      <td>2386</td>\n",
       "      <td>2530</td>\n",
       "      <td>2906</td>\n",
       "      <td>8093</td>\n",
       "      <td>7395</td>\n",
       "      <td>2834</td>\n",
       "      <td>3300</td>\n",
       "      <td>1767</td>\n",
       "      <td>...</td>\n",
       "      <td>15353</td>\n",
       "      <td>14536</td>\n",
       "      <td>14995</td>\n",
       "      <td>13529</td>\n",
       "      <td>11490</td>\n",
       "      <td>10928</td>\n",
       "      <td>2404</td>\n",
       "      <td>2433</td>\n",
       "      <td>1470</td>\n",
       "      <td>1058</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  69 columns</p>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## extracting from the subject file the subcortical volumes and merge nto one csv file\n",
   "id": "576358a0b41ac9b9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-05T08:27:26.945587Z",
     "start_time": "2025-12-05T08:27:22.933414Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ---------- CONFIG ----------\n",
    "FOLDER = Path(\"data/stats_t1_fs\")\n",
    "OUT_CSV = Path(\"data/stats_t1_fs/ses1/ses1_aseg_data.csv\")\n",
    "SHEET_NAME = \"aseg_voxels\"\n",
    "RECURSIVE = False\n",
    "# ----------------------------\n",
    "\n",
    "rows_by_subject = {}\n",
    "all_feature_cols = set()\n",
    "\n",
    "files = list_excel_files(FOLDER, RECURSIVE)\n",
    "for path in files:\n",
    "\n",
    "    m = file_regex.match(path.name)\n",
    "    if not m:\n",
    "        continue\n",
    "\n",
    "    subject = m.group(\"subject\")\n",
    "    group = m.group(\"group\").upper()\n",
    "    session = int(m.group(\"session\"))\n",
    "\n",
    "    # --- ONLY USE SESSION 1 ---\n",
    "    if session != 1:\n",
    "        continue\n",
    "\n",
    "    subject_code = f\"{group}{subject}\"\n",
    "\n",
    "    # read the aseg sheet\n",
    "    try:\n",
    "        df = pd.read_excel(path, sheet_name=SHEET_NAME)\n",
    "    except Exception as e:\n",
    "        print(f\"Warning: couldn't read sheet '{SHEET_NAME}' in {path.name}: {e}\")\n",
    "        continue\n",
    "\n",
    "    # locate required columns\n",
    "    col_struct = pick_column(df, [\"StructName\"])\n",
    "    col_gray   = pick_column(df, [\"Volume_mm3\"])\n",
    "\n",
    "    if not all([col_struct, col_gray]):\n",
    "        print(f\"Warning: missing needed columns in {path.name}. struct={col_struct}, vol={col_gray}\")\n",
    "        continue\n",
    "\n",
    "    # initialize subject row\n",
    "    if subject_code not in rows_by_subject:\n",
    "        rows_by_subject[subject_code] = {\"subject_code\": subject_code}\n",
    "\n",
    "    # iterate rows\n",
    "    for _, row in df.iterrows():\n",
    "        struct = slugify(row[col_struct])\n",
    "        if not struct:\n",
    "            continue\n",
    "\n",
    "        # --- FIX: NO SESSION SUFFIX ---\n",
    "        col_name = struct\n",
    "\n",
    "        val = row[col_gray]\n",
    "        try:\n",
    "            val = pd.to_numeric(val)\n",
    "        except:\n",
    "            val = np.nan\n",
    "\n",
    "        rows_by_subject[subject_code][col_name] = val\n",
    "        all_feature_cols.add(col_name)\n",
    "\n",
    "    # optional logging\n",
    "\n",
    "\n",
    "# final table columns\n",
    "all_columns = [\"subject_code\"] + sorted(all_feature_cols, key=col_sort_key)\n",
    "\n",
    "# build wide dataframe\n",
    "df_out = pd.DataFrame(rows_by_subject.values())\n",
    "\n",
    "# ensure missing columns exist\n",
    "for c in all_columns:\n",
    "    if c not in df_out.columns:\n",
    "        df_out[c] = np.nan\n",
    "\n",
    "df_out = df_out[all_columns]\n",
    "\n",
    "# write CSV\n",
    "OUT_CSV.parent.mkdir(parents=True, exist_ok=True)\n",
    "df_out.to_csv(OUT_CSV, index=False)\n",
    "\n",
    "print(f\"Saved: {OUT_CSV}\")\n",
    "display(df_out.head(5))\n"
   ],
   "id": "b48bc609c7367e87",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: data\\stats_t1_fs\\ses1\\ses1_aseg_data.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "  subject_code  3rd_ventricle  4th_ventricle  5th_ventricle  brain_stem  \\\n",
       "0        CT002          946.8         1479.5            0.0     20198.9   \n",
       "1        NT002          933.1          981.6            0.0     19351.4   \n",
       "2        CT003          795.9         1651.5            0.0     20283.0   \n",
       "3        NT003          771.7         1849.9            0.0     23059.0   \n",
       "4        CT004         1019.4         2162.6            0.0     19347.2   \n",
       "\n",
       "   cc_anterior  cc_central  cc_mid_anterior  cc_mid_posterior  cc_posterior  \\\n",
       "0        838.9       395.9            462.1             490.1         762.6   \n",
       "1        703.9       634.9            502.0             387.5         894.1   \n",
       "2        869.6       700.3            607.8             571.3         998.6   \n",
       "3        977.6       777.6            633.0             612.8        1137.3   \n",
       "4       1079.6       512.7            478.8             638.7        1027.5   \n",
       "\n",
       "   ...  right_inf_lat_vent  right_lateral_ventricle  \\\n",
       "0  ...               258.1                   7300.3   \n",
       "1  ...               232.4                   3594.3   \n",
       "2  ...               356.7                   5403.1   \n",
       "3  ...               293.5                   5516.4   \n",
       "4  ...               386.2                   9159.8   \n",
       "\n",
       "   right_non_wm_hypointensities  right_pallidum  right_putamen  \\\n",
       "0                           0.0          1714.5         4504.4   \n",
       "1                           0.0          1860.7         4944.3   \n",
       "2                           0.0          1959.3         4668.5   \n",
       "3                           0.0          2161.4         4955.2   \n",
       "4                           0.0          1898.0         5026.0   \n",
       "\n",
       "   right_thalamus  right_ventraldc  right_vessel  right_wm_hypointensities  \\\n",
       "0          7452.5           3682.2          13.3                       0.0   \n",
       "1          6697.8           3928.0          19.4                       0.0   \n",
       "2          7696.7           3794.7          15.0                       0.0   \n",
       "3          8696.2           4256.2           7.8                       0.0   \n",
       "4          7783.8           4164.7          10.8                       0.0   \n",
       "\n",
       "   wm_hypointensities  \n",
       "0               627.2  \n",
       "1               654.5  \n",
       "2               661.7  \n",
       "3               758.7  \n",
       "4               487.7  \n",
       "\n",
       "[5 rows x 46 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_code</th>\n",
       "      <th>3rd_ventricle</th>\n",
       "      <th>4th_ventricle</th>\n",
       "      <th>5th_ventricle</th>\n",
       "      <th>brain_stem</th>\n",
       "      <th>cc_anterior</th>\n",
       "      <th>cc_central</th>\n",
       "      <th>cc_mid_anterior</th>\n",
       "      <th>cc_mid_posterior</th>\n",
       "      <th>cc_posterior</th>\n",
       "      <th>...</th>\n",
       "      <th>right_inf_lat_vent</th>\n",
       "      <th>right_lateral_ventricle</th>\n",
       "      <th>right_non_wm_hypointensities</th>\n",
       "      <th>right_pallidum</th>\n",
       "      <th>right_putamen</th>\n",
       "      <th>right_thalamus</th>\n",
       "      <th>right_ventraldc</th>\n",
       "      <th>right_vessel</th>\n",
       "      <th>right_wm_hypointensities</th>\n",
       "      <th>wm_hypointensities</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CT002</td>\n",
       "      <td>946.8</td>\n",
       "      <td>1479.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20198.9</td>\n",
       "      <td>838.9</td>\n",
       "      <td>395.9</td>\n",
       "      <td>462.1</td>\n",
       "      <td>490.1</td>\n",
       "      <td>762.6</td>\n",
       "      <td>...</td>\n",
       "      <td>258.1</td>\n",
       "      <td>7300.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1714.5</td>\n",
       "      <td>4504.4</td>\n",
       "      <td>7452.5</td>\n",
       "      <td>3682.2</td>\n",
       "      <td>13.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>627.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NT002</td>\n",
       "      <td>933.1</td>\n",
       "      <td>981.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19351.4</td>\n",
       "      <td>703.9</td>\n",
       "      <td>634.9</td>\n",
       "      <td>502.0</td>\n",
       "      <td>387.5</td>\n",
       "      <td>894.1</td>\n",
       "      <td>...</td>\n",
       "      <td>232.4</td>\n",
       "      <td>3594.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1860.7</td>\n",
       "      <td>4944.3</td>\n",
       "      <td>6697.8</td>\n",
       "      <td>3928.0</td>\n",
       "      <td>19.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>654.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CT003</td>\n",
       "      <td>795.9</td>\n",
       "      <td>1651.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20283.0</td>\n",
       "      <td>869.6</td>\n",
       "      <td>700.3</td>\n",
       "      <td>607.8</td>\n",
       "      <td>571.3</td>\n",
       "      <td>998.6</td>\n",
       "      <td>...</td>\n",
       "      <td>356.7</td>\n",
       "      <td>5403.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1959.3</td>\n",
       "      <td>4668.5</td>\n",
       "      <td>7696.7</td>\n",
       "      <td>3794.7</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>661.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NT003</td>\n",
       "      <td>771.7</td>\n",
       "      <td>1849.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23059.0</td>\n",
       "      <td>977.6</td>\n",
       "      <td>777.6</td>\n",
       "      <td>633.0</td>\n",
       "      <td>612.8</td>\n",
       "      <td>1137.3</td>\n",
       "      <td>...</td>\n",
       "      <td>293.5</td>\n",
       "      <td>5516.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2161.4</td>\n",
       "      <td>4955.2</td>\n",
       "      <td>8696.2</td>\n",
       "      <td>4256.2</td>\n",
       "      <td>7.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>758.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CT004</td>\n",
       "      <td>1019.4</td>\n",
       "      <td>2162.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19347.2</td>\n",
       "      <td>1079.6</td>\n",
       "      <td>512.7</td>\n",
       "      <td>478.8</td>\n",
       "      <td>638.7</td>\n",
       "      <td>1027.5</td>\n",
       "      <td>...</td>\n",
       "      <td>386.2</td>\n",
       "      <td>9159.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1898.0</td>\n",
       "      <td>5026.0</td>\n",
       "      <td>7783.8</td>\n",
       "      <td>4164.7</td>\n",
       "      <td>10.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>487.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  46 columns</p>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## extracting from the subject file thewhite matter  volumes and merge nto one csv file\n",
   "id": "ac29c86ff2f5fc89"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-05T08:27:30.980888Z",
     "start_time": "2025-12-05T08:27:26.966328Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ---------- CONFIG ----------\n",
    "FOLDER = Path(\"data/stats_t1_fs\")\n",
    "OUT_CSV = Path(\"data/stats_t1_fs/ses1/ses1_wmparc_data.csv\")\n",
    "SHEET_NAME = \"wmparc_voxels\"\n",
    "RECURSIVE = False\n",
    "# ----------------------------\n",
    "\n",
    "rows_by_subject = {}\n",
    "all_feature_cols = set()\n",
    "\n",
    "files = list_excel_files(FOLDER, RECURSIVE)\n",
    "for path in files:\n",
    "\n",
    "    m = file_regex.match(path.name)\n",
    "    if not m:\n",
    "        continue\n",
    "\n",
    "    subject = m.group(\"subject\")\n",
    "    group = m.group(\"group\").upper()\n",
    "    session = int(m.group(\"session\"))\n",
    "\n",
    "    # --- ONLY USE SESSION 1 ---\n",
    "    if session != 1:\n",
    "        continue\n",
    "\n",
    "    subject_code = f\"{group}{subject}\"\n",
    "\n",
    "    # Load wmparc sheet\n",
    "    try:\n",
    "        df = pd.read_excel(path, sheet_name=SHEET_NAME)\n",
    "    except Exception as e:\n",
    "        print(f\"Warning: couldn't read sheet '{SHEET_NAME}' in {path.name}: {e}\")\n",
    "        continue\n",
    "\n",
    "    # Identify needed columns\n",
    "    col_struct = pick_column(df, [\"StructName\"])\n",
    "    col_gray   = pick_column(df, [\"Volume_mm3\"])\n",
    "\n",
    "    if not all([col_struct, col_gray]):\n",
    "        print(f\"Warning: missing needed columns in {path.name}. struct={col_struct}, vol={col_gray}\")\n",
    "        continue\n",
    "\n",
    "    # Initialize subject row\n",
    "    if subject_code not in rows_by_subject:\n",
    "        rows_by_subject[subject_code] = {\"subject_code\": subject_code}\n",
    "\n",
    "    # Process each ROI row\n",
    "    for _, row in df.iterrows():\n",
    "        struct = slugify(row[col_struct])\n",
    "        if not struct:\n",
    "            continue\n",
    "\n",
    "        # --- FIX: remove session suffix ---\n",
    "        col_name = struct\n",
    "\n",
    "        # convert to numeric\n",
    "        val = row[col_gray]\n",
    "        try:\n",
    "            val = pd.to_numeric(val)\n",
    "        except:\n",
    "            val = np.nan\n",
    "\n",
    "        rows_by_subject[subject_code][col_name] = val\n",
    "        all_feature_cols.add(col_name)\n",
    "\n",
    "    # optional tracking\n",
    "\n",
    "# Final set of columns\n",
    "all_columns = [\"subject_code\"] + sorted(all_feature_cols, key=col_sort_key)\n",
    "\n",
    "# Build final table\n",
    "df_out = pd.DataFrame(rows_by_subject.values())\n",
    "\n",
    "# Ensure all expected columns exist\n",
    "for c in all_columns:\n",
    "    if c not in df_out.columns:\n",
    "        df_out[c] = np.nan\n",
    "\n",
    "df_out = df_out[all_columns]\n",
    "\n",
    "# Save CSV\n",
    "OUT_CSV.parent.mkdir(parents=True, exist_ok=True)\n",
    "df_out.to_csv(OUT_CSV, index=False)\n",
    "\n",
    "print(f\"Saved: {OUT_CSV}\")\n",
    "display(df_out.head(5))\n"
   ],
   "id": "61332b92b0312412",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: data\\stats_t1_fs\\ses1\\ses1_wmparc_data.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "  subject_code  left_unsegmentedwhitematter  right_unsegmentedwhitematter  \\\n",
       "0        CT002                      24819.4                       25086.5   \n",
       "1        NT002                      28695.5                       29649.8   \n",
       "2        CT003                      33322.6                       31838.1   \n",
       "3        NT003                      32881.1                       31335.8   \n",
       "4        CT004                      27175.7                       26310.7   \n",
       "\n",
       "   wm_lh_bankssts  wm_lh_caudalanteriorcingulate  wm_lh_caudalmiddlefrontal  \\\n",
       "0          3408.9                         3590.1                     6647.4   \n",
       "1          3256.2                         2437.9                     5984.8   \n",
       "2          4073.6                         3197.4                     7118.4   \n",
       "3          3774.9                         4236.0                     6450.3   \n",
       "4          2227.5                         3318.3                     7673.4   \n",
       "\n",
       "   wm_lh_cuneus  wm_lh_entorhinal  wm_lh_frontalpole  wm_lh_fusiform  ...  \\\n",
       "0        1817.8             647.1              259.0          7629.1  ...   \n",
       "1        3093.4             728.1              332.9          5908.8  ...   \n",
       "2        2322.3            1036.5              261.5          7846.3  ...   \n",
       "3        2498.9            1219.6              279.3          6560.0  ...   \n",
       "4        2376.6             912.4              376.0          5927.0  ...   \n",
       "\n",
       "   wm_rh_precentral  wm_rh_precuneus  wm_rh_rostralanteriorcingulate  \\\n",
       "0           13317.3          10986.8                          2228.7   \n",
       "1           12051.8           7657.1                          1736.9   \n",
       "2           14465.7          10235.0                          1812.8   \n",
       "3           13129.2          10774.6                          1690.9   \n",
       "4           14148.8          10280.0                          1896.0   \n",
       "\n",
       "   wm_rh_rostralmiddlefrontal  wm_rh_superiorfrontal  wm_rh_superiorparietal  \\\n",
       "0                     11952.3                17967.1                 11795.6   \n",
       "1                     11152.4                15386.1                 11491.3   \n",
       "2                     12669.7                16985.7                 12255.8   \n",
       "3                     16402.2                19051.9                 13307.8   \n",
       "4                     15336.4                21204.6                 11449.5   \n",
       "\n",
       "   wm_rh_superiortemporal  wm_rh_supramarginal  wm_rh_temporalpole  \\\n",
       "0                  7314.8               8828.6               557.5   \n",
       "1                  6462.8               7443.3               623.1   \n",
       "2                  5995.6               8215.8               646.1   \n",
       "3                  7059.9               9943.8               756.8   \n",
       "4                  6947.3               9068.5               820.7   \n",
       "\n",
       "   wm_rh_transversetemporal  \n",
       "0                     699.3  \n",
       "1                     464.3  \n",
       "2                     560.0  \n",
       "3                     758.6  \n",
       "4                     664.1  \n",
       "\n",
       "[5 rows x 71 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_code</th>\n",
       "      <th>left_unsegmentedwhitematter</th>\n",
       "      <th>right_unsegmentedwhitematter</th>\n",
       "      <th>wm_lh_bankssts</th>\n",
       "      <th>wm_lh_caudalanteriorcingulate</th>\n",
       "      <th>wm_lh_caudalmiddlefrontal</th>\n",
       "      <th>wm_lh_cuneus</th>\n",
       "      <th>wm_lh_entorhinal</th>\n",
       "      <th>wm_lh_frontalpole</th>\n",
       "      <th>wm_lh_fusiform</th>\n",
       "      <th>...</th>\n",
       "      <th>wm_rh_precentral</th>\n",
       "      <th>wm_rh_precuneus</th>\n",
       "      <th>wm_rh_rostralanteriorcingulate</th>\n",
       "      <th>wm_rh_rostralmiddlefrontal</th>\n",
       "      <th>wm_rh_superiorfrontal</th>\n",
       "      <th>wm_rh_superiorparietal</th>\n",
       "      <th>wm_rh_superiortemporal</th>\n",
       "      <th>wm_rh_supramarginal</th>\n",
       "      <th>wm_rh_temporalpole</th>\n",
       "      <th>wm_rh_transversetemporal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CT002</td>\n",
       "      <td>24819.4</td>\n",
       "      <td>25086.5</td>\n",
       "      <td>3408.9</td>\n",
       "      <td>3590.1</td>\n",
       "      <td>6647.4</td>\n",
       "      <td>1817.8</td>\n",
       "      <td>647.1</td>\n",
       "      <td>259.0</td>\n",
       "      <td>7629.1</td>\n",
       "      <td>...</td>\n",
       "      <td>13317.3</td>\n",
       "      <td>10986.8</td>\n",
       "      <td>2228.7</td>\n",
       "      <td>11952.3</td>\n",
       "      <td>17967.1</td>\n",
       "      <td>11795.6</td>\n",
       "      <td>7314.8</td>\n",
       "      <td>8828.6</td>\n",
       "      <td>557.5</td>\n",
       "      <td>699.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NT002</td>\n",
       "      <td>28695.5</td>\n",
       "      <td>29649.8</td>\n",
       "      <td>3256.2</td>\n",
       "      <td>2437.9</td>\n",
       "      <td>5984.8</td>\n",
       "      <td>3093.4</td>\n",
       "      <td>728.1</td>\n",
       "      <td>332.9</td>\n",
       "      <td>5908.8</td>\n",
       "      <td>...</td>\n",
       "      <td>12051.8</td>\n",
       "      <td>7657.1</td>\n",
       "      <td>1736.9</td>\n",
       "      <td>11152.4</td>\n",
       "      <td>15386.1</td>\n",
       "      <td>11491.3</td>\n",
       "      <td>6462.8</td>\n",
       "      <td>7443.3</td>\n",
       "      <td>623.1</td>\n",
       "      <td>464.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CT003</td>\n",
       "      <td>33322.6</td>\n",
       "      <td>31838.1</td>\n",
       "      <td>4073.6</td>\n",
       "      <td>3197.4</td>\n",
       "      <td>7118.4</td>\n",
       "      <td>2322.3</td>\n",
       "      <td>1036.5</td>\n",
       "      <td>261.5</td>\n",
       "      <td>7846.3</td>\n",
       "      <td>...</td>\n",
       "      <td>14465.7</td>\n",
       "      <td>10235.0</td>\n",
       "      <td>1812.8</td>\n",
       "      <td>12669.7</td>\n",
       "      <td>16985.7</td>\n",
       "      <td>12255.8</td>\n",
       "      <td>5995.6</td>\n",
       "      <td>8215.8</td>\n",
       "      <td>646.1</td>\n",
       "      <td>560.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NT003</td>\n",
       "      <td>32881.1</td>\n",
       "      <td>31335.8</td>\n",
       "      <td>3774.9</td>\n",
       "      <td>4236.0</td>\n",
       "      <td>6450.3</td>\n",
       "      <td>2498.9</td>\n",
       "      <td>1219.6</td>\n",
       "      <td>279.3</td>\n",
       "      <td>6560.0</td>\n",
       "      <td>...</td>\n",
       "      <td>13129.2</td>\n",
       "      <td>10774.6</td>\n",
       "      <td>1690.9</td>\n",
       "      <td>16402.2</td>\n",
       "      <td>19051.9</td>\n",
       "      <td>13307.8</td>\n",
       "      <td>7059.9</td>\n",
       "      <td>9943.8</td>\n",
       "      <td>756.8</td>\n",
       "      <td>758.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CT004</td>\n",
       "      <td>27175.7</td>\n",
       "      <td>26310.7</td>\n",
       "      <td>2227.5</td>\n",
       "      <td>3318.3</td>\n",
       "      <td>7673.4</td>\n",
       "      <td>2376.6</td>\n",
       "      <td>912.4</td>\n",
       "      <td>376.0</td>\n",
       "      <td>5927.0</td>\n",
       "      <td>...</td>\n",
       "      <td>14148.8</td>\n",
       "      <td>10280.0</td>\n",
       "      <td>1896.0</td>\n",
       "      <td>15336.4</td>\n",
       "      <td>21204.6</td>\n",
       "      <td>11449.5</td>\n",
       "      <td>6947.3</td>\n",
       "      <td>9068.5</td>\n",
       "      <td>820.7</td>\n",
       "      <td>664.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  71 columns</p>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## ecxtrating from the cortical parameters of each subject into one csv",
   "id": "fc16790df18d43ac"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-05T08:27:34.037517Z",
     "start_time": "2025-12-05T08:27:31.004608Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Build per-subject table from aparc_summary, including hemisphere in column names.\n",
    "# Requires helpers already defined: file_regex, list_excel_files, slugify, pick_column, col_sort_key, mark_extraction_complete\n",
    "\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "# ---------- CONFIG ----------\n",
    "FOLDER = Path(\"data/stats_t1_fs\")\n",
    "OUT_CSV = Path(\"data/stats_t1_fs/ses1/ses1_aparc_summary_data.csv\")\n",
    "SHEET_NAME = \"aparc_summary\"\n",
    "\n",
    "SHORTNAME_COLUMN_CANDIDATES = [\"ShortName\"]\n",
    "VALUE_COLUMN_CANDIDATES     = [\"Value\"]\n",
    "HEMI_COLUMN_CANDIDATES      = [\"Hemisphere\"]\n",
    "\n",
    "SHORTNAMES_TO_KEEP = [\"WhiteSurfArea\", \"MeanThickness\"]\n",
    "\n",
    "RENAMES = {}\n",
    "# ----------------------------\n",
    "\n",
    "rows_by_subject = {}\n",
    "all_feature_cols = set()\n",
    "\n",
    "files = list_excel_files(FOLDER, recursive=False)\n",
    "for path in files:\n",
    "\n",
    "    m = file_regex.match(path.name)\n",
    "    if not m:\n",
    "        continue\n",
    "\n",
    "    subject = m.group(\"subject\")\n",
    "    group = m.group(\"group\").upper()\n",
    "    session = int(m.group(\"session\"))\n",
    "\n",
    "    # --- ONLY SESSION 1 ---\n",
    "    if session != 1:\n",
    "        continue\n",
    "\n",
    "    subject_code = f\"{group}{subject}\"\n",
    "\n",
    "    try:\n",
    "        df = pd.read_excel(path, sheet_name=SHEET_NAME)\n",
    "    except Exception as e:\n",
    "        print(f\"Warning: couldn't read sheet '{SHEET_NAME}' in {path.name}: {e}\")\n",
    "        continue\n",
    "\n",
    "    col_short = pick_column(df, SHORTNAME_COLUMN_CANDIDATES)\n",
    "    col_val   = pick_column(df, VALUE_COLUMN_CANDIDATES)\n",
    "    col_hemi  = pick_column(df, HEMI_COLUMN_CANDIDATES)\n",
    "\n",
    "    if not all([col_short, col_val, col_hemi]):\n",
    "        print(f\"Warning: missing needed columns in {path.name}. \"\n",
    "              f\"ShortName={col_short}, Value={col_val}, Hemisphere={col_hemi}\")\n",
    "        continue\n",
    "\n",
    "    if subject_code not in rows_by_subject:\n",
    "        rows_by_subject[subject_code] = {\"subject_code\": subject_code}\n",
    "\n",
    "    # keep only desired ShortNames\n",
    "    sub = df[df[col_short].astype(str).isin(SHORTNAMES_TO_KEEP)]\n",
    "\n",
    "    for _, r in sub.iterrows():\n",
    "\n",
    "        raw_short = str(r[col_short])\n",
    "        hemi_raw  = str(r[col_hemi]).strip().lower()\n",
    "\n",
    "        # normalize hemisphere\n",
    "        if hemi_raw in (\"left\", \"l\"):  hemi = \"lh\"\n",
    "        elif hemi_raw in (\"right\", \"r\"): hemi = \"rh\"\n",
    "        elif hemi_raw in (\"lh\", \"rh\"): hemi = hemi_raw\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "        key = slugify(raw_short)\n",
    "        key = RENAMES.get(key, key)\n",
    "\n",
    "        # --- FIX: REMOVE SESSION SUFFIX ---\n",
    "        col_name = f\"{key}_{hemi}\"\n",
    "\n",
    "        # numeric convert\n",
    "        val = pd.to_numeric(r[col_val], errors=\"coerce\")\n",
    "\n",
    "        rows_by_subject[subject_code][col_name] = val\n",
    "        all_feature_cols.add(col_name)\n",
    "\n",
    "\n",
    "# build final dataframe\n",
    "all_columns = [\"subject_code\"] + sorted(all_feature_cols, key=col_sort_key)\n",
    "df_out = pd.DataFrame(rows_by_subject.values())\n",
    "\n",
    "# ensure missing columns are filled\n",
    "for c in all_columns:\n",
    "    if c not in df_out.columns:\n",
    "        df_out[c] = np.nan\n",
    "\n",
    "df_out = df_out[all_columns]\n",
    "\n",
    "# save\n",
    "OUT_CSV.parent.mkdir(parents=True, exist_ok=True)\n",
    "df_out.to_csv(OUT_CSV, index=False)\n",
    "\n",
    "print(f\"Saved: {OUT_CSV}\")\n",
    "display(df_out.head(10))\n"
   ],
   "id": "111881f9a7fe6603",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: data\\stats_t1_fs\\ses1\\ses1_aparc_summary_data.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "  subject_code  meanthickness_lh  meanthickness_rh  whitesurfarea_lh  \\\n",
       "0        CT002           2.68254           2.64069           89982.5   \n",
       "1        NT002           2.57344           2.51046           83008.8   \n",
       "2        CT003           2.62987           2.60471           87464.1   \n",
       "3        NT003           2.58301           2.56652           95277.5   \n",
       "4        CT004           2.59215           2.57039           95042.3   \n",
       "5        CT005           2.58495           2.57033           73468.8   \n",
       "6        NT005           2.64838           2.59901           77063.6   \n",
       "7        NT006           2.55593           2.53523           97442.2   \n",
       "8        CT007           2.46965           2.46323           85666.5   \n",
       "9        NT007           2.53044           2.50443          100684.0   \n",
       "\n",
       "   whitesurfarea_rh  \n",
       "0           89436.7  \n",
       "1           84464.0  \n",
       "2           86826.2  \n",
       "3           95072.8  \n",
       "4           96119.6  \n",
       "5           74068.0  \n",
       "6           76244.8  \n",
       "7           95931.2  \n",
       "8           84996.4  \n",
       "9          100008.0  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_code</th>\n",
       "      <th>meanthickness_lh</th>\n",
       "      <th>meanthickness_rh</th>\n",
       "      <th>whitesurfarea_lh</th>\n",
       "      <th>whitesurfarea_rh</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CT002</td>\n",
       "      <td>2.68254</td>\n",
       "      <td>2.64069</td>\n",
       "      <td>89982.5</td>\n",
       "      <td>89436.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NT002</td>\n",
       "      <td>2.57344</td>\n",
       "      <td>2.51046</td>\n",
       "      <td>83008.8</td>\n",
       "      <td>84464.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CT003</td>\n",
       "      <td>2.62987</td>\n",
       "      <td>2.60471</td>\n",
       "      <td>87464.1</td>\n",
       "      <td>86826.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NT003</td>\n",
       "      <td>2.58301</td>\n",
       "      <td>2.56652</td>\n",
       "      <td>95277.5</td>\n",
       "      <td>95072.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CT004</td>\n",
       "      <td>2.59215</td>\n",
       "      <td>2.57039</td>\n",
       "      <td>95042.3</td>\n",
       "      <td>96119.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CT005</td>\n",
       "      <td>2.58495</td>\n",
       "      <td>2.57033</td>\n",
       "      <td>73468.8</td>\n",
       "      <td>74068.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NT005</td>\n",
       "      <td>2.64838</td>\n",
       "      <td>2.59901</td>\n",
       "      <td>77063.6</td>\n",
       "      <td>76244.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NT006</td>\n",
       "      <td>2.55593</td>\n",
       "      <td>2.53523</td>\n",
       "      <td>97442.2</td>\n",
       "      <td>95931.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>CT007</td>\n",
       "      <td>2.46965</td>\n",
       "      <td>2.46323</td>\n",
       "      <td>85666.5</td>\n",
       "      <td>84996.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NT007</td>\n",
       "      <td>2.53044</td>\n",
       "      <td>2.50443</td>\n",
       "      <td>100684.0</td>\n",
       "      <td>100008.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## extracting from the subject file the subcortical volumes and merge nto one csv file\n",
   "id": "3a5535329a639b9e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-05T08:27:37.105912Z",
     "start_time": "2025-12-05T08:27:34.077627Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ---------- CONFIG ----------\n",
    "FOLDER = Path(\"data/stats_t1_fs\")\n",
    "OUT_CSV = Path(\"data/stats_t1_fs/ses1/ses1_aseg_summary_data.csv\")\n",
    "SHEET_NAME = \"aseg_summary\"\n",
    "\n",
    "SHORTNAME_COLUMN_CANDIDATES = [\"ShortName\"]\n",
    "VALUE_COLUMN_CANDIDATES     = [\"Value\"]\n",
    "\n",
    "SHORTNAMES_TO_KEEP = [\n",
    "    \"eTIV\", \"BrainSegVol\", \"lhCortexVol\", \"rhCortexVol\",\n",
    "    \"CortexVol\", \"CerebralWhiteMatterVol\", \"SubCortGrayVol\", \"TotalGrayVol\"\n",
    "]\n",
    "\n",
    "RENAMES = {}\n",
    "# ----------------------------\n",
    "\n",
    "rows_by_subject = {}\n",
    "all_feature_cols = set()\n",
    "\n",
    "files = list_excel_files(FOLDER, recursive=False)\n",
    "for path in files:\n",
    "\n",
    "    m = file_regex.match(path.name)\n",
    "    if not m:\n",
    "        continue\n",
    "\n",
    "    subject = m.group(\"subject\")\n",
    "    group = m.group(\"group\").upper()\n",
    "    session = int(m.group(\"session\"))\n",
    "\n",
    "    # --- ONLY SESSION 1 ---\n",
    "    if session != 1:\n",
    "        continue\n",
    "\n",
    "    subject_code = f\"{group}{subject}\"\n",
    "\n",
    "    try:\n",
    "        df = pd.read_excel(path, sheet_name=SHEET_NAME)\n",
    "    except Exception as e:\n",
    "        print(f\"Warning: couldn't read sheet '{SHEET_NAME}' in {path.name}: {e}\")\n",
    "        continue\n",
    "\n",
    "    col_short = pick_column(df, SHORTNAME_COLUMN_CANDIDATES)\n",
    "    col_val   = pick_column(df, VALUE_COLUMN_CANDIDATES)\n",
    "\n",
    "    if not all([col_short, col_val]):\n",
    "        print(f\"Warning: missing needed columns in {path.name}. ShortName={col_short}, Value={col_val}\")\n",
    "        continue\n",
    "\n",
    "    if subject_code not in rows_by_subject:\n",
    "        rows_by_subject[subject_code] = {\"subject_code\": subject_code}\n",
    "\n",
    "    # filter important metrics\n",
    "    sub = df[df[col_short].astype(str).isin(SHORTNAMES_TO_KEEP)]\n",
    "\n",
    "    for _, r in sub.iterrows():\n",
    "        raw_short = str(r[col_short])\n",
    "        key = slugify(raw_short)\n",
    "        key = RENAMES.get(key, key)\n",
    "\n",
    "        # --- FIX: REMOVE SESSION SUFFIX ---\n",
    "        col_name = key\n",
    "\n",
    "        # numeric convert\n",
    "        val = pd.to_numeric(r[col_val], errors=\"coerce\")\n",
    "\n",
    "        rows_by_subject[subject_code][col_name] = val\n",
    "        all_feature_cols.add(col_name)\n",
    "\n",
    "    # optional logging\n",
    "\n",
    "# finalize dataframe\n",
    "all_columns = [\"subject_code\"] + sorted(all_feature_cols, key=col_sort_key)\n",
    "df_out = pd.DataFrame(rows_by_subject.values())\n",
    "\n",
    "# ensure all columns exist\n",
    "for c in all_columns:\n",
    "    if c not in df_out.columns:\n",
    "        df_out[c] = np.nan\n",
    "\n",
    "df_out = df_out[all_columns]\n",
    "\n",
    "# save\n",
    "OUT_CSV.parent.mkdir(parents=True, exist_ok=True)\n",
    "df_out.to_csv(OUT_CSV, index=False)\n",
    "\n",
    "print(f\"Saved: {OUT_CSV}\")\n",
    "display(df_out.head(10))\n"
   ],
   "id": "7bd1c7e2c9225a71",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: data\\stats_t1_fs\\ses1\\ses1_aseg_summary_data.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "  subject_code  brainsegvol  cerebralwhitemattervol      cortexvol  \\\n",
       "0        CT002    1206545.0                453710.0  544619.107970   \n",
       "1        NT002    1112235.0                433453.0  479625.670030   \n",
       "2        CT003    1175880.0                464621.0  516867.684733   \n",
       "3        NT003    1279727.0                503653.0  547404.543520   \n",
       "4        CT004    1238372.0                474822.0  554975.392120   \n",
       "5        CT005    1011822.0                381493.0  434623.354034   \n",
       "6        NT005    1094167.0                421522.0  458670.156485   \n",
       "7        NT006    1226479.0                465770.0  552172.764328   \n",
       "8        CT007    1135690.0                440088.0  471758.358213   \n",
       "9        NT007    1273058.0                494327.0  573972.024005   \n",
       "\n",
       "           etiv    lhcortexvol    rhcortexvol  subcortgrayvol   totalgrayvol  \n",
       "0  1.563734e+06  274365.964887  270253.143083         54433.0  706866.107970  \n",
       "1  1.410701e+06  240458.346845  239167.323185         55377.0  642291.670030  \n",
       "2  1.500579e+06  260149.033135  256718.651598         56634.0  673158.684733  \n",
       "3  1.657961e+06  274821.618574  272582.924946         63662.0  727368.543520  \n",
       "4  1.564331e+06  275988.895743  278986.496377         59391.0  711508.392120  \n",
       "5  1.320171e+06  217051.120627  217572.233407         57258.0  592673.354034  \n",
       "6  1.440326e+06  231985.177486  226684.979000         54767.0  628372.156485  \n",
       "7  1.567791e+06  279222.777460  272949.986868         63480.0  720886.764328  \n",
       "8  1.445751e+06  236258.718813  235499.639399         60414.0  654590.358213  \n",
       "9  1.585406e+06  289220.288274  284751.735731         63379.0  741652.024005  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_code</th>\n",
       "      <th>brainsegvol</th>\n",
       "      <th>cerebralwhitemattervol</th>\n",
       "      <th>cortexvol</th>\n",
       "      <th>etiv</th>\n",
       "      <th>lhcortexvol</th>\n",
       "      <th>rhcortexvol</th>\n",
       "      <th>subcortgrayvol</th>\n",
       "      <th>totalgrayvol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CT002</td>\n",
       "      <td>1206545.0</td>\n",
       "      <td>453710.0</td>\n",
       "      <td>544619.107970</td>\n",
       "      <td>1.563734e+06</td>\n",
       "      <td>274365.964887</td>\n",
       "      <td>270253.143083</td>\n",
       "      <td>54433.0</td>\n",
       "      <td>706866.107970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NT002</td>\n",
       "      <td>1112235.0</td>\n",
       "      <td>433453.0</td>\n",
       "      <td>479625.670030</td>\n",
       "      <td>1.410701e+06</td>\n",
       "      <td>240458.346845</td>\n",
       "      <td>239167.323185</td>\n",
       "      <td>55377.0</td>\n",
       "      <td>642291.670030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CT003</td>\n",
       "      <td>1175880.0</td>\n",
       "      <td>464621.0</td>\n",
       "      <td>516867.684733</td>\n",
       "      <td>1.500579e+06</td>\n",
       "      <td>260149.033135</td>\n",
       "      <td>256718.651598</td>\n",
       "      <td>56634.0</td>\n",
       "      <td>673158.684733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NT003</td>\n",
       "      <td>1279727.0</td>\n",
       "      <td>503653.0</td>\n",
       "      <td>547404.543520</td>\n",
       "      <td>1.657961e+06</td>\n",
       "      <td>274821.618574</td>\n",
       "      <td>272582.924946</td>\n",
       "      <td>63662.0</td>\n",
       "      <td>727368.543520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CT004</td>\n",
       "      <td>1238372.0</td>\n",
       "      <td>474822.0</td>\n",
       "      <td>554975.392120</td>\n",
       "      <td>1.564331e+06</td>\n",
       "      <td>275988.895743</td>\n",
       "      <td>278986.496377</td>\n",
       "      <td>59391.0</td>\n",
       "      <td>711508.392120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CT005</td>\n",
       "      <td>1011822.0</td>\n",
       "      <td>381493.0</td>\n",
       "      <td>434623.354034</td>\n",
       "      <td>1.320171e+06</td>\n",
       "      <td>217051.120627</td>\n",
       "      <td>217572.233407</td>\n",
       "      <td>57258.0</td>\n",
       "      <td>592673.354034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NT005</td>\n",
       "      <td>1094167.0</td>\n",
       "      <td>421522.0</td>\n",
       "      <td>458670.156485</td>\n",
       "      <td>1.440326e+06</td>\n",
       "      <td>231985.177486</td>\n",
       "      <td>226684.979000</td>\n",
       "      <td>54767.0</td>\n",
       "      <td>628372.156485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NT006</td>\n",
       "      <td>1226479.0</td>\n",
       "      <td>465770.0</td>\n",
       "      <td>552172.764328</td>\n",
       "      <td>1.567791e+06</td>\n",
       "      <td>279222.777460</td>\n",
       "      <td>272949.986868</td>\n",
       "      <td>63480.0</td>\n",
       "      <td>720886.764328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>CT007</td>\n",
       "      <td>1135690.0</td>\n",
       "      <td>440088.0</td>\n",
       "      <td>471758.358213</td>\n",
       "      <td>1.445751e+06</td>\n",
       "      <td>236258.718813</td>\n",
       "      <td>235499.639399</td>\n",
       "      <td>60414.0</td>\n",
       "      <td>654590.358213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NT007</td>\n",
       "      <td>1273058.0</td>\n",
       "      <td>494327.0</td>\n",
       "      <td>573972.024005</td>\n",
       "      <td>1.585406e+06</td>\n",
       "      <td>289220.288274</td>\n",
       "      <td>284751.735731</td>\n",
       "      <td>63379.0</td>\n",
       "      <td>741652.024005</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## creating csv of the merged( left and right hemishpere ) for the subcortical volumes",
   "id": "e7ab49ee8480464c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-05T08:27:37.182308Z",
     "start_time": "2025-12-05T08:27:37.111592Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "# ---------- CONFIG ----------\n",
    "IN_CSV  = Path(\"data/stats_t1_fs/ses1/ses1_aparc_voxels_lh_rh.csv\")\n",
    "OUT_CSV = Path(\"data/stats_t1_fs/ses1/ses1_aparc_voxels_merge.csv\")\n",
    "AGGREGATION = \"sum\"     # \"sum\" or \"mean\"\n",
    "# ----------------------------\n",
    "\n",
    "def merge_two_cols(df, cols, how=\"sum\"):\n",
    "    \"\"\"Utility to merge two numeric columns by sum or mean.\"\"\"\n",
    "    vals = []\n",
    "    for c in cols:\n",
    "        if c is not None and c in df.columns:\n",
    "            vals.append(df[c])\n",
    "    if not vals:\n",
    "        return np.nan\n",
    "    vals = pd.concat(vals, axis=1)\n",
    "    return vals.mean(axis=1) if how == \"mean\" else vals.sum(axis=1)\n",
    "\n",
    "# Load LH/RH file\n",
    "df = pd.read_csv(IN_CSV)\n",
    "\n",
    "# Pattern for columns like: insula_lh , insula_rh\n",
    "pat = re.compile(r\"^(?P<struct>.+)_(?P<hemi>lh|rh)$\", re.IGNORECASE)\n",
    "\n",
    "pairs = {}\n",
    "other_cols = []\n",
    "\n",
    "for col in df.columns:\n",
    "    m = pat.match(col)\n",
    "    if m:\n",
    "        struct = m.group(\"struct\")\n",
    "        hemi   = m.group(\"hemi\").lower()\n",
    "\n",
    "        # No sessions in file  no filtering needed\n",
    "        key = struct\n",
    "        pairs.setdefault(key, {\"lh\": None, \"rh\": None})\n",
    "        pairs[key][hemi] = col\n",
    "\n",
    "    else:\n",
    "        other_cols.append(col)\n",
    "\n",
    "# Start output with non-hemisphere columns first (subject_code)\n",
    "out = df[other_cols].copy()\n",
    "\n",
    "# Create merged columns: \"<struct>\"\n",
    "for struct, hemis in pairs.items():\n",
    "    new_col = struct\n",
    "    out[new_col] = merge_two_cols(df, [hemis.get(\"lh\"), hemis.get(\"rh\")], how=AGGREGATION)\n",
    "\n",
    "# Sort columns (subject_code first)\n",
    "def col_sort_key(c):\n",
    "    return \" 0\" if c == \"subject_code\" else c.lower()\n",
    "\n",
    "out = out[sorted(out.columns, key=col_sort_key)]\n",
    "\n",
    "# Save\n",
    "OUT_CSV.parent.mkdir(parents=True, exist_ok=True)\n",
    "out.to_csv(OUT_CSV, index=False)\n",
    "\n",
    "print(f\"Saved merged file: {OUT_CSV}\")\n",
    "display(out.head(10))\n"
   ],
   "id": "90d667b11de48e3f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved merged file: data\\stats_t1_fs\\ses1\\ses1_aparc_voxels_merge.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "  subject_code  bankssts  caudalanteriorcingulate  caudalmiddlefrontal  \\\n",
       "0        CT002      5637                     3825                13710   \n",
       "1        NT002      4584                     3611                12586   \n",
       "2        CT003      5333                     3566                13370   \n",
       "3        NT003      5455                     4978                15039   \n",
       "4        CT004      4984                     5436                15488   \n",
       "5        CT005      3651                     3113                 9820   \n",
       "6        NT005      4840                     3211                 9124   \n",
       "7        NT006      4702                     4569                15870   \n",
       "8        CT007      4131                     4518                10968   \n",
       "9        NT007      5453                     3833                15456   \n",
       "\n",
       "   cuneus  entorhinal  frontalpole  fusiform  inferiorparietal  \\\n",
       "0    6017        2730         2818     22488             35471   \n",
       "1    8302        3896         2921     19363             28614   \n",
       "2    6399        3973         2673     20230             36313   \n",
       "3    6948        4240         2691     20866             31815   \n",
       "4    6134        3623         2595     20540             35087   \n",
       "5    6503        3750         2656     18145             22027   \n",
       "6    5558        3391         2322     17926             25452   \n",
       "7    8678        3492         2603     22289             28662   \n",
       "8    5505        4377         2553     18457             25727   \n",
       "9    8161        3569         2625     21120             33003   \n",
       "\n",
       "   inferiortemporal  ...  precentral  precuneus  rostralanteriorcingulate  \\\n",
       "0             26203  ...       30719      24249                      5349   \n",
       "1             24188  ...       26883      19560                      4607   \n",
       "2             25821  ...       29777      22560                      4935   \n",
       "3             24226  ...       30344      26188                      5501   \n",
       "4             26348  ...       31079      21325                      6294   \n",
       "5             20039  ...       25586      16045                      4068   \n",
       "6             22126  ...       26460      18048                      3946   \n",
       "7             24447  ...       31148      20781                      4981   \n",
       "8             20893  ...       27238      18471                      4792   \n",
       "9             24306  ...       29901      25245                      4757   \n",
       "\n",
       "   rostralmiddlefrontal  superiorfrontal  superiorparietal  superiortemporal  \\\n",
       "0                 34116            53252             33087             29339   \n",
       "1                 31357            42855             28123             24566   \n",
       "2                 33854            44590             30986             24530   \n",
       "3                 38077            49655             30556             28118   \n",
       "4                 38638            55203             29889             28524   \n",
       "5                 25270            41841             23599             24882   \n",
       "6                 30740            42690             27225             23640   \n",
       "7                 34327            51212             28914             30115   \n",
       "8                 31962            45018             24517             27573   \n",
       "9                 34139            55918             35641             27164   \n",
       "\n",
       "   supramarginal  temporalpole  transversetemporal  \n",
       "0          25533          3271                2266  \n",
       "1          20542          4529                1752  \n",
       "2          19014          6273                1818  \n",
       "3          26675          5240                2172  \n",
       "4          22418          4837                2528  \n",
       "5          21012          5023                1977  \n",
       "6          20317          4037                2160  \n",
       "7          26750          4731                3093  \n",
       "8          18011          4315                2102  \n",
       "9          30964          5698                2409  \n",
       "\n",
       "[10 rows x 35 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_code</th>\n",
       "      <th>bankssts</th>\n",
       "      <th>caudalanteriorcingulate</th>\n",
       "      <th>caudalmiddlefrontal</th>\n",
       "      <th>cuneus</th>\n",
       "      <th>entorhinal</th>\n",
       "      <th>frontalpole</th>\n",
       "      <th>fusiform</th>\n",
       "      <th>inferiorparietal</th>\n",
       "      <th>inferiortemporal</th>\n",
       "      <th>...</th>\n",
       "      <th>precentral</th>\n",
       "      <th>precuneus</th>\n",
       "      <th>rostralanteriorcingulate</th>\n",
       "      <th>rostralmiddlefrontal</th>\n",
       "      <th>superiorfrontal</th>\n",
       "      <th>superiorparietal</th>\n",
       "      <th>superiortemporal</th>\n",
       "      <th>supramarginal</th>\n",
       "      <th>temporalpole</th>\n",
       "      <th>transversetemporal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CT002</td>\n",
       "      <td>5637</td>\n",
       "      <td>3825</td>\n",
       "      <td>13710</td>\n",
       "      <td>6017</td>\n",
       "      <td>2730</td>\n",
       "      <td>2818</td>\n",
       "      <td>22488</td>\n",
       "      <td>35471</td>\n",
       "      <td>26203</td>\n",
       "      <td>...</td>\n",
       "      <td>30719</td>\n",
       "      <td>24249</td>\n",
       "      <td>5349</td>\n",
       "      <td>34116</td>\n",
       "      <td>53252</td>\n",
       "      <td>33087</td>\n",
       "      <td>29339</td>\n",
       "      <td>25533</td>\n",
       "      <td>3271</td>\n",
       "      <td>2266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NT002</td>\n",
       "      <td>4584</td>\n",
       "      <td>3611</td>\n",
       "      <td>12586</td>\n",
       "      <td>8302</td>\n",
       "      <td>3896</td>\n",
       "      <td>2921</td>\n",
       "      <td>19363</td>\n",
       "      <td>28614</td>\n",
       "      <td>24188</td>\n",
       "      <td>...</td>\n",
       "      <td>26883</td>\n",
       "      <td>19560</td>\n",
       "      <td>4607</td>\n",
       "      <td>31357</td>\n",
       "      <td>42855</td>\n",
       "      <td>28123</td>\n",
       "      <td>24566</td>\n",
       "      <td>20542</td>\n",
       "      <td>4529</td>\n",
       "      <td>1752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CT003</td>\n",
       "      <td>5333</td>\n",
       "      <td>3566</td>\n",
       "      <td>13370</td>\n",
       "      <td>6399</td>\n",
       "      <td>3973</td>\n",
       "      <td>2673</td>\n",
       "      <td>20230</td>\n",
       "      <td>36313</td>\n",
       "      <td>25821</td>\n",
       "      <td>...</td>\n",
       "      <td>29777</td>\n",
       "      <td>22560</td>\n",
       "      <td>4935</td>\n",
       "      <td>33854</td>\n",
       "      <td>44590</td>\n",
       "      <td>30986</td>\n",
       "      <td>24530</td>\n",
       "      <td>19014</td>\n",
       "      <td>6273</td>\n",
       "      <td>1818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NT003</td>\n",
       "      <td>5455</td>\n",
       "      <td>4978</td>\n",
       "      <td>15039</td>\n",
       "      <td>6948</td>\n",
       "      <td>4240</td>\n",
       "      <td>2691</td>\n",
       "      <td>20866</td>\n",
       "      <td>31815</td>\n",
       "      <td>24226</td>\n",
       "      <td>...</td>\n",
       "      <td>30344</td>\n",
       "      <td>26188</td>\n",
       "      <td>5501</td>\n",
       "      <td>38077</td>\n",
       "      <td>49655</td>\n",
       "      <td>30556</td>\n",
       "      <td>28118</td>\n",
       "      <td>26675</td>\n",
       "      <td>5240</td>\n",
       "      <td>2172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CT004</td>\n",
       "      <td>4984</td>\n",
       "      <td>5436</td>\n",
       "      <td>15488</td>\n",
       "      <td>6134</td>\n",
       "      <td>3623</td>\n",
       "      <td>2595</td>\n",
       "      <td>20540</td>\n",
       "      <td>35087</td>\n",
       "      <td>26348</td>\n",
       "      <td>...</td>\n",
       "      <td>31079</td>\n",
       "      <td>21325</td>\n",
       "      <td>6294</td>\n",
       "      <td>38638</td>\n",
       "      <td>55203</td>\n",
       "      <td>29889</td>\n",
       "      <td>28524</td>\n",
       "      <td>22418</td>\n",
       "      <td>4837</td>\n",
       "      <td>2528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CT005</td>\n",
       "      <td>3651</td>\n",
       "      <td>3113</td>\n",
       "      <td>9820</td>\n",
       "      <td>6503</td>\n",
       "      <td>3750</td>\n",
       "      <td>2656</td>\n",
       "      <td>18145</td>\n",
       "      <td>22027</td>\n",
       "      <td>20039</td>\n",
       "      <td>...</td>\n",
       "      <td>25586</td>\n",
       "      <td>16045</td>\n",
       "      <td>4068</td>\n",
       "      <td>25270</td>\n",
       "      <td>41841</td>\n",
       "      <td>23599</td>\n",
       "      <td>24882</td>\n",
       "      <td>21012</td>\n",
       "      <td>5023</td>\n",
       "      <td>1977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NT005</td>\n",
       "      <td>4840</td>\n",
       "      <td>3211</td>\n",
       "      <td>9124</td>\n",
       "      <td>5558</td>\n",
       "      <td>3391</td>\n",
       "      <td>2322</td>\n",
       "      <td>17926</td>\n",
       "      <td>25452</td>\n",
       "      <td>22126</td>\n",
       "      <td>...</td>\n",
       "      <td>26460</td>\n",
       "      <td>18048</td>\n",
       "      <td>3946</td>\n",
       "      <td>30740</td>\n",
       "      <td>42690</td>\n",
       "      <td>27225</td>\n",
       "      <td>23640</td>\n",
       "      <td>20317</td>\n",
       "      <td>4037</td>\n",
       "      <td>2160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NT006</td>\n",
       "      <td>4702</td>\n",
       "      <td>4569</td>\n",
       "      <td>15870</td>\n",
       "      <td>8678</td>\n",
       "      <td>3492</td>\n",
       "      <td>2603</td>\n",
       "      <td>22289</td>\n",
       "      <td>28662</td>\n",
       "      <td>24447</td>\n",
       "      <td>...</td>\n",
       "      <td>31148</td>\n",
       "      <td>20781</td>\n",
       "      <td>4981</td>\n",
       "      <td>34327</td>\n",
       "      <td>51212</td>\n",
       "      <td>28914</td>\n",
       "      <td>30115</td>\n",
       "      <td>26750</td>\n",
       "      <td>4731</td>\n",
       "      <td>3093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>CT007</td>\n",
       "      <td>4131</td>\n",
       "      <td>4518</td>\n",
       "      <td>10968</td>\n",
       "      <td>5505</td>\n",
       "      <td>4377</td>\n",
       "      <td>2553</td>\n",
       "      <td>18457</td>\n",
       "      <td>25727</td>\n",
       "      <td>20893</td>\n",
       "      <td>...</td>\n",
       "      <td>27238</td>\n",
       "      <td>18471</td>\n",
       "      <td>4792</td>\n",
       "      <td>31962</td>\n",
       "      <td>45018</td>\n",
       "      <td>24517</td>\n",
       "      <td>27573</td>\n",
       "      <td>18011</td>\n",
       "      <td>4315</td>\n",
       "      <td>2102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NT007</td>\n",
       "      <td>5453</td>\n",
       "      <td>3833</td>\n",
       "      <td>15456</td>\n",
       "      <td>8161</td>\n",
       "      <td>3569</td>\n",
       "      <td>2625</td>\n",
       "      <td>21120</td>\n",
       "      <td>33003</td>\n",
       "      <td>24306</td>\n",
       "      <td>...</td>\n",
       "      <td>29901</td>\n",
       "      <td>25245</td>\n",
       "      <td>4757</td>\n",
       "      <td>34139</td>\n",
       "      <td>55918</td>\n",
       "      <td>35641</td>\n",
       "      <td>27164</td>\n",
       "      <td>30964</td>\n",
       "      <td>5698</td>\n",
       "      <td>2409</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows  35 columns</p>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## creating csv of the lobes split into left and right by summign the parcels based on previous mapping",
   "id": "43dfcd6d849b3461"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-05T08:27:37.270444Z",
     "start_time": "2025-12-05T08:27:37.206586Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "# ---------- CONFIG ----------\n",
    "IN_CSV   = Path(\"data/stats_t1_fs/ses1/ses1_aparc_voxels_lh_rh.csv\")\n",
    "MAP_XLSX = Path(\"data/stats_t1_fs/mapping_lobes_networks.xlsx\")\n",
    "MAP_SHEET = \"aparc_voxels_normalized_ttests\"\n",
    "\n",
    "OUT_CSV = Path(\"data/stats_t1_fs/ses1/ses1_aparc_lobes_lr.csv\")\n",
    "\n",
    "AGGREGATION = \"sum\"   # \"sum\" or \"mean\"\n",
    "STRUCTNAME_COL_CANDIDATES = [\"Parameter\"]\n",
    "LOBEFILTER_COL_CANDIDATES = [\"Lobes\"]\n",
    "# --------------------------------\n",
    "\n",
    "# Pattern for columns like: insula_lh or precuneus_rh\n",
    "pat = re.compile(r\"^(?P<struct>.+)_(?P<hemi>lh|rh)$\", re.IGNORECASE)\n",
    "\n",
    "# Load LH/RH-style file\n",
    "df = pd.read_csv(IN_CSV)\n",
    "\n",
    "# All region-level columns\n",
    "lr_cols = [c for c in df.columns if pat.match(c)]\n",
    "\n",
    "# --- 2) Load mapping for struct  lobe ---\n",
    "map_df = pd.read_excel(MAP_XLSX, sheet_name=MAP_SHEET)\n",
    "col_struct = pick_column(map_df, STRUCTNAME_COL_CANDIDATES)\n",
    "col_lobe   = pick_column(map_df, LOBEFILTER_COL_CANDIDATES)\n",
    "\n",
    "map_df = map_df[[col_struct, col_lobe]].dropna()\n",
    "map_df[col_struct] = map_df[col_struct].astype(str)\n",
    "map_df[col_lobe]   = map_df[col_lobe].astype(str)\n",
    "\n",
    "# Mapping uses non-hemisphere names  slugify\n",
    "struct_to_lobe = {\n",
    "    slugify(s): slugify(l)\n",
    "    for s, l in zip(map_df[col_struct], map_df[col_lobe])\n",
    "}\n",
    "\n",
    "# --- 3) Determine structs that exist in CSV ---\n",
    "present_structs = {}\n",
    "for c in lr_cols:\n",
    "    m = pat.match(c)\n",
    "    struct = slugify(m.group(\"struct\"))\n",
    "    hemi   = m.group(\"hemi\").lower()\n",
    "    present_structs.setdefault(struct, set()).add(hemi)\n",
    "\n",
    "# Output (start with subject_code)\n",
    "out = df[[\"subject_code\"]].copy()\n",
    "\n",
    "# Lobes present in BOTH data & mapping\n",
    "lobes_present = sorted({\n",
    "    struct_to_lobe.get(struct)\n",
    "    for struct in present_structs\n",
    "    if struct_to_lobe.get(struct) is not None\n",
    "})\n",
    "\n",
    "# --- 4) Aggregate by lobe and hemisphere ---\n",
    "def reduce_cols(df, cols, how=\"sum\"):\n",
    "    if not cols:\n",
    "        return np.nan\n",
    "    vals = df[cols]\n",
    "    return vals.mean(axis=1) if how == \"mean\" else vals.sum(axis=1)\n",
    "\n",
    "for lobe in lobes_present:\n",
    "    for hemi in (\"lh\", \"rh\"):\n",
    "        cols_for_group = []\n",
    "        for struct in present_structs:\n",
    "\n",
    "            # skip if struct not assigned to this lobe\n",
    "            if struct_to_lobe.get(struct) != lobe:\n",
    "                continue\n",
    "\n",
    "            col_name = f\"{struct}_{hemi}\"\n",
    "            if col_name in df.columns:\n",
    "                cols_for_group.append(col_name)\n",
    "\n",
    "        # ALWAYS create a column (even if empty) for consistency\n",
    "        new_col = f\"{lobe}_{hemi}\"\n",
    "        out[new_col] = reduce_cols(df, cols_for_group, how=AGGREGATION)\n",
    "\n",
    "# Sort columns\n",
    "def order_key(c):\n",
    "    return \" 0\" if c == \"subject_code\" else c.lower()\n",
    "\n",
    "out = out[sorted(out.columns, key=order_key)]\n",
    "\n",
    "# Save\n",
    "OUT_CSV.parent.mkdir(parents=True, exist_ok=True)\n",
    "out.to_csv(OUT_CSV, index=False)\n",
    "\n",
    "print(f\"Saved lobe-level file: {OUT_CSV}\")\n",
    "display(out.head(10))\n"
   ],
   "id": "bc185d63f8c438f9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved lobe-level file: data\\stats_t1_fs\\ses1\\ses1_aparc_lobes_lr.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "  subject_code  cingulate_lh  cingulate_rh  frontal_lh  frontal_rh  insula_lh  \\\n",
       "0        CT002         10321          9356      102820       97325       7473   \n",
       "1        NT002          9761         10052       87508       82084       5971   \n",
       "2        CT003         10279          9813       91427       89735       6527   \n",
       "3        NT003         12000         12754      101811       97457       7572   \n",
       "4        CT004         12690         12433      104498      104087       8281   \n",
       "5        CT005          7822          9750       78605       77809       6550   \n",
       "6        NT005          7347          8684       87199       81086       7531   \n",
       "7        NT006         12661         10216      101151       98564       8291   \n",
       "8        CT007         10137         10974       90324       85976       7018   \n",
       "9        NT007         11191         10373      104291       98888       7791   \n",
       "\n",
       "   insula_rh  occipital_lh  occipital_rh  parietal_lh  parietal_rh  \\\n",
       "0       7147         21689         24583        67772        70382   \n",
       "1       6425         25620         27894        57266        57397   \n",
       "2       6714         25541         26307        65559        67570   \n",
       "3       7938         25889         26498        66390        67970   \n",
       "4       7850         26906         26111        63024        65886   \n",
       "5       6330         23938         22928        48274        49851   \n",
       "6       7202         22162         22592        53203        56096   \n",
       "7       7912         28572         31233        61578        63074   \n",
       "8       7389         23967         24637        49565        53572   \n",
       "9       7660         30179         31893        74785        76161   \n",
       "\n",
       "   temporal_lh  temporal_rh  \n",
       "0        63946        61365  \n",
       "1        53990        54959  \n",
       "2        60496        56356  \n",
       "3        60569        59749  \n",
       "4        60145        62151  \n",
       "5        51512        50577  \n",
       "6        54254        50777  \n",
       "7        66242        61658  \n",
       "8        55316        52879  \n",
       "9        60714        59602  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_code</th>\n",
       "      <th>cingulate_lh</th>\n",
       "      <th>cingulate_rh</th>\n",
       "      <th>frontal_lh</th>\n",
       "      <th>frontal_rh</th>\n",
       "      <th>insula_lh</th>\n",
       "      <th>insula_rh</th>\n",
       "      <th>occipital_lh</th>\n",
       "      <th>occipital_rh</th>\n",
       "      <th>parietal_lh</th>\n",
       "      <th>parietal_rh</th>\n",
       "      <th>temporal_lh</th>\n",
       "      <th>temporal_rh</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CT002</td>\n",
       "      <td>10321</td>\n",
       "      <td>9356</td>\n",
       "      <td>102820</td>\n",
       "      <td>97325</td>\n",
       "      <td>7473</td>\n",
       "      <td>7147</td>\n",
       "      <td>21689</td>\n",
       "      <td>24583</td>\n",
       "      <td>67772</td>\n",
       "      <td>70382</td>\n",
       "      <td>63946</td>\n",
       "      <td>61365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NT002</td>\n",
       "      <td>9761</td>\n",
       "      <td>10052</td>\n",
       "      <td>87508</td>\n",
       "      <td>82084</td>\n",
       "      <td>5971</td>\n",
       "      <td>6425</td>\n",
       "      <td>25620</td>\n",
       "      <td>27894</td>\n",
       "      <td>57266</td>\n",
       "      <td>57397</td>\n",
       "      <td>53990</td>\n",
       "      <td>54959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CT003</td>\n",
       "      <td>10279</td>\n",
       "      <td>9813</td>\n",
       "      <td>91427</td>\n",
       "      <td>89735</td>\n",
       "      <td>6527</td>\n",
       "      <td>6714</td>\n",
       "      <td>25541</td>\n",
       "      <td>26307</td>\n",
       "      <td>65559</td>\n",
       "      <td>67570</td>\n",
       "      <td>60496</td>\n",
       "      <td>56356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NT003</td>\n",
       "      <td>12000</td>\n",
       "      <td>12754</td>\n",
       "      <td>101811</td>\n",
       "      <td>97457</td>\n",
       "      <td>7572</td>\n",
       "      <td>7938</td>\n",
       "      <td>25889</td>\n",
       "      <td>26498</td>\n",
       "      <td>66390</td>\n",
       "      <td>67970</td>\n",
       "      <td>60569</td>\n",
       "      <td>59749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CT004</td>\n",
       "      <td>12690</td>\n",
       "      <td>12433</td>\n",
       "      <td>104498</td>\n",
       "      <td>104087</td>\n",
       "      <td>8281</td>\n",
       "      <td>7850</td>\n",
       "      <td>26906</td>\n",
       "      <td>26111</td>\n",
       "      <td>63024</td>\n",
       "      <td>65886</td>\n",
       "      <td>60145</td>\n",
       "      <td>62151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CT005</td>\n",
       "      <td>7822</td>\n",
       "      <td>9750</td>\n",
       "      <td>78605</td>\n",
       "      <td>77809</td>\n",
       "      <td>6550</td>\n",
       "      <td>6330</td>\n",
       "      <td>23938</td>\n",
       "      <td>22928</td>\n",
       "      <td>48274</td>\n",
       "      <td>49851</td>\n",
       "      <td>51512</td>\n",
       "      <td>50577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NT005</td>\n",
       "      <td>7347</td>\n",
       "      <td>8684</td>\n",
       "      <td>87199</td>\n",
       "      <td>81086</td>\n",
       "      <td>7531</td>\n",
       "      <td>7202</td>\n",
       "      <td>22162</td>\n",
       "      <td>22592</td>\n",
       "      <td>53203</td>\n",
       "      <td>56096</td>\n",
       "      <td>54254</td>\n",
       "      <td>50777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NT006</td>\n",
       "      <td>12661</td>\n",
       "      <td>10216</td>\n",
       "      <td>101151</td>\n",
       "      <td>98564</td>\n",
       "      <td>8291</td>\n",
       "      <td>7912</td>\n",
       "      <td>28572</td>\n",
       "      <td>31233</td>\n",
       "      <td>61578</td>\n",
       "      <td>63074</td>\n",
       "      <td>66242</td>\n",
       "      <td>61658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>CT007</td>\n",
       "      <td>10137</td>\n",
       "      <td>10974</td>\n",
       "      <td>90324</td>\n",
       "      <td>85976</td>\n",
       "      <td>7018</td>\n",
       "      <td>7389</td>\n",
       "      <td>23967</td>\n",
       "      <td>24637</td>\n",
       "      <td>49565</td>\n",
       "      <td>53572</td>\n",
       "      <td>55316</td>\n",
       "      <td>52879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NT007</td>\n",
       "      <td>11191</td>\n",
       "      <td>10373</td>\n",
       "      <td>104291</td>\n",
       "      <td>98888</td>\n",
       "      <td>7791</td>\n",
       "      <td>7660</td>\n",
       "      <td>30179</td>\n",
       "      <td>31893</td>\n",
       "      <td>74785</td>\n",
       "      <td>76161</td>\n",
       "      <td>60714</td>\n",
       "      <td>59602</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## creating csv of the lobes ( one for the while brain) by summing the parcels based on previous mapping\n",
   "id": "417a5d153e60b492"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-05T08:27:37.366508Z",
     "start_time": "2025-12-05T08:27:37.294812Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "# ---------- CONFIG ----------\n",
    "IN_CSV   = Path(\"data/stats_t1_fs/ses1/ses1_aparc_voxels_merge.csv\")\n",
    "MAP_XLSX = Path(\"data/stats_t1_fs/mapping_lobes_networks.xlsx\")\n",
    "MAP_SHEET = \"aparc_voxels_normalized_ttests\"\n",
    "\n",
    "OUT_CSV = Path(\"data/stats_t1_fs/ses1/ses1_aparc_lobes_full_brain.csv\")\n",
    "\n",
    "AGGREGATION = \"sum\"   # \"sum\" or \"mean\"\n",
    "STRUCTNAME_COL_CANDIDATES = [\"Parameter\"]\n",
    "LOBEFILTER_COL_CANDIDATES = [\"Lobes\"]\n",
    "# --------------------------------\n",
    "\n",
    "# No session pattern needed  column names are just <struct>\n",
    "df = pd.read_csv(IN_CSV)\n",
    "\n",
    "# All structural columns (exclude subject_code)\n",
    "struct_cols = [c for c in df.columns if c != \"subject_code\"]\n",
    "\n",
    "# --- Load mapping file ---\n",
    "map_df = pd.read_excel(MAP_XLSX, sheet_name=MAP_SHEET)\n",
    "\n",
    "col_struct = pick_column(map_df, STRUCTNAME_COL_CANDIDATES)\n",
    "col_lobe   = pick_column(map_df, LOBEFILTER_COL_CANDIDATES)\n",
    "\n",
    "map_df = map_df[[col_struct, col_lobe]].dropna()\n",
    "map_df[col_struct] = map_df[col_struct].astype(str)\n",
    "map_df[col_lobe]   = map_df[col_lobe].astype(str)\n",
    "\n",
    "# slugify mapping\n",
    "struct_to_lobe = {\n",
    "    slugify(s): slugify(l)\n",
    "    for s, l in zip(map_df[col_struct], map_df[col_lobe])\n",
    "}\n",
    "\n",
    "# Determine structs present in CSV\n",
    "present_structs = {slugify(c) for c in struct_cols}\n",
    "\n",
    "# Lobes present\n",
    "lobes_present = sorted({\n",
    "    struct_to_lobe.get(s)\n",
    "    for s in present_structs\n",
    "    if struct_to_lobe.get(s) is not None\n",
    "})\n",
    "\n",
    "# Output dataframe\n",
    "out = df[[\"subject_code\"]].copy()\n",
    "\n",
    "# Reduce per-lobe\n",
    "def reduce_cols(df, cols, how=\"sum\"):\n",
    "    if not cols:\n",
    "        return np.nan\n",
    "    vals = df[cols]\n",
    "    return vals.mean(axis=1) if how == \"mean\" else vals.sum(axis=1)\n",
    "\n",
    "for lobe in lobes_present:\n",
    "\n",
    "    cols_for_group = []\n",
    "\n",
    "    for struct_col in struct_cols:\n",
    "        if struct_to_lobe.get(slugify(struct_col)) == lobe:\n",
    "            cols_for_group.append(struct_col)\n",
    "\n",
    "    out[lobe] = reduce_cols(df, cols_for_group, how=AGGREGATION)\n",
    "\n",
    "# Order columns\n",
    "def order_key(c):\n",
    "    return \" 0\" if c == \"subject_code\" else c\n",
    "\n",
    "out = out[sorted(out.columns, key=order_key)]\n",
    "\n",
    "# Save\n",
    "OUT_CSV.parent.mkdir(parents=True, exist_ok=True)\n",
    "out.to_csv(OUT_CSV, index=False)\n",
    "\n",
    "print(f\"Saved lobe-level file: {OUT_CSV}\")\n",
    "display(out.head(10))\n"
   ],
   "id": "257509e081ba44f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved lobe-level file: data\\stats_t1_fs\\ses1\\ses1_aparc_lobes_full_brain.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "  subject_code  cingulate  frontal  insula  occipital  parietal  temporal\n",
       "0        CT002      19677   200145   14620      46272    138154    125311\n",
       "1        NT002      19813   169592   12396      53514    114663    108949\n",
       "2        CT003      20092   181162   13241      51848    133129    116852\n",
       "3        NT003      24754   199268   15510      52387    134360    120318\n",
       "4        CT004      25123   208585   16131      53017    128910    122296\n",
       "5        CT005      17572   156414   12880      46866     98125    102089\n",
       "6        NT005      16031   168285   14733      44754    109299    105031\n",
       "7        NT006      22877   199715   16203      59805    124652    127900\n",
       "8        CT007      21111   176300   14407      48604    103137    108195\n",
       "9        NT007      21564   203179   15451      62072    150946    120316"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_code</th>\n",
       "      <th>cingulate</th>\n",
       "      <th>frontal</th>\n",
       "      <th>insula</th>\n",
       "      <th>occipital</th>\n",
       "      <th>parietal</th>\n",
       "      <th>temporal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CT002</td>\n",
       "      <td>19677</td>\n",
       "      <td>200145</td>\n",
       "      <td>14620</td>\n",
       "      <td>46272</td>\n",
       "      <td>138154</td>\n",
       "      <td>125311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NT002</td>\n",
       "      <td>19813</td>\n",
       "      <td>169592</td>\n",
       "      <td>12396</td>\n",
       "      <td>53514</td>\n",
       "      <td>114663</td>\n",
       "      <td>108949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CT003</td>\n",
       "      <td>20092</td>\n",
       "      <td>181162</td>\n",
       "      <td>13241</td>\n",
       "      <td>51848</td>\n",
       "      <td>133129</td>\n",
       "      <td>116852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NT003</td>\n",
       "      <td>24754</td>\n",
       "      <td>199268</td>\n",
       "      <td>15510</td>\n",
       "      <td>52387</td>\n",
       "      <td>134360</td>\n",
       "      <td>120318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CT004</td>\n",
       "      <td>25123</td>\n",
       "      <td>208585</td>\n",
       "      <td>16131</td>\n",
       "      <td>53017</td>\n",
       "      <td>128910</td>\n",
       "      <td>122296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CT005</td>\n",
       "      <td>17572</td>\n",
       "      <td>156414</td>\n",
       "      <td>12880</td>\n",
       "      <td>46866</td>\n",
       "      <td>98125</td>\n",
       "      <td>102089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NT005</td>\n",
       "      <td>16031</td>\n",
       "      <td>168285</td>\n",
       "      <td>14733</td>\n",
       "      <td>44754</td>\n",
       "      <td>109299</td>\n",
       "      <td>105031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NT006</td>\n",
       "      <td>22877</td>\n",
       "      <td>199715</td>\n",
       "      <td>16203</td>\n",
       "      <td>59805</td>\n",
       "      <td>124652</td>\n",
       "      <td>127900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>CT007</td>\n",
       "      <td>21111</td>\n",
       "      <td>176300</td>\n",
       "      <td>14407</td>\n",
       "      <td>48604</td>\n",
       "      <td>103137</td>\n",
       "      <td>108195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NT007</td>\n",
       "      <td>21564</td>\n",
       "      <td>203179</td>\n",
       "      <td>15451</td>\n",
       "      <td>62072</td>\n",
       "      <td>150946</td>\n",
       "      <td>120316</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## creating csv of the  networks ( one for the while brain) by summing the parcels based on previous mapping\n",
   "id": "d41d0ea3848b97eb"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-05T08:27:37.507180Z",
     "start_time": "2025-12-05T08:27:37.396794Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "# ---------- CONFIG ----------\n",
    "IN_CSV   = Path(\"data/stats_t1_fs/ses1/ses1_aparc_voxels_merge.csv\")\n",
    "MAP_XLSX = Path(\"data/stats_t1_fs/mapping_lobes_networks.xlsx\")\n",
    "MAP_SHEET = \"aparc_voxels_normalized_ttests\"\n",
    "\n",
    "OUT_CSV = Path(\"data/stats_t1_fs/ses1/ses1_aparc_nets_full_brain.csv\")\n",
    "\n",
    "AGGREGATION = \"sum\"   # \"sum\" (default) or \"mean\"\n",
    "STRUCTNAME_COL_CANDIDATES = [\"Parameter\"]\n",
    "YEOFILTER_COL_CANDIDATES  = [\"Yeo\"]\n",
    "# --------------------------------\n",
    "\n",
    "# Pattern for columns WITHOUT sessions: <struct>\n",
    "pat = re.compile(r\"^(?P<struct>.+)$\")\n",
    "\n",
    "# 1) Load input table\n",
    "df = pd.read_csv(IN_CSV)\n",
    "\n",
    "# keep only structural columns (exclude subject_code)\n",
    "struct_cols = [c for c in df.columns if c != \"subject_code\"]\n",
    "df_struct = df[[\"subject_code\"] + struct_cols].copy()\n",
    "\n",
    "# 2) Load mapping file\n",
    "map_df = pd.read_excel(MAP_XLSX, sheet_name=MAP_SHEET)\n",
    "\n",
    "col_struct = pick_column(map_df, STRUCTNAME_COL_CANDIDATES)\n",
    "col_net    = pick_column(map_df, YEOFILTER_COL_CANDIDATES)\n",
    "\n",
    "map_df = map_df[[col_struct, col_net]].dropna()\n",
    "map_df[col_struct] = map_df[col_struct].astype(str)\n",
    "map_df[col_net]    = map_df[col_net].astype(str)\n",
    "\n",
    "# slugify mapping\n",
    "struct_to_net = {\n",
    "    slugify(s): slugify(n)\n",
    "    for s, n in zip(map_df[col_struct], map_df[col_net])\n",
    "}\n",
    "\n",
    "# Which structs exist (slugified)\n",
    "present_structs = {slugify(c) for c in struct_cols}\n",
    "\n",
    "# Networks that actually appear\n",
    "networks_present = sorted({\n",
    "    struct_to_net.get(s)\n",
    "    for s in present_structs\n",
    "    if struct_to_net.get(s)\n",
    "})\n",
    "\n",
    "# 3) Aggregate networks\n",
    "out = df_struct[[\"subject_code\"]].copy()\n",
    "\n",
    "def reduce_cols(df, cols, how=\"sum\"):\n",
    "    if not cols:\n",
    "        return np.nan\n",
    "    vals = df[cols]\n",
    "    return vals.mean(axis=1) if how == \"mean\" else vals.sum(axis=1)\n",
    "\n",
    "for net in networks_present:\n",
    "    cols_for_group = []\n",
    "\n",
    "    for struct_col in struct_cols:\n",
    "        if struct_to_net.get(slugify(struct_col)) == net:\n",
    "            cols_for_group.append(struct_col)\n",
    "\n",
    "    out[net] = reduce_cols(df_struct, cols_for_group, how=AGGREGATION)\n",
    "\n",
    "# 4) Sort\n",
    "def order_key(c):\n",
    "    return \" 0\" if c == \"subject_code\" else c\n",
    "\n",
    "out = out[sorted(out.columns, key=order_key)]\n",
    "\n",
    "# 5) Rename networks\n",
    "net_map = {\n",
    "    \"default_mode\"      : \"DMN_GM\",\n",
    "    \"dorsal_attention\"  : \"DAN_GM\",\n",
    "    \"frontoparietal\"    : \"FPN_GM\",\n",
    "    \"limbic\"            : \"LIM_GM\",\n",
    "    \"somatomotor\"       : \"SMN_GM\",\n",
    "    \"ventral_attention\" : \"VAN_GM\",\n",
    "    \"visual\"            : \"VIS_GM\",\n",
    "}\n",
    "\n",
    "out = out.rename(columns=net_map)\n",
    "\n",
    "# Save\n",
    "OUT_CSV.parent.mkdir(parents=True, exist_ok=True)\n",
    "out.to_csv(OUT_CSV, index=False)\n",
    "\n",
    "print(f\"Saved network-level file (no sessions): {OUT_CSV}\")\n",
    "display(out.head(10))\n"
   ],
   "id": "4210121da90424b2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved network-level file (no sessions): data\\stats_t1_fs\\ses1\\ses1_aparc_nets_full_brain.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "  subject_code  DMN_GM  DAN_GM  FPN_GM  LIM_GM  SMN_GM  VAN_GM  VIS_GM\n",
       "0        CT002  174423   33087   47826   65568   91028   63487   68760\n",
       "1        NT002  143547   28123   43943   60053   78053   52331   72877\n",
       "2        CT003  159872   30986   47224   66238   88987   50939   72078\n",
       "3        NT003  169448   30556   53116   65850   88287   66087   73253\n",
       "4        CT004  172948   29889   54126   67313   90927   65302   73557\n",
       "5        CT005  127745   23599   35090   55938   74339   52224   65011\n",
       "6        NT005  136769   27225   39864   58400   77743   55452   62680\n",
       "7        NT006  165192   28914   50197   65109   92349   67297   82094\n",
       "8        CT007  142435   24517   42930   59068   79272   56471   67061\n",
       "9        NT007  173935   35641   49595   66674   95932   68559   83192"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_code</th>\n",
       "      <th>DMN_GM</th>\n",
       "      <th>DAN_GM</th>\n",
       "      <th>FPN_GM</th>\n",
       "      <th>LIM_GM</th>\n",
       "      <th>SMN_GM</th>\n",
       "      <th>VAN_GM</th>\n",
       "      <th>VIS_GM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CT002</td>\n",
       "      <td>174423</td>\n",
       "      <td>33087</td>\n",
       "      <td>47826</td>\n",
       "      <td>65568</td>\n",
       "      <td>91028</td>\n",
       "      <td>63487</td>\n",
       "      <td>68760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NT002</td>\n",
       "      <td>143547</td>\n",
       "      <td>28123</td>\n",
       "      <td>43943</td>\n",
       "      <td>60053</td>\n",
       "      <td>78053</td>\n",
       "      <td>52331</td>\n",
       "      <td>72877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CT003</td>\n",
       "      <td>159872</td>\n",
       "      <td>30986</td>\n",
       "      <td>47224</td>\n",
       "      <td>66238</td>\n",
       "      <td>88987</td>\n",
       "      <td>50939</td>\n",
       "      <td>72078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NT003</td>\n",
       "      <td>169448</td>\n",
       "      <td>30556</td>\n",
       "      <td>53116</td>\n",
       "      <td>65850</td>\n",
       "      <td>88287</td>\n",
       "      <td>66087</td>\n",
       "      <td>73253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CT004</td>\n",
       "      <td>172948</td>\n",
       "      <td>29889</td>\n",
       "      <td>54126</td>\n",
       "      <td>67313</td>\n",
       "      <td>90927</td>\n",
       "      <td>65302</td>\n",
       "      <td>73557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CT005</td>\n",
       "      <td>127745</td>\n",
       "      <td>23599</td>\n",
       "      <td>35090</td>\n",
       "      <td>55938</td>\n",
       "      <td>74339</td>\n",
       "      <td>52224</td>\n",
       "      <td>65011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NT005</td>\n",
       "      <td>136769</td>\n",
       "      <td>27225</td>\n",
       "      <td>39864</td>\n",
       "      <td>58400</td>\n",
       "      <td>77743</td>\n",
       "      <td>55452</td>\n",
       "      <td>62680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NT006</td>\n",
       "      <td>165192</td>\n",
       "      <td>28914</td>\n",
       "      <td>50197</td>\n",
       "      <td>65109</td>\n",
       "      <td>92349</td>\n",
       "      <td>67297</td>\n",
       "      <td>82094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>CT007</td>\n",
       "      <td>142435</td>\n",
       "      <td>24517</td>\n",
       "      <td>42930</td>\n",
       "      <td>59068</td>\n",
       "      <td>79272</td>\n",
       "      <td>56471</td>\n",
       "      <td>67061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NT007</td>\n",
       "      <td>173935</td>\n",
       "      <td>35641</td>\n",
       "      <td>49595</td>\n",
       "      <td>66674</td>\n",
       "      <td>95932</td>\n",
       "      <td>68559</td>\n",
       "      <td>83192</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## creating the final merged file",
   "id": "c709650bf421ab70"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-05T08:27:38.735469Z",
     "start_time": "2025-12-05T08:27:37.711629Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "# ========== CONFIG ==========\n",
    "OUTPUT_XLSX = Path(\"data/stats_t1_fs/ses1/ses1_T1_data.xlsx\")\n",
    "\n",
    "# The sheet that merges TWO CSVs into one\n",
    "MERGED_SHEET_NAME = \"global_parameters\"\n",
    "MERGED_CSVS = [\n",
    "    Path(\"data/stats_t1_fs/ses1/ses1_aparc_summary_data.csv\"),\n",
    "    Path(\"data/stats_t1_fs/ses1/ses1_aseg_summary_data.csv\"),\n",
    "]\n",
    "MERGE_KEY = \"subject_code\"\n",
    "MERGE_HOW = \"outer\"           # \"inner\", \"left\", \"right\", \"outer\"\n",
    "MERGE_SUFFIXES = (\"_x\", \"_y\") # for overlapping column names\n",
    "\n",
    "# Other individual sheets: sheet_name -> csv path\n",
    "OTHER_SHEETS = {\n",
    "    \"subcortical_vol\": Path(\"data/stats_t1_fs/ses1/ses1_aseg_data.csv\"),\n",
    "    \"cortical_vol_lr\": Path(\"data/stats_t1_fs/ses1/ses1_aparc_voxels_lh_rh.csv\"),\n",
    "    \"cortical_vol_full_brain\": Path(\"data/stats_t1_fs/ses1/ses1_aparc_voxels_merge.csv\"),\n",
    "    \"cortical_lobes_lr_\": Path(\"data/stats_t1_fs/ses1/ses1_aparc_lobes_lr.csv\"),\n",
    "    \"cortical_lobes_full_brain\": Path(\"data/stats_t1_fs/ses1/ses1_aparc_lobes_full_brain.csv\"),  # <- check your path (removed .csv.csv)\n",
    "    \"cortical_networks_full_brain\": Path(\"data/stats_t1_fs/ses1/ses1_aparc_nets_full_brain.csv\"),\n",
    "}\n",
    "# ===========================\n",
    "\n",
    "# ---------- helpers (local to this cell) ----------\n",
    "\n",
    "# ---------------------------------------------------\n",
    "\n",
    "# 1) Merge the two CSVs into one sheet\n",
    "df_a = _read_csv(MERGED_CSVS[0], MERGE_KEY)\n",
    "df_b = _read_csv(MERGED_CSVS[1], MERGE_KEY)\n",
    "\n",
    "if df_a.empty and df_b.empty:\n",
    "    merged_df = pd.DataFrame(columns=[MERGE_KEY])\n",
    "else:\n",
    "    if MERGE_KEY not in df_a.columns or MERGE_KEY not in df_b.columns:\n",
    "        raise ValueError(f\"MERGE_KEY '{MERGE_KEY}' must be present in both files.\")\n",
    "    merged_df = df_a.merge(df_b, on=MERGE_KEY, how=MERGE_HOW, suffixes=MERGE_SUFFIXES)\n",
    "\n",
    "# Keep subject_code first, then sort consistently\n",
    "merged_df = _order_columns_subject_first(merged_df, MERGE_KEY)\n",
    "merged_df = _sort_consistent(merged_df, MERGE_KEY)\n",
    "\n",
    "# 2) Write everything to one Excel workbook (all sheets sorted the same way)\n",
    "with pd.ExcelWriter(OUTPUT_XLSX, engine=\"openpyxl\") as writer:\n",
    "    # merged sheet\n",
    "    merged_df.to_excel(writer, index=False, sheet_name=MERGED_SHEET_NAME[:31])\n",
    "    _autosize_columns(writer, merged_df, MERGED_SHEET_NAME[:31])\n",
    "\n",
    "    # other sheets (one CSV per sheet)\n",
    "    for sheet_name, csv_path in OTHER_SHEETS.items():\n",
    "        df = _read_csv(csv_path, MERGE_KEY)\n",
    "        df = _order_columns_subject_first(df, MERGE_KEY)\n",
    "        df = _sort_consistent(df, MERGE_KEY)\n",
    "        safe_name = sheet_name[:31]  # Excel sheet name limit is 31 chars\n",
    "        df.to_excel(writer, index=False, sheet_name=safe_name)\n",
    "        _autosize_columns(writer, df, safe_name)\n",
    "\n",
    "print(f\"Saved Excel workbook: {OUTPUT_XLSX}\")\n"
   ],
   "id": "d49d7871edaac3b2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Excel workbook: data\\stats_t1_fs\\ses1\\ses1_T1_data.xlsx\n"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## adding dict columsn sheet for the final merged excel",
   "id": "bd6f1bfc0f160173"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-05T08:27:39.291082Z",
     "start_time": "2025-12-05T08:27:38.781866Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "MAP_XLSX = Path(\"data/stats_t1_fs/ses1/ses1_T1_data.xlsx\")\n",
    "\n",
    "# Load workbook\n",
    "xlsx = pd.ExcelFile(MAP_XLSX)\n",
    "\n",
    "print(\" Sheets found in workbook:\\n\")\n",
    "\n",
    "for sheet in xlsx.sheet_names:\n",
    "    print(f\"--- Sheet: {sheet} ---\")\n",
    "    df = pd.read_excel(MAP_XLSX, sheet_name=sheet)\n",
    "    print(\"Columns:\", list(df.columns))\n",
    "    print()\n"
   ],
   "id": "cedb0fff4ce8073e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Sheets found in workbook:\n",
      "\n",
      "--- Sheet: global_parameters ---\n",
      "Columns: ['subject_code', 'meanthickness_lh', 'meanthickness_rh', 'whitesurfarea_lh', 'whitesurfarea_rh', 'brainsegvol', 'cerebralwhitemattervol', 'cortexvol', 'etiv', 'lhcortexvol', 'rhcortexvol', 'subcortgrayvol', 'totalgrayvol']\n",
      "\n",
      "--- Sheet: subcortical_vol ---\n",
      "Columns: ['subject_code', '3rd_ventricle', '4th_ventricle', '5th_ventricle', 'brain_stem', 'cc_anterior', 'cc_central', 'cc_mid_anterior', 'cc_mid_posterior', 'cc_posterior', 'csf', 'left_accumbens_area', 'left_amygdala', 'left_caudate', 'left_cerebellum_cortex', 'left_cerebellum_white_matter', 'left_choroid_plexus', 'left_hippocampus', 'left_inf_lat_vent', 'left_lateral_ventricle', 'left_non_wm_hypointensities', 'left_pallidum', 'left_putamen', 'left_thalamus', 'left_ventraldc', 'left_vessel', 'left_wm_hypointensities', 'non_wm_hypointensities', 'optic_chiasm', 'right_accumbens_area', 'right_amygdala', 'right_caudate', 'right_cerebellum_cortex', 'right_cerebellum_white_matter', 'right_choroid_plexus', 'right_hippocampus', 'right_inf_lat_vent', 'right_lateral_ventricle', 'right_non_wm_hypointensities', 'right_pallidum', 'right_putamen', 'right_thalamus', 'right_ventraldc', 'right_vessel', 'right_wm_hypointensities', 'wm_hypointensities']\n",
      "\n",
      "--- Sheet: cortical_vol_lr ---\n",
      "Columns: ['subject_code', 'bankssts_lh', 'bankssts_rh', 'caudalanteriorcingulate_lh', 'caudalanteriorcingulate_rh', 'caudalmiddlefrontal_lh', 'caudalmiddlefrontal_rh', 'cuneus_lh', 'cuneus_rh', 'entorhinal_lh', 'entorhinal_rh', 'frontalpole_lh', 'frontalpole_rh', 'fusiform_lh', 'fusiform_rh', 'inferiorparietal_lh', 'inferiorparietal_rh', 'inferiortemporal_lh', 'inferiortemporal_rh', 'insula_lh', 'insula_rh', 'isthmuscingulate_lh', 'isthmuscingulate_rh', 'lateraloccipital_lh', 'lateraloccipital_rh', 'lateralorbitofrontal_lh', 'lateralorbitofrontal_rh', 'lingual_lh', 'lingual_rh', 'medialorbitofrontal_lh', 'medialorbitofrontal_rh', 'middletemporal_lh', 'middletemporal_rh', 'paracentral_lh', 'paracentral_rh', 'parahippocampal_lh', 'parahippocampal_rh', 'parsopercularis_lh', 'parsopercularis_rh', 'parsorbitalis_lh', 'parsorbitalis_rh', 'parstriangularis_lh', 'parstriangularis_rh', 'pericalcarine_lh', 'pericalcarine_rh', 'postcentral_lh', 'postcentral_rh', 'posteriorcingulate_lh', 'posteriorcingulate_rh', 'precentral_lh', 'precentral_rh', 'precuneus_lh', 'precuneus_rh', 'rostralanteriorcingulate_lh', 'rostralanteriorcingulate_rh', 'rostralmiddlefrontal_lh', 'rostralmiddlefrontal_rh', 'superiorfrontal_lh', 'superiorfrontal_rh', 'superiorparietal_lh', 'superiorparietal_rh', 'superiortemporal_lh', 'superiortemporal_rh', 'supramarginal_lh', 'supramarginal_rh', 'temporalpole_lh', 'temporalpole_rh', 'transversetemporal_lh', 'transversetemporal_rh']\n",
      "\n",
      "--- Sheet: cortical_vol_full_brain ---\n",
      "Columns: ['subject_code', 'bankssts', 'caudalanteriorcingulate', 'caudalmiddlefrontal', 'cuneus', 'entorhinal', 'frontalpole', 'fusiform', 'inferiorparietal', 'inferiortemporal', 'insula', 'isthmuscingulate', 'lateraloccipital', 'lateralorbitofrontal', 'lingual', 'medialorbitofrontal', 'middletemporal', 'paracentral', 'parahippocampal', 'parsopercularis', 'parsorbitalis', 'parstriangularis', 'pericalcarine', 'postcentral', 'posteriorcingulate', 'precentral', 'precuneus', 'rostralanteriorcingulate', 'rostralmiddlefrontal', 'superiorfrontal', 'superiorparietal', 'superiortemporal', 'supramarginal', 'temporalpole', 'transversetemporal']\n",
      "\n",
      "--- Sheet: cortical_lobes_lr_ ---\n",
      "Columns: ['subject_code', 'cingulate_lh', 'cingulate_rh', 'frontal_lh', 'frontal_rh', 'insula_lh', 'insula_rh', 'occipital_lh', 'occipital_rh', 'parietal_lh', 'parietal_rh', 'temporal_lh', 'temporal_rh']\n",
      "\n",
      "--- Sheet: cortical_lobes_full_brain ---\n",
      "Columns: ['subject_code', 'cingulate', 'frontal', 'insula', 'occipital', 'parietal', 'temporal']\n",
      "\n",
      "--- Sheet: cortical_networks_full_brain ---\n",
      "Columns: ['subject_code', 'DMN_GM', 'DAN_GM', 'FPN_GM', 'LIM_GM', 'SMN_GM', 'VAN_GM', 'VIS_GM']\n",
      "\n"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-05T08:27:40.545134Z",
     "start_time": "2025-12-05T08:27:39.328564Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "from openpyxl import load_workbook\n",
    "\n",
    "# ---------- CONFIG ----------\n",
    "EXCEL_PATH = \"data/stats_t1_fs/ses1/ses1_T1_data.xlsx\"\n",
    "DICT_SHEET = \"dict_columns\"\n",
    "# ----------------------------\n",
    "\n",
    "# Load workbook\n",
    "wb = load_workbook(EXCEL_PATH)\n",
    "\n",
    "# If dict_columns already exists  delete it (fresh rebuild)\n",
    "if DICT_SHEET in wb.sheetnames:\n",
    "    wb.remove(wb[DICT_SHEET])\n",
    "\n",
    "# Create new empty sheet\n",
    "ws = wb.create_sheet(DICT_SHEET)\n",
    "\n",
    "# Load sheet names using pandas\n",
    "xlsx = pd.ExcelFile(EXCEL_PATH)\n",
    "\n",
    "current_col = 1  # Start in column A\n",
    "\n",
    "for sheet in xlsx.sheet_names:\n",
    "\n",
    "    # Write sheet name in row 1\n",
    "    ws.cell(row=1, column=current_col, value=sheet)\n",
    "\n",
    "    # Load the sheet to get the columns\n",
    "    df = pd.read_excel(EXCEL_PATH, sheet_name=sheet)\n",
    "\n",
    "    # Write each column name below\n",
    "    for row_i, col_name in enumerate(df.columns, start=2):\n",
    "        ws.cell(row=row_i, column=current_col, value=col_name)\n",
    "\n",
    "    # Move 3 columns right  1 for data, 2 blank columns between blocks\n",
    "    current_col += 3\n",
    "\n",
    "# Save updated workbook (same file)\n",
    "wb.save(EXCEL_PATH)\n",
    "\n",
    "print(f\"Sheet '{DICT_SHEET}' created and saved into {EXCEL_PATH}\")\n"
   ],
   "id": "339571f221d37827",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sheet 'dict_columns' created and saved into data/stats_t1_fs/ses1/ses1_T1_data.xlsx\n"
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# second session",
   "id": "d72d6cb712891f52"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## extracting from the subject file the cortical volumes and merge nto one csv file\n",
   "id": "15506f02808dce64"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-05T08:27:41.988669Z",
     "start_time": "2025-12-05T08:27:40.581358Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# ---------- CONFIG ----------\n",
    "FOLDER = Path(\"data/stats_t1_fs\")  # change to your folder\n",
    "OUT_CSV = Path(\"data/stats_t1_fs/ses2/ses2_aparc_voxels_lh_rh.csv\")  # output file\n",
    "SHEET_NAME = \"aparc_voxels\"  # sheet to read\n",
    "RECURSIVE = False            # set True if files are in subfolders\n",
    "# ----------------------------\n",
    "\n",
    "file_regex = re.compile(\n",
    "    r\"sub-(?P<subject>\\d{3})_(?P<group>CT|NT)_ses-(?P<session>[12])_merged\\.xlsx$\",\n",
    "    re.IGNORECASE,\n",
    ")\n",
    "\n",
    "# Accumulate rows keyed by subject_code\n",
    "rows_by_subject = {}\n",
    "all_feature_cols = set()\n",
    "files = list_excel_files(FOLDER, RECURSIVE)\n",
    "for path in files:\n",
    "    print(\"FULL PATH :\", repr(str(path)))\n",
    "    print(\"NAME ONLY :\", repr(path.name))\n",
    "    m = file_regex.match(path.name)\n",
    "    print(m)\n",
    "    if not m:\n",
    "        continue\n",
    "\n",
    "    subject = m.group(\"subject\")\n",
    "    group = m.group(\"group\").upper()\n",
    "    session = int(m.group(\"session\"))\n",
    "    print(session)\n",
    "\n",
    "    # --- ONLY PROCESS SESSION 1 ---\n",
    "    if session != 2:\n",
    "        continue\n",
    "\n",
    "    subject_code = f\"{group}{subject}\"\n",
    "\n",
    "    try:\n",
    "        df = pd.read_excel(path, sheet_name=SHEET_NAME)\n",
    "    except Exception as e:\n",
    "        print(f\"Warning: couldn't read sheet '{SHEET_NAME}' in {path.name}: {e}\")\n",
    "        continue\n",
    "\n",
    "    # Locate columns\n",
    "    col_struct = pick_column(df, [\"StructName\"])\n",
    "    col_hemi   = pick_column(df, [\"Hemisphere\"])\n",
    "    col_gray   = pick_column(df, [\"GrayVol\"])\n",
    "\n",
    "    if not all([col_struct, col_hemi, col_gray]):\n",
    "        print(f\"Warning: missing needed columns in {path.name}. \"\n",
    "              f\"StructName={col_struct}, Hemisphere={col_hemi}, GrayVol={col_gray}\")\n",
    "        continue\n",
    "\n",
    "    # Initialize row\n",
    "    if subject_code not in rows_by_subject:\n",
    "        rows_by_subject[subject_code] = {\"subject_code\": subject_code}\n",
    "\n",
    "    # Process rows\n",
    "    for _, row in df.iterrows():\n",
    "        struct = slugify(row[col_struct])\n",
    "        hemi = slugify(row[col_hemi])\n",
    "\n",
    "        if hemi in (\"left\", \"l\"): hemi = \"lh\"\n",
    "        if hemi in (\"right\", \"r\"): hemi = \"rh\"\n",
    "\n",
    "        if not struct or hemi not in (\"lh\", \"rh\"):\n",
    "            continue\n",
    "\n",
    "        # --- NEW: COLUMN NAME WITHOUT SESSION ---\n",
    "        col_name = f\"{struct}_{hemi}\"\n",
    "\n",
    "        # Convert to numeric\n",
    "        val = row[col_gray]\n",
    "        try:\n",
    "            val = pd.to_numeric(val)\n",
    "        except:\n",
    "            val = np.nan\n",
    "\n",
    "        rows_by_subject[subject_code][col_name] = val\n",
    "        all_feature_cols.add(col_name)\n",
    "\n",
    "all_columns = [\"subject_code\"] + sorted(all_feature_cols, key=col_sort_key)\n",
    "\n",
    "# Build DataFrame\n",
    "df_out = pd.DataFrame(rows_by_subject.values())\n",
    "for c in all_columns:\n",
    "    if c not in df_out.columns:\n",
    "        df_out[c] = np.nan\n",
    "df_out = df_out[all_columns]\n",
    "\n",
    "# Save\n",
    "OUT_CSV.parent.mkdir(parents=True, exist_ok=True)\n",
    "df_out.to_csv(OUT_CSV, index=False)\n",
    "\n",
    "print(f\"Saved: {OUT_CSV}\")\n",
    "display(df_out.head(5))\n",
    "\n"
   ],
   "id": "86696e11e6dbf83e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FULL PATH : 'data\\\\stats_t1_fs\\\\mapping_lobes_networks.xlsx'\n",
      "NAME ONLY : 'mapping_lobes_networks.xlsx'\n",
      "None\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-002_CT_ses-1_merged.xlsx'\n",
      "NAME ONLY : 'sub-002_CT_ses-1_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-002_CT_ses-1_merged.xlsx'>\n",
      "1\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-002_NT_ses-1_merged.xlsx'\n",
      "NAME ONLY : 'sub-002_NT_ses-1_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-002_NT_ses-1_merged.xlsx'>\n",
      "1\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-002_NT_ses-2_merged.xlsx'\n",
      "NAME ONLY : 'sub-002_NT_ses-2_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-002_NT_ses-2_merged.xlsx'>\n",
      "2\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-003_CT_ses-1_merged.xlsx'\n",
      "NAME ONLY : 'sub-003_CT_ses-1_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-003_CT_ses-1_merged.xlsx'>\n",
      "1\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-003_CT_ses-2_merged.xlsx'\n",
      "NAME ONLY : 'sub-003_CT_ses-2_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-003_CT_ses-2_merged.xlsx'>\n",
      "2\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-003_NT_ses-1_merged.xlsx'\n",
      "NAME ONLY : 'sub-003_NT_ses-1_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-003_NT_ses-1_merged.xlsx'>\n",
      "1\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-004_CT_ses-1_merged.xlsx'\n",
      "NAME ONLY : 'sub-004_CT_ses-1_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-004_CT_ses-1_merged.xlsx'>\n",
      "1\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-005_CT_ses-1_merged.xlsx'\n",
      "NAME ONLY : 'sub-005_CT_ses-1_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-005_CT_ses-1_merged.xlsx'>\n",
      "1\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-005_NT_ses-1_merged.xlsx'\n",
      "NAME ONLY : 'sub-005_NT_ses-1_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-005_NT_ses-1_merged.xlsx'>\n",
      "1\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-005_NT_ses-2_merged.xlsx'\n",
      "NAME ONLY : 'sub-005_NT_ses-2_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-005_NT_ses-2_merged.xlsx'>\n",
      "2\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-006_NT_ses-1_merged.xlsx'\n",
      "NAME ONLY : 'sub-006_NT_ses-1_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-006_NT_ses-1_merged.xlsx'>\n",
      "1\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-007_CT_ses-1_merged.xlsx'\n",
      "NAME ONLY : 'sub-007_CT_ses-1_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-007_CT_ses-1_merged.xlsx'>\n",
      "1\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-007_CT_ses-2_merged.xlsx'\n",
      "NAME ONLY : 'sub-007_CT_ses-2_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-007_CT_ses-2_merged.xlsx'>\n",
      "2\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-007_NT_ses-1_merged.xlsx'\n",
      "NAME ONLY : 'sub-007_NT_ses-1_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-007_NT_ses-1_merged.xlsx'>\n",
      "1\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-008_CT_ses-1_merged.xlsx'\n",
      "NAME ONLY : 'sub-008_CT_ses-1_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-008_CT_ses-1_merged.xlsx'>\n",
      "1\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-010_CT_ses-1_merged.xlsx'\n",
      "NAME ONLY : 'sub-010_CT_ses-1_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-010_CT_ses-1_merged.xlsx'>\n",
      "1\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-010_CT_ses-2_merged.xlsx'\n",
      "NAME ONLY : 'sub-010_CT_ses-2_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-010_CT_ses-2_merged.xlsx'>\n",
      "2\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-010_NT_ses-1_merged.xlsx'\n",
      "NAME ONLY : 'sub-010_NT_ses-1_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-010_NT_ses-1_merged.xlsx'>\n",
      "1\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-012_CT_ses-1_merged.xlsx'\n",
      "NAME ONLY : 'sub-012_CT_ses-1_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-012_CT_ses-1_merged.xlsx'>\n",
      "1\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-012_CT_ses-2_merged.xlsx'\n",
      "NAME ONLY : 'sub-012_CT_ses-2_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-012_CT_ses-2_merged.xlsx'>\n",
      "2\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-013_CT_ses-1_merged.xlsx'\n",
      "NAME ONLY : 'sub-013_CT_ses-1_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-013_CT_ses-1_merged.xlsx'>\n",
      "1\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-013_CT_ses-2_merged.xlsx'\n",
      "NAME ONLY : 'sub-013_CT_ses-2_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-013_CT_ses-2_merged.xlsx'>\n",
      "2\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-013_NT_ses-1_merged.xlsx'\n",
      "NAME ONLY : 'sub-013_NT_ses-1_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-013_NT_ses-1_merged.xlsx'>\n",
      "1\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-015_CT_ses-1_merged.xlsx'\n",
      "NAME ONLY : 'sub-015_CT_ses-1_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-015_CT_ses-1_merged.xlsx'>\n",
      "1\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-015_NT_ses-1_merged.xlsx'\n",
      "NAME ONLY : 'sub-015_NT_ses-1_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-015_NT_ses-1_merged.xlsx'>\n",
      "1\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-015_NT_ses-2_merged.xlsx'\n",
      "NAME ONLY : 'sub-015_NT_ses-2_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-015_NT_ses-2_merged.xlsx'>\n",
      "2\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-015_NT_ses-3_merged.xlsx'\n",
      "NAME ONLY : 'sub-015_NT_ses-3_merged.xlsx'\n",
      "None\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-016_CT_ses-1_merged.xlsx'\n",
      "NAME ONLY : 'sub-016_CT_ses-1_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-016_CT_ses-1_merged.xlsx'>\n",
      "1\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-016_NT_ses-1_merged.xlsx'\n",
      "NAME ONLY : 'sub-016_NT_ses-1_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-016_NT_ses-1_merged.xlsx'>\n",
      "1\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-016_NT_ses-2_merged.xlsx'\n",
      "NAME ONLY : 'sub-016_NT_ses-2_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-016_NT_ses-2_merged.xlsx'>\n",
      "2\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-017_CT_ses-1_merged.xlsx'\n",
      "NAME ONLY : 'sub-017_CT_ses-1_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-017_CT_ses-1_merged.xlsx'>\n",
      "1\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-017_NT_ses-1_merged.xlsx'\n",
      "NAME ONLY : 'sub-017_NT_ses-1_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-017_NT_ses-1_merged.xlsx'>\n",
      "1\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-017_NT_ses-2_merged.xlsx'\n",
      "NAME ONLY : 'sub-017_NT_ses-2_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-017_NT_ses-2_merged.xlsx'>\n",
      "2\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-018_CT_ses-1_merged.xlsx'\n",
      "NAME ONLY : 'sub-018_CT_ses-1_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-018_CT_ses-1_merged.xlsx'>\n",
      "1\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-018_CT_ses-2_merged.xlsx'\n",
      "NAME ONLY : 'sub-018_CT_ses-2_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-018_CT_ses-2_merged.xlsx'>\n",
      "2\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-019_NT_ses-1_merged.xlsx'\n",
      "NAME ONLY : 'sub-019_NT_ses-1_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-019_NT_ses-1_merged.xlsx'>\n",
      "1\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-020_CT_ses-1_merged.xlsx'\n",
      "NAME ONLY : 'sub-020_CT_ses-1_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-020_CT_ses-1_merged.xlsx'>\n",
      "1\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-020_NT_ses-1_merged.xlsx'\n",
      "NAME ONLY : 'sub-020_NT_ses-1_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-020_NT_ses-1_merged.xlsx'>\n",
      "1\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-020_NT_ses-2_merged.xlsx'\n",
      "NAME ONLY : 'sub-020_NT_ses-2_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-020_NT_ses-2_merged.xlsx'>\n",
      "2\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-021_CT_ses-1_merged.xlsx'\n",
      "NAME ONLY : 'sub-021_CT_ses-1_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-021_CT_ses-1_merged.xlsx'>\n",
      "1\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-023_CT_ses-1_merged.xlsx'\n",
      "NAME ONLY : 'sub-023_CT_ses-1_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-023_CT_ses-1_merged.xlsx'>\n",
      "1\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-024_CT_ses-1_merged.xlsx'\n",
      "NAME ONLY : 'sub-024_CT_ses-1_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-024_CT_ses-1_merged.xlsx'>\n",
      "1\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-025_CT_ses-1_merged.xlsx'\n",
      "NAME ONLY : 'sub-025_CT_ses-1_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-025_CT_ses-1_merged.xlsx'>\n",
      "1\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-025_NT_ses-1_merged.xlsx'\n",
      "NAME ONLY : 'sub-025_NT_ses-1_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-025_NT_ses-1_merged.xlsx'>\n",
      "1\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-025_NT_ses-2_merged.xlsx'\n",
      "NAME ONLY : 'sub-025_NT_ses-2_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-025_NT_ses-2_merged.xlsx'>\n",
      "2\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-026_CT_ses-1_merged.xlsx'\n",
      "NAME ONLY : 'sub-026_CT_ses-1_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-026_CT_ses-1_merged.xlsx'>\n",
      "1\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-026_NT_ses-1_merged.xlsx'\n",
      "NAME ONLY : 'sub-026_NT_ses-1_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-026_NT_ses-1_merged.xlsx'>\n",
      "1\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-026_NT_ses-2_merged.xlsx'\n",
      "NAME ONLY : 'sub-026_NT_ses-2_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-026_NT_ses-2_merged.xlsx'>\n",
      "2\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-027_CT_ses-1_merged.xlsx'\n",
      "NAME ONLY : 'sub-027_CT_ses-1_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-027_CT_ses-1_merged.xlsx'>\n",
      "1\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-027_CT_ses-2_merged.xlsx'\n",
      "NAME ONLY : 'sub-027_CT_ses-2_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-027_CT_ses-2_merged.xlsx'>\n",
      "2\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-027_NT_ses-1_merged.xlsx'\n",
      "NAME ONLY : 'sub-027_NT_ses-1_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-027_NT_ses-1_merged.xlsx'>\n",
      "1\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-027_NT_ses-2_merged.xlsx'\n",
      "NAME ONLY : 'sub-027_NT_ses-2_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-027_NT_ses-2_merged.xlsx'>\n",
      "2\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-028_CT_ses-1_merged.xlsx'\n",
      "NAME ONLY : 'sub-028_CT_ses-1_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-028_CT_ses-1_merged.xlsx'>\n",
      "1\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-028_NT_ses-1_merged.xlsx'\n",
      "NAME ONLY : 'sub-028_NT_ses-1_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-028_NT_ses-1_merged.xlsx'>\n",
      "1\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-029_CT_ses-1_merged.xlsx'\n",
      "NAME ONLY : 'sub-029_CT_ses-1_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-029_CT_ses-1_merged.xlsx'>\n",
      "1\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-029_CT_ses-2_merged.xlsx'\n",
      "NAME ONLY : 'sub-029_CT_ses-2_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-029_CT_ses-2_merged.xlsx'>\n",
      "2\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-029_NT_ses-1_merged.xlsx'\n",
      "NAME ONLY : 'sub-029_NT_ses-1_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-029_NT_ses-1_merged.xlsx'>\n",
      "1\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-030_CT_ses-1_merged.xlsx'\n",
      "NAME ONLY : 'sub-030_CT_ses-1_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-030_CT_ses-1_merged.xlsx'>\n",
      "1\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-030_NT_ses-1_merged.xlsx'\n",
      "NAME ONLY : 'sub-030_NT_ses-1_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-030_NT_ses-1_merged.xlsx'>\n",
      "1\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-031_NT_ses-1_merged.xlsx'\n",
      "NAME ONLY : 'sub-031_NT_ses-1_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-031_NT_ses-1_merged.xlsx'>\n",
      "1\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-031_NT_ses-2_merged.xlsx'\n",
      "NAME ONLY : 'sub-031_NT_ses-2_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-031_NT_ses-2_merged.xlsx'>\n",
      "2\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-032_CT_ses-1_merged.xlsx'\n",
      "NAME ONLY : 'sub-032_CT_ses-1_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-032_CT_ses-1_merged.xlsx'>\n",
      "1\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-032_CT_ses-2_merged.xlsx'\n",
      "NAME ONLY : 'sub-032_CT_ses-2_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-032_CT_ses-2_merged.xlsx'>\n",
      "2\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-032_NT_ses-1_merged.xlsx'\n",
      "NAME ONLY : 'sub-032_NT_ses-1_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-032_NT_ses-1_merged.xlsx'>\n",
      "1\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-033_CT_ses-1_merged.xlsx'\n",
      "NAME ONLY : 'sub-033_CT_ses-1_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-033_CT_ses-1_merged.xlsx'>\n",
      "1\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-033_NT_ses-1_merged.xlsx'\n",
      "NAME ONLY : 'sub-033_NT_ses-1_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-033_NT_ses-1_merged.xlsx'>\n",
      "1\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-033_NT_ses-2_merged.xlsx'\n",
      "NAME ONLY : 'sub-033_NT_ses-2_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-033_NT_ses-2_merged.xlsx'>\n",
      "2\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-034_CT_ses-1_merged.xlsx'\n",
      "NAME ONLY : 'sub-034_CT_ses-1_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-034_CT_ses-1_merged.xlsx'>\n",
      "1\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-035_CT_ses-1_merged.xlsx'\n",
      "NAME ONLY : 'sub-035_CT_ses-1_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-035_CT_ses-1_merged.xlsx'>\n",
      "1\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-035_NT_ses-1_merged.xlsx'\n",
      "NAME ONLY : 'sub-035_NT_ses-1_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-035_NT_ses-1_merged.xlsx'>\n",
      "1\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-036_NT_ses-1_merged.xlsx'\n",
      "NAME ONLY : 'sub-036_NT_ses-1_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-036_NT_ses-1_merged.xlsx'>\n",
      "1\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-036_NT_ses-2_merged.xlsx'\n",
      "NAME ONLY : 'sub-036_NT_ses-2_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-036_NT_ses-2_merged.xlsx'>\n",
      "2\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-038_NT_ses-1_merged.xlsx'\n",
      "NAME ONLY : 'sub-038_NT_ses-1_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-038_NT_ses-1_merged.xlsx'>\n",
      "1\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-039_CT_ses-1_merged.xlsx'\n",
      "NAME ONLY : 'sub-039_CT_ses-1_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-039_CT_ses-1_merged.xlsx'>\n",
      "1\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-039_CT_ses-2_merged.xlsx'\n",
      "NAME ONLY : 'sub-039_CT_ses-2_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-039_CT_ses-2_merged.xlsx'>\n",
      "2\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-039_NT_ses-1_merged.xlsx'\n",
      "NAME ONLY : 'sub-039_NT_ses-1_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-039_NT_ses-1_merged.xlsx'>\n",
      "1\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-040_NT_ses-1_merged.xlsx'\n",
      "NAME ONLY : 'sub-040_NT_ses-1_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-040_NT_ses-1_merged.xlsx'>\n",
      "1\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-040_NT_ses-2_merged.xlsx'\n",
      "NAME ONLY : 'sub-040_NT_ses-2_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-040_NT_ses-2_merged.xlsx'>\n",
      "2\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-041_CT_ses-1_merged.xlsx'\n",
      "NAME ONLY : 'sub-041_CT_ses-1_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-041_CT_ses-1_merged.xlsx'>\n",
      "1\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-041_CT_ses-2_merged.xlsx'\n",
      "NAME ONLY : 'sub-041_CT_ses-2_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-041_CT_ses-2_merged.xlsx'>\n",
      "2\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-041_NT_ses-1_merged.xlsx'\n",
      "NAME ONLY : 'sub-041_NT_ses-1_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-041_NT_ses-1_merged.xlsx'>\n",
      "1\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-041_NT_ses-2_merged.xlsx'\n",
      "NAME ONLY : 'sub-041_NT_ses-2_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-041_NT_ses-2_merged.xlsx'>\n",
      "2\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-042_CT_ses-1_merged.xlsx'\n",
      "NAME ONLY : 'sub-042_CT_ses-1_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-042_CT_ses-1_merged.xlsx'>\n",
      "1\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-042_NT_ses-1_merged.xlsx'\n",
      "NAME ONLY : 'sub-042_NT_ses-1_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-042_NT_ses-1_merged.xlsx'>\n",
      "1\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-043_CT_ses-1_merged.xlsx'\n",
      "NAME ONLY : 'sub-043_CT_ses-1_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-043_CT_ses-1_merged.xlsx'>\n",
      "1\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-043_CT_ses-2_merged.xlsx'\n",
      "NAME ONLY : 'sub-043_CT_ses-2_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-043_CT_ses-2_merged.xlsx'>\n",
      "2\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-043_NT_ses-1_merged.xlsx'\n",
      "NAME ONLY : 'sub-043_NT_ses-1_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-043_NT_ses-1_merged.xlsx'>\n",
      "1\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-044_NT_ses-1_merged.xlsx'\n",
      "NAME ONLY : 'sub-044_NT_ses-1_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-044_NT_ses-1_merged.xlsx'>\n",
      "1\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-044_NT_ses-2_merged.xlsx'\n",
      "NAME ONLY : 'sub-044_NT_ses-2_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-044_NT_ses-2_merged.xlsx'>\n",
      "2\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-046_CT_ses-1_merged.xlsx'\n",
      "NAME ONLY : 'sub-046_CT_ses-1_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-046_CT_ses-1_merged.xlsx'>\n",
      "1\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-046_CT_ses-2_merged.xlsx'\n",
      "NAME ONLY : 'sub-046_CT_ses-2_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-046_CT_ses-2_merged.xlsx'>\n",
      "2\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-047_NT_ses-1_merged.xlsx'\n",
      "NAME ONLY : 'sub-047_NT_ses-1_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-047_NT_ses-1_merged.xlsx'>\n",
      "1\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-047_NT_ses-2_merged.xlsx'\n",
      "NAME ONLY : 'sub-047_NT_ses-2_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-047_NT_ses-2_merged.xlsx'>\n",
      "2\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-047_NT_ses-3_merged.xlsx'\n",
      "NAME ONLY : 'sub-047_NT_ses-3_merged.xlsx'\n",
      "None\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-048_NT_ses-1_merged.xlsx'\n",
      "NAME ONLY : 'sub-048_NT_ses-1_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-048_NT_ses-1_merged.xlsx'>\n",
      "1\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-049_NT_ses-1_merged.xlsx'\n",
      "NAME ONLY : 'sub-049_NT_ses-1_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-049_NT_ses-1_merged.xlsx'>\n",
      "1\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-049_NT_ses-2_merged.xlsx'\n",
      "NAME ONLY : 'sub-049_NT_ses-2_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-049_NT_ses-2_merged.xlsx'>\n",
      "2\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-051_CT_ses-1_merged.xlsx'\n",
      "NAME ONLY : 'sub-051_CT_ses-1_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-051_CT_ses-1_merged.xlsx'>\n",
      "1\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-051_NT_ses-1_merged.xlsx'\n",
      "NAME ONLY : 'sub-051_NT_ses-1_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-051_NT_ses-1_merged.xlsx'>\n",
      "1\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-051_NT_ses-2_merged.xlsx'\n",
      "NAME ONLY : 'sub-051_NT_ses-2_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-051_NT_ses-2_merged.xlsx'>\n",
      "2\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-052_NT_ses-1_merged.xlsx'\n",
      "NAME ONLY : 'sub-052_NT_ses-1_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-052_NT_ses-1_merged.xlsx'>\n",
      "1\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-053_NT_ses-1_merged.xlsx'\n",
      "NAME ONLY : 'sub-053_NT_ses-1_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-053_NT_ses-1_merged.xlsx'>\n",
      "1\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-055_NT_ses-1_merged.xlsx'\n",
      "NAME ONLY : 'sub-055_NT_ses-1_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-055_NT_ses-1_merged.xlsx'>\n",
      "1\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-056_CT_ses-1_merged.xlsx'\n",
      "NAME ONLY : 'sub-056_CT_ses-1_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-056_CT_ses-1_merged.xlsx'>\n",
      "1\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-056_NT_ses-1_merged.xlsx'\n",
      "NAME ONLY : 'sub-056_NT_ses-1_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-056_NT_ses-1_merged.xlsx'>\n",
      "1\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-056_NT_ses-2_merged.xlsx'\n",
      "NAME ONLY : 'sub-056_NT_ses-2_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-056_NT_ses-2_merged.xlsx'>\n",
      "2\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-057_CT_ses-1_merged.xlsx'\n",
      "NAME ONLY : 'sub-057_CT_ses-1_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-057_CT_ses-1_merged.xlsx'>\n",
      "1\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-057_NT_ses-1_merged.xlsx'\n",
      "NAME ONLY : 'sub-057_NT_ses-1_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-057_NT_ses-1_merged.xlsx'>\n",
      "1\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-058_CT_ses-1_merged.xlsx'\n",
      "NAME ONLY : 'sub-058_CT_ses-1_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-058_CT_ses-1_merged.xlsx'>\n",
      "1\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-058_CT_ses-2_merged.xlsx'\n",
      "NAME ONLY : 'sub-058_CT_ses-2_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-058_CT_ses-2_merged.xlsx'>\n",
      "2\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-059_NT_ses-1_merged.xlsx'\n",
      "NAME ONLY : 'sub-059_NT_ses-1_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-059_NT_ses-1_merged.xlsx'>\n",
      "1\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-059_NT_ses-2_merged.xlsx'\n",
      "NAME ONLY : 'sub-059_NT_ses-2_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-059_NT_ses-2_merged.xlsx'>\n",
      "2\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-060_NT_ses-1_merged.xlsx'\n",
      "NAME ONLY : 'sub-060_NT_ses-1_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-060_NT_ses-1_merged.xlsx'>\n",
      "1\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-062_CT_ses-1_merged.xlsx'\n",
      "NAME ONLY : 'sub-062_CT_ses-1_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-062_CT_ses-1_merged.xlsx'>\n",
      "1\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-062_CT_ses-2_merged.xlsx'\n",
      "NAME ONLY : 'sub-062_CT_ses-2_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-062_CT_ses-2_merged.xlsx'>\n",
      "2\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-063_NT_ses-1_merged.xlsx'\n",
      "NAME ONLY : 'sub-063_NT_ses-1_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-063_NT_ses-1_merged.xlsx'>\n",
      "1\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-065_CT_ses-1_merged.xlsx'\n",
      "NAME ONLY : 'sub-065_CT_ses-1_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-065_CT_ses-1_merged.xlsx'>\n",
      "1\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-065_NT_ses-1_merged.xlsx'\n",
      "NAME ONLY : 'sub-065_NT_ses-1_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-065_NT_ses-1_merged.xlsx'>\n",
      "1\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-066_NT_ses-1_merged.xlsx'\n",
      "NAME ONLY : 'sub-066_NT_ses-1_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-066_NT_ses-1_merged.xlsx'>\n",
      "1\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-067_NT_ses-1_merged.xlsx'\n",
      "NAME ONLY : 'sub-067_NT_ses-1_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-067_NT_ses-1_merged.xlsx'>\n",
      "1\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-068_NT_ses-1_merged.xlsx'\n",
      "NAME ONLY : 'sub-068_NT_ses-1_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-068_NT_ses-1_merged.xlsx'>\n",
      "1\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-069_NT_ses-1_merged.xlsx'\n",
      "NAME ONLY : 'sub-069_NT_ses-1_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-069_NT_ses-1_merged.xlsx'>\n",
      "1\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-070_NT_ses-1_merged.xlsx'\n",
      "NAME ONLY : 'sub-070_NT_ses-1_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-070_NT_ses-1_merged.xlsx'>\n",
      "1\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-070_NT_ses-2_merged.xlsx'\n",
      "NAME ONLY : 'sub-070_NT_ses-2_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-070_NT_ses-2_merged.xlsx'>\n",
      "2\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-074_NT_ses-1_merged.xlsx'\n",
      "NAME ONLY : 'sub-074_NT_ses-1_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-074_NT_ses-1_merged.xlsx'>\n",
      "1\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-075_NT_ses-1_merged.xlsx'\n",
      "NAME ONLY : 'sub-075_NT_ses-1_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-075_NT_ses-1_merged.xlsx'>\n",
      "1\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-077_NT_ses-1_merged.xlsx'\n",
      "NAME ONLY : 'sub-077_NT_ses-1_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-077_NT_ses-1_merged.xlsx'>\n",
      "1\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-078_NT_ses-1_merged.xlsx'\n",
      "NAME ONLY : 'sub-078_NT_ses-1_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-078_NT_ses-1_merged.xlsx'>\n",
      "1\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-080_NT_ses-1_merged.xlsx'\n",
      "NAME ONLY : 'sub-080_NT_ses-1_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-080_NT_ses-1_merged.xlsx'>\n",
      "1\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-081_NT_ses-1_merged.xlsx'\n",
      "NAME ONLY : 'sub-081_NT_ses-1_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-081_NT_ses-1_merged.xlsx'>\n",
      "1\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-081_NT_ses-2_merged.xlsx'\n",
      "NAME ONLY : 'sub-081_NT_ses-2_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-081_NT_ses-2_merged.xlsx'>\n",
      "2\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-082_NT_ses-1_merged.xlsx'\n",
      "NAME ONLY : 'sub-082_NT_ses-1_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-082_NT_ses-1_merged.xlsx'>\n",
      "1\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-082_NT_ses-2_merged.xlsx'\n",
      "NAME ONLY : 'sub-082_NT_ses-2_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-082_NT_ses-2_merged.xlsx'>\n",
      "2\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-082_NT_ses-3_merged.xlsx'\n",
      "NAME ONLY : 'sub-082_NT_ses-3_merged.xlsx'\n",
      "None\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-083_NT_ses-1_merged.xlsx'\n",
      "NAME ONLY : 'sub-083_NT_ses-1_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-083_NT_ses-1_merged.xlsx'>\n",
      "1\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-087_NT_ses-1_merged.xlsx'\n",
      "NAME ONLY : 'sub-087_NT_ses-1_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-087_NT_ses-1_merged.xlsx'>\n",
      "1\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-088_NT_ses-1_merged.xlsx'\n",
      "NAME ONLY : 'sub-088_NT_ses-1_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-088_NT_ses-1_merged.xlsx'>\n",
      "1\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-090_NT_ses-1_merged.xlsx'\n",
      "NAME ONLY : 'sub-090_NT_ses-1_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-090_NT_ses-1_merged.xlsx'>\n",
      "1\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-090_NT_ses-2_merged.xlsx'\n",
      "NAME ONLY : 'sub-090_NT_ses-2_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-090_NT_ses-2_merged.xlsx'>\n",
      "2\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-093_NT_ses-1_merged.xlsx'\n",
      "NAME ONLY : 'sub-093_NT_ses-1_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-093_NT_ses-1_merged.xlsx'>\n",
      "1\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-093_NT_ses-2_merged.xlsx'\n",
      "NAME ONLY : 'sub-093_NT_ses-2_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-093_NT_ses-2_merged.xlsx'>\n",
      "2\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-096_NT_ses-1_merged.xlsx'\n",
      "NAME ONLY : 'sub-096_NT_ses-1_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-096_NT_ses-1_merged.xlsx'>\n",
      "1\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-096_NT_ses-2_merged.xlsx'\n",
      "NAME ONLY : 'sub-096_NT_ses-2_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-096_NT_ses-2_merged.xlsx'>\n",
      "2\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-100_NT_ses-1_merged.xlsx'\n",
      "NAME ONLY : 'sub-100_NT_ses-1_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-100_NT_ses-1_merged.xlsx'>\n",
      "1\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-106_NT_ses-1_merged.xlsx'\n",
      "NAME ONLY : 'sub-106_NT_ses-1_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-106_NT_ses-1_merged.xlsx'>\n",
      "1\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-112_NT_ses-1_merged.xlsx'\n",
      "NAME ONLY : 'sub-112_NT_ses-1_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-112_NT_ses-1_merged.xlsx'>\n",
      "1\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-113_NT_ses-1_merged.xlsx'\n",
      "NAME ONLY : 'sub-113_NT_ses-1_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-113_NT_ses-1_merged.xlsx'>\n",
      "1\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-114_NT_ses-1_merged.xlsx'\n",
      "NAME ONLY : 'sub-114_NT_ses-1_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-114_NT_ses-1_merged.xlsx'>\n",
      "1\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-118_NT_ses-1_merged.xlsx'\n",
      "NAME ONLY : 'sub-118_NT_ses-1_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-118_NT_ses-1_merged.xlsx'>\n",
      "1\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-119_NT_ses-1_merged.xlsx'\n",
      "NAME ONLY : 'sub-119_NT_ses-1_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-119_NT_ses-1_merged.xlsx'>\n",
      "1\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-121_NT_ses-1_merged.xlsx'\n",
      "NAME ONLY : 'sub-121_NT_ses-1_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-121_NT_ses-1_merged.xlsx'>\n",
      "1\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-124_NT_ses-1_merged.xlsx'\n",
      "NAME ONLY : 'sub-124_NT_ses-1_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-124_NT_ses-1_merged.xlsx'>\n",
      "1\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-125_NT_ses-1_merged.xlsx'\n",
      "NAME ONLY : 'sub-125_NT_ses-1_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-125_NT_ses-1_merged.xlsx'>\n",
      "1\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-126_NT_ses-1_merged.xlsx'\n",
      "NAME ONLY : 'sub-126_NT_ses-1_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-126_NT_ses-1_merged.xlsx'>\n",
      "1\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-131_NT_ses-1_merged.xlsx'\n",
      "NAME ONLY : 'sub-131_NT_ses-1_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-131_NT_ses-1_merged.xlsx'>\n",
      "1\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-132_NT_ses-1_merged.xlsx'\n",
      "NAME ONLY : 'sub-132_NT_ses-1_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-132_NT_ses-1_merged.xlsx'>\n",
      "1\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-134_NT_ses-1_merged.xlsx'\n",
      "NAME ONLY : 'sub-134_NT_ses-1_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-134_NT_ses-1_merged.xlsx'>\n",
      "1\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-135_NT_ses-1_merged.xlsx'\n",
      "NAME ONLY : 'sub-135_NT_ses-1_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-135_NT_ses-1_merged.xlsx'>\n",
      "1\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-137_NT_ses-1_merged.xlsx'\n",
      "NAME ONLY : 'sub-137_NT_ses-1_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-137_NT_ses-1_merged.xlsx'>\n",
      "1\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-138_NT_ses-1_merged.xlsx'\n",
      "NAME ONLY : 'sub-138_NT_ses-1_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-138_NT_ses-1_merged.xlsx'>\n",
      "1\n",
      "FULL PATH : 'data\\\\stats_t1_fs\\\\sub-142_NT_ses-1_merged.xlsx'\n",
      "NAME ONLY : 'sub-142_NT_ses-1_merged.xlsx'\n",
      "<re.Match object; span=(0, 28), match='sub-142_NT_ses-1_merged.xlsx'>\n",
      "1\n",
      "Saved: data\\stats_t1_fs\\ses2\\ses2_aparc_voxels_lh_rh.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "  subject_code  bankssts_lh  bankssts_rh  caudalanteriorcingulate_lh  \\\n",
       "0        NT002         2644         1935                        1446   \n",
       "1        CT003         2449         2528                        1693   \n",
       "2        NT005         2611         2153                         975   \n",
       "3        CT007         2020         2106                        1813   \n",
       "4        CT010         2480         2242                        1481   \n",
       "\n",
       "   caudalanteriorcingulate_rh  caudalmiddlefrontal_lh  caudalmiddlefrontal_rh  \\\n",
       "0                        1999                    5706                    5937   \n",
       "1                        1978                    7022                    5961   \n",
       "2                        2121                    3774                    4359   \n",
       "3                        2729                    5464                    6269   \n",
       "4                        2313                    5247                    3316   \n",
       "\n",
       "   cuneus_lh  cuneus_rh  entorhinal_lh  ...  superiorparietal_lh  \\\n",
       "0       3152       5006           1523  ...                13392   \n",
       "1       2956       3309           1987  ...                14936   \n",
       "2       2451       2767           2010  ...                11910   \n",
       "3       2844       2909           1888  ...                12173   \n",
       "4       3048       3672           1536  ...                14381   \n",
       "\n",
       "   superiorparietal_rh  superiortemporal_lh  superiortemporal_rh  \\\n",
       "0                14360                11952                12036   \n",
       "1                14817                11607                12440   \n",
       "2                12556                11662                10863   \n",
       "3                12493                13761                12980   \n",
       "4                 9522                12082                10763   \n",
       "\n",
       "   supramarginal_lh  supramarginal_rh  temporalpole_lh  temporalpole_rh  \\\n",
       "0             10211              9902             2388             2386   \n",
       "1              9317              9477             3147             2882   \n",
       "2              9166              9764             2690             2699   \n",
       "3              9319              8923             3149             2569   \n",
       "4             13357              6827             2289             2235   \n",
       "\n",
       "   transversetemporal_lh  transversetemporal_rh  \n",
       "0                    961                    816  \n",
       "1                    950                    757  \n",
       "2                   1117                    805  \n",
       "3                   1195                    750  \n",
       "4                   1127                    800  \n",
       "\n",
       "[5 rows x 69 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_code</th>\n",
       "      <th>bankssts_lh</th>\n",
       "      <th>bankssts_rh</th>\n",
       "      <th>caudalanteriorcingulate_lh</th>\n",
       "      <th>caudalanteriorcingulate_rh</th>\n",
       "      <th>caudalmiddlefrontal_lh</th>\n",
       "      <th>caudalmiddlefrontal_rh</th>\n",
       "      <th>cuneus_lh</th>\n",
       "      <th>cuneus_rh</th>\n",
       "      <th>entorhinal_lh</th>\n",
       "      <th>...</th>\n",
       "      <th>superiorparietal_lh</th>\n",
       "      <th>superiorparietal_rh</th>\n",
       "      <th>superiortemporal_lh</th>\n",
       "      <th>superiortemporal_rh</th>\n",
       "      <th>supramarginal_lh</th>\n",
       "      <th>supramarginal_rh</th>\n",
       "      <th>temporalpole_lh</th>\n",
       "      <th>temporalpole_rh</th>\n",
       "      <th>transversetemporal_lh</th>\n",
       "      <th>transversetemporal_rh</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NT002</td>\n",
       "      <td>2644</td>\n",
       "      <td>1935</td>\n",
       "      <td>1446</td>\n",
       "      <td>1999</td>\n",
       "      <td>5706</td>\n",
       "      <td>5937</td>\n",
       "      <td>3152</td>\n",
       "      <td>5006</td>\n",
       "      <td>1523</td>\n",
       "      <td>...</td>\n",
       "      <td>13392</td>\n",
       "      <td>14360</td>\n",
       "      <td>11952</td>\n",
       "      <td>12036</td>\n",
       "      <td>10211</td>\n",
       "      <td>9902</td>\n",
       "      <td>2388</td>\n",
       "      <td>2386</td>\n",
       "      <td>961</td>\n",
       "      <td>816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CT003</td>\n",
       "      <td>2449</td>\n",
       "      <td>2528</td>\n",
       "      <td>1693</td>\n",
       "      <td>1978</td>\n",
       "      <td>7022</td>\n",
       "      <td>5961</td>\n",
       "      <td>2956</td>\n",
       "      <td>3309</td>\n",
       "      <td>1987</td>\n",
       "      <td>...</td>\n",
       "      <td>14936</td>\n",
       "      <td>14817</td>\n",
       "      <td>11607</td>\n",
       "      <td>12440</td>\n",
       "      <td>9317</td>\n",
       "      <td>9477</td>\n",
       "      <td>3147</td>\n",
       "      <td>2882</td>\n",
       "      <td>950</td>\n",
       "      <td>757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NT005</td>\n",
       "      <td>2611</td>\n",
       "      <td>2153</td>\n",
       "      <td>975</td>\n",
       "      <td>2121</td>\n",
       "      <td>3774</td>\n",
       "      <td>4359</td>\n",
       "      <td>2451</td>\n",
       "      <td>2767</td>\n",
       "      <td>2010</td>\n",
       "      <td>...</td>\n",
       "      <td>11910</td>\n",
       "      <td>12556</td>\n",
       "      <td>11662</td>\n",
       "      <td>10863</td>\n",
       "      <td>9166</td>\n",
       "      <td>9764</td>\n",
       "      <td>2690</td>\n",
       "      <td>2699</td>\n",
       "      <td>1117</td>\n",
       "      <td>805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CT007</td>\n",
       "      <td>2020</td>\n",
       "      <td>2106</td>\n",
       "      <td>1813</td>\n",
       "      <td>2729</td>\n",
       "      <td>5464</td>\n",
       "      <td>6269</td>\n",
       "      <td>2844</td>\n",
       "      <td>2909</td>\n",
       "      <td>1888</td>\n",
       "      <td>...</td>\n",
       "      <td>12173</td>\n",
       "      <td>12493</td>\n",
       "      <td>13761</td>\n",
       "      <td>12980</td>\n",
       "      <td>9319</td>\n",
       "      <td>8923</td>\n",
       "      <td>3149</td>\n",
       "      <td>2569</td>\n",
       "      <td>1195</td>\n",
       "      <td>750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CT010</td>\n",
       "      <td>2480</td>\n",
       "      <td>2242</td>\n",
       "      <td>1481</td>\n",
       "      <td>2313</td>\n",
       "      <td>5247</td>\n",
       "      <td>3316</td>\n",
       "      <td>3048</td>\n",
       "      <td>3672</td>\n",
       "      <td>1536</td>\n",
       "      <td>...</td>\n",
       "      <td>14381</td>\n",
       "      <td>9522</td>\n",
       "      <td>12082</td>\n",
       "      <td>10763</td>\n",
       "      <td>13357</td>\n",
       "      <td>6827</td>\n",
       "      <td>2289</td>\n",
       "      <td>2235</td>\n",
       "      <td>1127</td>\n",
       "      <td>800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  69 columns</p>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## extracting from the subject file subcortical   volumes and merge nto one csv file\n",
   "id": "8a2ba08379864c5f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-05T08:27:43.398692Z",
     "start_time": "2025-12-05T08:27:42.021770Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ---------- CONFIG ----------\n",
    "FOLDER = Path(\"data/stats_t1_fs\")\n",
    "OUT_CSV = Path(\"data/stats_t1_fs/ses2/ses2_aseg_data.csv\")\n",
    "SHEET_NAME = \"aseg_voxels\"\n",
    "RECURSIVE = False\n",
    "# ----------------------------\n",
    "\n",
    "rows_by_subject = {}\n",
    "all_feature_cols = set()\n",
    "\n",
    "files = list_excel_files(FOLDER, RECURSIVE)\n",
    "for path in files:\n",
    "\n",
    "    m = file_regex.match(path.name)\n",
    "    if not m:\n",
    "        continue\n",
    "\n",
    "    subject = m.group(\"subject\")\n",
    "    group = m.group(\"group\").upper()\n",
    "    session = int(m.group(\"session\"))\n",
    "\n",
    "    # --- ONLY USE SESSION 1 ---\n",
    "    if session != 2:\n",
    "        continue\n",
    "\n",
    "    subject_code = f\"{group}{subject}\"\n",
    "\n",
    "    # read the aseg sheet\n",
    "    try:\n",
    "        df = pd.read_excel(path, sheet_name=SHEET_NAME)\n",
    "    except Exception as e:\n",
    "        print(f\"Warning: couldn't read sheet '{SHEET_NAME}' in {path.name}: {e}\")\n",
    "        continue\n",
    "\n",
    "    # locate required columns\n",
    "    col_struct = pick_column(df, [\"StructName\"])\n",
    "    col_gray   = pick_column(df, [\"Volume_mm3\"])\n",
    "\n",
    "    if not all([col_struct, col_gray]):\n",
    "        print(f\"Warning: missing needed columns in {path.name}. struct={col_struct}, vol={col_gray}\")\n",
    "        continue\n",
    "\n",
    "    # initialize subject row\n",
    "    if subject_code not in rows_by_subject:\n",
    "        rows_by_subject[subject_code] = {\"subject_code\": subject_code}\n",
    "\n",
    "    # iterate rows\n",
    "    for _, row in df.iterrows():\n",
    "        struct = slugify(row[col_struct])\n",
    "        if not struct:\n",
    "            continue\n",
    "\n",
    "        # --- FIX: NO SESSION SUFFIX ---\n",
    "        col_name = struct\n",
    "\n",
    "        val = row[col_gray]\n",
    "        try:\n",
    "            val = pd.to_numeric(val)\n",
    "        except:\n",
    "            val = np.nan\n",
    "\n",
    "        rows_by_subject[subject_code][col_name] = val\n",
    "        all_feature_cols.add(col_name)\n",
    "\n",
    "    # optional logging\n",
    "\n",
    "\n",
    "# final table columns\n",
    "all_columns = [\"subject_code\"] + sorted(all_feature_cols, key=col_sort_key)\n",
    "\n",
    "# build wide dataframe\n",
    "df_out = pd.DataFrame(rows_by_subject.values())\n",
    "\n",
    "# ensure missing columns exist\n",
    "for c in all_columns:\n",
    "    if c not in df_out.columns:\n",
    "        df_out[c] = np.nan\n",
    "\n",
    "df_out = df_out[all_columns]\n",
    "\n",
    "# write CSV\n",
    "OUT_CSV.parent.mkdir(parents=True, exist_ok=True)\n",
    "df_out.to_csv(OUT_CSV, index=False)\n",
    "\n",
    "print(f\"Saved: {OUT_CSV}\")\n",
    "display(df_out.head(5))\n"
   ],
   "id": "f452b2ffb33bc0e9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: data\\stats_t1_fs\\ses2\\ses2_aseg_data.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "  subject_code  3rd_ventricle  4th_ventricle  5th_ventricle  brain_stem  \\\n",
       "0        NT002          848.4          905.7            0.0     20227.2   \n",
       "1        CT003          862.2         1549.3            0.0     20067.4   \n",
       "2        NT005          797.4         1390.6            0.0     20013.8   \n",
       "3        CT007          828.3         2001.5            0.0     23184.8   \n",
       "4        CT010          929.1         2334.6            0.0     22725.4   \n",
       "\n",
       "   cc_anterior  cc_central  cc_mid_anterior  cc_mid_posterior  cc_posterior  \\\n",
       "0        548.6       628.3            438.2             413.8         924.2   \n",
       "1        831.1       802.5            562.7             609.9        1018.2   \n",
       "2       1070.8       558.3            543.2             550.4         980.0   \n",
       "3       1042.7       555.1            495.4             513.4         903.0   \n",
       "4        949.6       569.6            579.7             633.7        1000.1   \n",
       "\n",
       "   ...  right_inf_lat_vent  right_lateral_ventricle  \\\n",
       "0  ...               256.2                   3414.7   \n",
       "1  ...               375.8                   5374.1   \n",
       "2  ...               206.8                   5780.1   \n",
       "3  ...               493.2                   3372.9   \n",
       "4  ...               181.7                   6904.5   \n",
       "\n",
       "   right_non_wm_hypointensities  right_pallidum  right_putamen  \\\n",
       "0                           0.0          1773.5         4982.9   \n",
       "1                           0.0          2034.5         4818.3   \n",
       "2                           0.0          1825.2         4853.3   \n",
       "3                           0.0          2095.8         4702.1   \n",
       "4                           0.0          1988.0         4664.7   \n",
       "\n",
       "   right_thalamus  right_ventraldc  right_vessel  right_wm_hypointensities  \\\n",
       "0          6935.9           4155.3          27.5                       0.0   \n",
       "1          7209.8           3917.4           9.2                       0.0   \n",
       "2          6618.6           3493.4          41.5                       0.0   \n",
       "3          8321.4           4114.4           7.6                       0.0   \n",
       "4          7374.2           4148.9          10.6                       0.0   \n",
       "\n",
       "   wm_hypointensities  \n",
       "0               534.4  \n",
       "1               809.0  \n",
       "2               340.5  \n",
       "3               685.5  \n",
       "4               535.8  \n",
       "\n",
       "[5 rows x 46 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_code</th>\n",
       "      <th>3rd_ventricle</th>\n",
       "      <th>4th_ventricle</th>\n",
       "      <th>5th_ventricle</th>\n",
       "      <th>brain_stem</th>\n",
       "      <th>cc_anterior</th>\n",
       "      <th>cc_central</th>\n",
       "      <th>cc_mid_anterior</th>\n",
       "      <th>cc_mid_posterior</th>\n",
       "      <th>cc_posterior</th>\n",
       "      <th>...</th>\n",
       "      <th>right_inf_lat_vent</th>\n",
       "      <th>right_lateral_ventricle</th>\n",
       "      <th>right_non_wm_hypointensities</th>\n",
       "      <th>right_pallidum</th>\n",
       "      <th>right_putamen</th>\n",
       "      <th>right_thalamus</th>\n",
       "      <th>right_ventraldc</th>\n",
       "      <th>right_vessel</th>\n",
       "      <th>right_wm_hypointensities</th>\n",
       "      <th>wm_hypointensities</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NT002</td>\n",
       "      <td>848.4</td>\n",
       "      <td>905.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20227.2</td>\n",
       "      <td>548.6</td>\n",
       "      <td>628.3</td>\n",
       "      <td>438.2</td>\n",
       "      <td>413.8</td>\n",
       "      <td>924.2</td>\n",
       "      <td>...</td>\n",
       "      <td>256.2</td>\n",
       "      <td>3414.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1773.5</td>\n",
       "      <td>4982.9</td>\n",
       "      <td>6935.9</td>\n",
       "      <td>4155.3</td>\n",
       "      <td>27.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>534.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CT003</td>\n",
       "      <td>862.2</td>\n",
       "      <td>1549.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20067.4</td>\n",
       "      <td>831.1</td>\n",
       "      <td>802.5</td>\n",
       "      <td>562.7</td>\n",
       "      <td>609.9</td>\n",
       "      <td>1018.2</td>\n",
       "      <td>...</td>\n",
       "      <td>375.8</td>\n",
       "      <td>5374.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2034.5</td>\n",
       "      <td>4818.3</td>\n",
       "      <td>7209.8</td>\n",
       "      <td>3917.4</td>\n",
       "      <td>9.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>809.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NT005</td>\n",
       "      <td>797.4</td>\n",
       "      <td>1390.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20013.8</td>\n",
       "      <td>1070.8</td>\n",
       "      <td>558.3</td>\n",
       "      <td>543.2</td>\n",
       "      <td>550.4</td>\n",
       "      <td>980.0</td>\n",
       "      <td>...</td>\n",
       "      <td>206.8</td>\n",
       "      <td>5780.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1825.2</td>\n",
       "      <td>4853.3</td>\n",
       "      <td>6618.6</td>\n",
       "      <td>3493.4</td>\n",
       "      <td>41.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>340.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CT007</td>\n",
       "      <td>828.3</td>\n",
       "      <td>2001.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23184.8</td>\n",
       "      <td>1042.7</td>\n",
       "      <td>555.1</td>\n",
       "      <td>495.4</td>\n",
       "      <td>513.4</td>\n",
       "      <td>903.0</td>\n",
       "      <td>...</td>\n",
       "      <td>493.2</td>\n",
       "      <td>3372.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2095.8</td>\n",
       "      <td>4702.1</td>\n",
       "      <td>8321.4</td>\n",
       "      <td>4114.4</td>\n",
       "      <td>7.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>685.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CT010</td>\n",
       "      <td>929.1</td>\n",
       "      <td>2334.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22725.4</td>\n",
       "      <td>949.6</td>\n",
       "      <td>569.6</td>\n",
       "      <td>579.7</td>\n",
       "      <td>633.7</td>\n",
       "      <td>1000.1</td>\n",
       "      <td>...</td>\n",
       "      <td>181.7</td>\n",
       "      <td>6904.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1988.0</td>\n",
       "      <td>4664.7</td>\n",
       "      <td>7374.2</td>\n",
       "      <td>4148.9</td>\n",
       "      <td>10.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>535.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  46 columns</p>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## extracting from the subject file white matter  volumes and merge nto one csv file\n",
   "id": "97e017ad10f7bcf9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-05T08:27:44.769791Z",
     "start_time": "2025-12-05T08:27:43.438819Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ---------- CONFIG ----------\n",
    "FOLDER = Path(\"data/stats_t1_fs\")\n",
    "OUT_CSV = Path(\"data/stats_t1_fs/ses2/ses2_wmparc_data.csv\")\n",
    "SHEET_NAME = \"wmparc_voxels\"\n",
    "RECURSIVE = False\n",
    "# ----------------------------\n",
    "\n",
    "rows_by_subject = {}\n",
    "all_feature_cols = set()\n",
    "\n",
    "files = list_excel_files(FOLDER, RECURSIVE)\n",
    "for path in files:\n",
    "\n",
    "    m = file_regex.match(path.name)\n",
    "    if not m:\n",
    "        continue\n",
    "\n",
    "    subject = m.group(\"subject\")\n",
    "    group = m.group(\"group\").upper()\n",
    "    session = int(m.group(\"session\"))\n",
    "\n",
    "    # --- ONLY USE SESSION 2 ---\n",
    "    if session != 2:\n",
    "        continue\n",
    "\n",
    "    subject_code = f\"{group}{subject}\"\n",
    "\n",
    "    # Load wmparc sheet\n",
    "    try:\n",
    "        df = pd.read_excel(path, sheet_name=SHEET_NAME)\n",
    "    except Exception as e:\n",
    "        print(f\"Warning: couldn't read sheet '{SHEET_NAME}' in {path.name}: {e}\")\n",
    "        continue\n",
    "\n",
    "    # Identify needed columns\n",
    "    col_struct = pick_column(df, [\"StructName\"])\n",
    "    col_gray   = pick_column(df, [\"Volume_mm3\"])\n",
    "\n",
    "    if not all([col_struct, col_gray]):\n",
    "        print(f\"Warning: missing needed columns in {path.name}. struct={col_struct}, vol={col_gray}\")\n",
    "        continue\n",
    "\n",
    "    # Initialize subject row\n",
    "    if subject_code not in rows_by_subject:\n",
    "        rows_by_subject[subject_code] = {\"subject_code\": subject_code}\n",
    "\n",
    "    # Process each ROI row\n",
    "    for _, row in df.iterrows():\n",
    "        struct = slugify(row[col_struct])\n",
    "        if not struct:\n",
    "            continue\n",
    "\n",
    "        # --- FIX: remove session suffix ---\n",
    "        col_name = struct\n",
    "\n",
    "        # convert to numeric\n",
    "        val = row[col_gray]\n",
    "        try:\n",
    "            val = pd.to_numeric(val)\n",
    "        except:\n",
    "            val = np.nan\n",
    "\n",
    "        rows_by_subject[subject_code][col_name] = val\n",
    "        all_feature_cols.add(col_name)\n",
    "\n",
    "    # optional tracking\n",
    "\n",
    "# Final set of columns\n",
    "all_columns = [\"subject_code\"] + sorted(all_feature_cols, key=col_sort_key)\n",
    "\n",
    "# Build final table\n",
    "df_out = pd.DataFrame(rows_by_subject.values())\n",
    "\n",
    "# Ensure all expected columns exist\n",
    "for c in all_columns:\n",
    "    if c not in df_out.columns:\n",
    "        df_out[c] = np.nan\n",
    "\n",
    "df_out = df_out[all_columns]\n",
    "\n",
    "# Save CSV\n",
    "OUT_CSV.parent.mkdir(parents=True, exist_ok=True)\n",
    "df_out.to_csv(OUT_CSV, index=False)\n",
    "\n",
    "print(f\"Saved: {OUT_CSV}\")\n",
    "display(df_out.head(5))\n"
   ],
   "id": "1530b09556a40d42",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: data\\stats_t1_fs\\ses2\\ses2_wmparc_data.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "  subject_code  left_unsegmentedwhitematter  right_unsegmentedwhitematter  \\\n",
       "0        NT002                      28138.1                       27934.5   \n",
       "1        CT003                      34201.5                       32796.0   \n",
       "2        NT005                      29960.9                       29078.1   \n",
       "3        CT007                      27850.0                       26192.0   \n",
       "4        CT010                      30400.2                       29906.1   \n",
       "\n",
       "   wm_lh_bankssts  wm_lh_caudalanteriorcingulate  wm_lh_caudalmiddlefrontal  \\\n",
       "0          3346.1                         2363.5                     5982.7   \n",
       "1          3869.8                         3267.3                     6825.3   \n",
       "2          2449.1                         1753.1                     5141.3   \n",
       "3          2645.3                         2805.1                     5603.7   \n",
       "4          2644.2                         2442.0                     5439.7   \n",
       "\n",
       "   wm_lh_cuneus  wm_lh_entorhinal  wm_lh_frontalpole  wm_lh_fusiform  ...  \\\n",
       "0        3255.9             935.9              345.5          5776.8  ...   \n",
       "1        2413.0            1057.0              251.3          7752.2  ...   \n",
       "2        2153.2            1091.9              316.1          6663.4  ...   \n",
       "3        2895.4             983.7              294.7          6849.4  ...   \n",
       "4        2033.0             834.0              245.2          5858.6  ...   \n",
       "\n",
       "   wm_rh_precentral  wm_rh_precuneus  wm_rh_rostralanteriorcingulate  \\\n",
       "0           11894.0           7826.5                          1654.8   \n",
       "1           14339.5          10000.5                          1983.3   \n",
       "2           11004.1           8994.9                          1718.3   \n",
       "3           14219.8           9203.9                          2052.4   \n",
       "4            8442.9           6909.4                          1882.0   \n",
       "\n",
       "   wm_rh_rostralmiddlefrontal  wm_rh_superiorfrontal  wm_rh_superiorparietal  \\\n",
       "0                     11424.0                14914.6                 11592.3   \n",
       "1                     12883.4                16902.2                 12273.0   \n",
       "2                     11836.7                15599.8                 11877.5   \n",
       "3                     11762.2                17044.1                 10797.5   \n",
       "4                     18911.9                18284.5                  9114.2   \n",
       "\n",
       "   wm_rh_superiortemporal  wm_rh_supramarginal  wm_rh_temporalpole  \\\n",
       "0                  6787.5               7414.4               658.3   \n",
       "1                  6022.7               8070.5               832.0   \n",
       "2                  6080.8               8108.6               644.7   \n",
       "3                  6750.9               7203.6               774.1   \n",
       "4                  5758.8               4446.7               692.8   \n",
       "\n",
       "   wm_rh_transversetemporal  \n",
       "0                     478.0  \n",
       "1                     504.7  \n",
       "2                     422.8  \n",
       "3                     418.0  \n",
       "4                     615.9  \n",
       "\n",
       "[5 rows x 71 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_code</th>\n",
       "      <th>left_unsegmentedwhitematter</th>\n",
       "      <th>right_unsegmentedwhitematter</th>\n",
       "      <th>wm_lh_bankssts</th>\n",
       "      <th>wm_lh_caudalanteriorcingulate</th>\n",
       "      <th>wm_lh_caudalmiddlefrontal</th>\n",
       "      <th>wm_lh_cuneus</th>\n",
       "      <th>wm_lh_entorhinal</th>\n",
       "      <th>wm_lh_frontalpole</th>\n",
       "      <th>wm_lh_fusiform</th>\n",
       "      <th>...</th>\n",
       "      <th>wm_rh_precentral</th>\n",
       "      <th>wm_rh_precuneus</th>\n",
       "      <th>wm_rh_rostralanteriorcingulate</th>\n",
       "      <th>wm_rh_rostralmiddlefrontal</th>\n",
       "      <th>wm_rh_superiorfrontal</th>\n",
       "      <th>wm_rh_superiorparietal</th>\n",
       "      <th>wm_rh_superiortemporal</th>\n",
       "      <th>wm_rh_supramarginal</th>\n",
       "      <th>wm_rh_temporalpole</th>\n",
       "      <th>wm_rh_transversetemporal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NT002</td>\n",
       "      <td>28138.1</td>\n",
       "      <td>27934.5</td>\n",
       "      <td>3346.1</td>\n",
       "      <td>2363.5</td>\n",
       "      <td>5982.7</td>\n",
       "      <td>3255.9</td>\n",
       "      <td>935.9</td>\n",
       "      <td>345.5</td>\n",
       "      <td>5776.8</td>\n",
       "      <td>...</td>\n",
       "      <td>11894.0</td>\n",
       "      <td>7826.5</td>\n",
       "      <td>1654.8</td>\n",
       "      <td>11424.0</td>\n",
       "      <td>14914.6</td>\n",
       "      <td>11592.3</td>\n",
       "      <td>6787.5</td>\n",
       "      <td>7414.4</td>\n",
       "      <td>658.3</td>\n",
       "      <td>478.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CT003</td>\n",
       "      <td>34201.5</td>\n",
       "      <td>32796.0</td>\n",
       "      <td>3869.8</td>\n",
       "      <td>3267.3</td>\n",
       "      <td>6825.3</td>\n",
       "      <td>2413.0</td>\n",
       "      <td>1057.0</td>\n",
       "      <td>251.3</td>\n",
       "      <td>7752.2</td>\n",
       "      <td>...</td>\n",
       "      <td>14339.5</td>\n",
       "      <td>10000.5</td>\n",
       "      <td>1983.3</td>\n",
       "      <td>12883.4</td>\n",
       "      <td>16902.2</td>\n",
       "      <td>12273.0</td>\n",
       "      <td>6022.7</td>\n",
       "      <td>8070.5</td>\n",
       "      <td>832.0</td>\n",
       "      <td>504.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NT005</td>\n",
       "      <td>29960.9</td>\n",
       "      <td>29078.1</td>\n",
       "      <td>2449.1</td>\n",
       "      <td>1753.1</td>\n",
       "      <td>5141.3</td>\n",
       "      <td>2153.2</td>\n",
       "      <td>1091.9</td>\n",
       "      <td>316.1</td>\n",
       "      <td>6663.4</td>\n",
       "      <td>...</td>\n",
       "      <td>11004.1</td>\n",
       "      <td>8994.9</td>\n",
       "      <td>1718.3</td>\n",
       "      <td>11836.7</td>\n",
       "      <td>15599.8</td>\n",
       "      <td>11877.5</td>\n",
       "      <td>6080.8</td>\n",
       "      <td>8108.6</td>\n",
       "      <td>644.7</td>\n",
       "      <td>422.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CT007</td>\n",
       "      <td>27850.0</td>\n",
       "      <td>26192.0</td>\n",
       "      <td>2645.3</td>\n",
       "      <td>2805.1</td>\n",
       "      <td>5603.7</td>\n",
       "      <td>2895.4</td>\n",
       "      <td>983.7</td>\n",
       "      <td>294.7</td>\n",
       "      <td>6849.4</td>\n",
       "      <td>...</td>\n",
       "      <td>14219.8</td>\n",
       "      <td>9203.9</td>\n",
       "      <td>2052.4</td>\n",
       "      <td>11762.2</td>\n",
       "      <td>17044.1</td>\n",
       "      <td>10797.5</td>\n",
       "      <td>6750.9</td>\n",
       "      <td>7203.6</td>\n",
       "      <td>774.1</td>\n",
       "      <td>418.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CT010</td>\n",
       "      <td>30400.2</td>\n",
       "      <td>29906.1</td>\n",
       "      <td>2644.2</td>\n",
       "      <td>2442.0</td>\n",
       "      <td>5439.7</td>\n",
       "      <td>2033.0</td>\n",
       "      <td>834.0</td>\n",
       "      <td>245.2</td>\n",
       "      <td>5858.6</td>\n",
       "      <td>...</td>\n",
       "      <td>8442.9</td>\n",
       "      <td>6909.4</td>\n",
       "      <td>1882.0</td>\n",
       "      <td>18911.9</td>\n",
       "      <td>18284.5</td>\n",
       "      <td>9114.2</td>\n",
       "      <td>5758.8</td>\n",
       "      <td>4446.7</td>\n",
       "      <td>692.8</td>\n",
       "      <td>615.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  71 columns</p>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## extracting the cortical parmeters of each subject into one csv",
   "id": "f786a55068a06aa"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-05T08:27:45.696374Z",
     "start_time": "2025-12-05T08:27:44.806303Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Build per-subject table from aparc_summary, including hemisphere in column names.\n",
    "# Requires helpers already defined: file_regex, list_excel_files, slugify, pick_column, col_sort_key, mark_extraction_complete\n",
    "\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "# ---------- CONFIG ----------\n",
    "FOLDER = Path(\"data/stats_t1_fs\")\n",
    "OUT_CSV = Path(\"data/stats_t1_fs/ses2/ses2_aparc_summary_data.csv\")\n",
    "SHEET_NAME = \"aparc_summary\"\n",
    "\n",
    "SHORTNAME_COLUMN_CANDIDATES = [\"ShortName\"]\n",
    "VALUE_COLUMN_CANDIDATES     = [\"Value\"]\n",
    "HEMI_COLUMN_CANDIDATES      = [\"Hemisphere\"]\n",
    "\n",
    "SHORTNAMES_TO_KEEP = [\"WhiteSurfArea\", \"MeanThickness\"]\n",
    "\n",
    "RENAMES = {}\n",
    "# ----------------------------\n",
    "\n",
    "rows_by_subject = {}\n",
    "all_feature_cols = set()\n",
    "\n",
    "files = list_excel_files(FOLDER, recursive=False)\n",
    "for path in files:\n",
    "\n",
    "    m = file_regex.match(path.name)\n",
    "    if not m:\n",
    "        continue\n",
    "\n",
    "    subject = m.group(\"subject\")\n",
    "    group = m.group(\"group\").upper()\n",
    "    session = int(m.group(\"session\"))\n",
    "\n",
    "    # --- ONLY SESSION 2---\n",
    "    if session != 2:\n",
    "        continue\n",
    "\n",
    "    subject_code = f\"{group}{subject}\"\n",
    "\n",
    "    try:\n",
    "        df = pd.read_excel(path, sheet_name=SHEET_NAME)\n",
    "    except Exception as e:\n",
    "        print(f\"Warning: couldn't read sheet '{SHEET_NAME}' in {path.name}: {e}\")\n",
    "        continue\n",
    "\n",
    "    col_short = pick_column(df, SHORTNAME_COLUMN_CANDIDATES)\n",
    "    col_val   = pick_column(df, VALUE_COLUMN_CANDIDATES)\n",
    "    col_hemi  = pick_column(df, HEMI_COLUMN_CANDIDATES)\n",
    "\n",
    "    if not all([col_short, col_val, col_hemi]):\n",
    "        print(f\"Warning: missing needed columns in {path.name}. \"\n",
    "              f\"ShortName={col_short}, Value={col_val}, Hemisphere={col_hemi}\")\n",
    "        continue\n",
    "\n",
    "    if subject_code not in rows_by_subject:\n",
    "        rows_by_subject[subject_code] = {\"subject_code\": subject_code}\n",
    "\n",
    "    # keep only desired ShortNames\n",
    "    sub = df[df[col_short].astype(str).isin(SHORTNAMES_TO_KEEP)]\n",
    "\n",
    "    for _, r in sub.iterrows():\n",
    "\n",
    "        raw_short = str(r[col_short])\n",
    "        hemi_raw  = str(r[col_hemi]).strip().lower()\n",
    "\n",
    "        # normalize hemisphere\n",
    "        if hemi_raw in (\"left\", \"l\"):  hemi = \"lh\"\n",
    "        elif hemi_raw in (\"right\", \"r\"): hemi = \"rh\"\n",
    "        elif hemi_raw in (\"lh\", \"rh\"): hemi = hemi_raw\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "        key = slugify(raw_short)\n",
    "        key = RENAMES.get(key, key)\n",
    "\n",
    "        # --- FIX: REMOVE SESSION SUFFIX ---\n",
    "        col_name = f\"{key}_{hemi}\"\n",
    "\n",
    "        # numeric convert\n",
    "        val = pd.to_numeric(r[col_val], errors=\"coerce\")\n",
    "\n",
    "        rows_by_subject[subject_code][col_name] = val\n",
    "        all_feature_cols.add(col_name)\n",
    "\n",
    "\n",
    "# build final dataframe\n",
    "all_columns = [\"subject_code\"] + sorted(all_feature_cols, key=col_sort_key)\n",
    "df_out = pd.DataFrame(rows_by_subject.values())\n",
    "\n",
    "# ensure missing columns are filled\n",
    "for c in all_columns:\n",
    "    if c not in df_out.columns:\n",
    "        df_out[c] = np.nan\n",
    "\n",
    "df_out = df_out[all_columns]\n",
    "\n",
    "# save\n",
    "OUT_CSV.parent.mkdir(parents=True, exist_ok=True)\n",
    "df_out.to_csv(OUT_CSV, index=False)\n",
    "\n",
    "print(f\"Saved: {OUT_CSV}\")\n",
    "display(df_out.head(10))\n"
   ],
   "id": "6bffce93b2195dc9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: data\\stats_t1_fs\\ses2\\ses2_aparc_summary_data.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "  subject_code  meanthickness_lh  meanthickness_rh  whitesurfarea_lh  \\\n",
       "0        NT002           2.53983           2.47017           82790.9   \n",
       "1        CT003           2.61352           2.60654           86437.2   \n",
       "2        NT005           2.60428           2.57512           74623.6   \n",
       "3        CT007           2.51822           2.47898           84689.8   \n",
       "4        CT010           2.54736           2.53174           80297.0   \n",
       "5        CT012           2.62747           2.66530           80167.3   \n",
       "6        CT013           2.57238           2.52014           82662.4   \n",
       "7        NT015           2.57023           2.53286           76559.3   \n",
       "8        NT016           2.51704           2.58262           81984.0   \n",
       "9        NT017           2.55015           2.52395           80126.5   \n",
       "\n",
       "   whitesurfarea_rh  \n",
       "0           83587.8  \n",
       "1           85357.4  \n",
       "2           74142.1  \n",
       "3           83382.3  \n",
       "4           79914.2  \n",
       "5           79735.6  \n",
       "6           83327.8  \n",
       "7           76265.9  \n",
       "8           81744.8  \n",
       "9           78178.8  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_code</th>\n",
       "      <th>meanthickness_lh</th>\n",
       "      <th>meanthickness_rh</th>\n",
       "      <th>whitesurfarea_lh</th>\n",
       "      <th>whitesurfarea_rh</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NT002</td>\n",
       "      <td>2.53983</td>\n",
       "      <td>2.47017</td>\n",
       "      <td>82790.9</td>\n",
       "      <td>83587.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CT003</td>\n",
       "      <td>2.61352</td>\n",
       "      <td>2.60654</td>\n",
       "      <td>86437.2</td>\n",
       "      <td>85357.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NT005</td>\n",
       "      <td>2.60428</td>\n",
       "      <td>2.57512</td>\n",
       "      <td>74623.6</td>\n",
       "      <td>74142.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CT007</td>\n",
       "      <td>2.51822</td>\n",
       "      <td>2.47898</td>\n",
       "      <td>84689.8</td>\n",
       "      <td>83382.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CT010</td>\n",
       "      <td>2.54736</td>\n",
       "      <td>2.53174</td>\n",
       "      <td>80297.0</td>\n",
       "      <td>79914.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CT012</td>\n",
       "      <td>2.62747</td>\n",
       "      <td>2.66530</td>\n",
       "      <td>80167.3</td>\n",
       "      <td>79735.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>CT013</td>\n",
       "      <td>2.57238</td>\n",
       "      <td>2.52014</td>\n",
       "      <td>82662.4</td>\n",
       "      <td>83327.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NT015</td>\n",
       "      <td>2.57023</td>\n",
       "      <td>2.53286</td>\n",
       "      <td>76559.3</td>\n",
       "      <td>76265.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NT016</td>\n",
       "      <td>2.51704</td>\n",
       "      <td>2.58262</td>\n",
       "      <td>81984.0</td>\n",
       "      <td>81744.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NT017</td>\n",
       "      <td>2.55015</td>\n",
       "      <td>2.52395</td>\n",
       "      <td>80126.5</td>\n",
       "      <td>78178.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 32
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## extractign from each subject the subcortical parameters and merge into one csv",
   "id": "548c9aec53fe5781"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-05T08:27:46.857721Z",
     "start_time": "2025-12-05T08:27:45.730632Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ---------- CONFIG ----------\n",
    "FOLDER = Path(\"data/stats_t1_fs\")\n",
    "OUT_CSV = Path(\"data/stats_t1_fs/ses2/ses2_aseg_summary_data.csv\")\n",
    "SHEET_NAME = \"aseg_summary\"\n",
    "\n",
    "SHORTNAME_COLUMN_CANDIDATES = [\"ShortName\"]\n",
    "VALUE_COLUMN_CANDIDATES     = [\"Value\"]\n",
    "\n",
    "SHORTNAMES_TO_KEEP = [\n",
    "    \"eTIV\", \"BrainSegVol\", \"lhCortexVol\", \"rhCortexVol\",\n",
    "    \"CortexVol\", \"CerebralWhiteMatterVol\", \"SubCortGrayVol\", \"TotalGrayVol\"\n",
    "]\n",
    "\n",
    "RENAMES = {}\n",
    "# ----------------------------\n",
    "\n",
    "rows_by_subject = {}\n",
    "all_feature_cols = set()\n",
    "\n",
    "files = list_excel_files(FOLDER, recursive=False)\n",
    "for path in files:\n",
    "\n",
    "    m = file_regex.match(path.name)\n",
    "    if not m:\n",
    "        continue\n",
    "\n",
    "    subject = m.group(\"subject\")\n",
    "    group = m.group(\"group\").upper()\n",
    "    session = int(m.group(\"session\"))\n",
    "\n",
    "    # --- ONLY SESSION 2 ---\n",
    "    if session != 2:\n",
    "        continue\n",
    "\n",
    "    subject_code = f\"{group}{subject}\"\n",
    "\n",
    "    try:\n",
    "        df = pd.read_excel(path, sheet_name=SHEET_NAME)\n",
    "    except Exception as e:\n",
    "        print(f\"Warning: couldn't read sheet '{SHEET_NAME}' in {path.name}: {e}\")\n",
    "        continue\n",
    "\n",
    "    col_short = pick_column(df, SHORTNAME_COLUMN_CANDIDATES)\n",
    "    col_val   = pick_column(df, VALUE_COLUMN_CANDIDATES)\n",
    "\n",
    "    if not all([col_short, col_val]):\n",
    "        print(f\"Warning: missing needed columns in {path.name}. ShortName={col_short}, Value={col_val}\")\n",
    "        continue\n",
    "\n",
    "    if subject_code not in rows_by_subject:\n",
    "        rows_by_subject[subject_code] = {\"subject_code\": subject_code}\n",
    "\n",
    "    # filter important metrics\n",
    "    sub = df[df[col_short].astype(str).isin(SHORTNAMES_TO_KEEP)]\n",
    "\n",
    "    for _, r in sub.iterrows():\n",
    "        raw_short = str(r[col_short])\n",
    "        key = slugify(raw_short)\n",
    "        key = RENAMES.get(key, key)\n",
    "\n",
    "        # --- FIX: REMOVE SESSION SUFFIX ---\n",
    "        col_name = key\n",
    "\n",
    "        # numeric convert\n",
    "        val = pd.to_numeric(r[col_val], errors=\"coerce\")\n",
    "\n",
    "        rows_by_subject[subject_code][col_name] = val\n",
    "        all_feature_cols.add(col_name)\n",
    "\n",
    "    # optional logging\n",
    "\n",
    "# finalize dataframe\n",
    "all_columns = [\"subject_code\"] + sorted(all_feature_cols, key=col_sort_key)\n",
    "df_out = pd.DataFrame(rows_by_subject.values())\n",
    "\n",
    "# ensure all columns exist\n",
    "for c in all_columns:\n",
    "    if c not in df_out.columns:\n",
    "        df_out[c] = np.nan\n",
    "\n",
    "df_out = df_out[all_columns]\n",
    "\n",
    "# save\n",
    "OUT_CSV.parent.mkdir(parents=True, exist_ok=True)\n",
    "df_out.to_csv(OUT_CSV, index=False)\n",
    "\n",
    "print(f\"Saved: {OUT_CSV}\")\n",
    "display(df_out.head(10))\n"
   ],
   "id": "3d9cc9ade6d7ff60",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: data\\stats_t1_fs\\ses2\\ses2_aseg_summary_data.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "  subject_code  brainsegvol  cerebralwhitemattervol      cortexvol  \\\n",
       "0        NT002    1098726.0                432028.0  467041.830018   \n",
       "1        CT003    1164172.0                466003.0  504776.174155   \n",
       "2        NT005    1070379.0                419660.0  435276.918266   \n",
       "3        CT007    1135751.0                435282.0  475457.080609   \n",
       "4        CT010    1112571.0                422521.0  455246.833629   \n",
       "5        CT012    1093848.0                403552.0  476809.407913   \n",
       "6        CT013    1072627.0                391345.0  478995.662613   \n",
       "7        NT015    1031328.0                400304.0  437612.253679   \n",
       "8        NT016    1104085.0                407686.0  468350.108376   \n",
       "9        NT017    1079215.0                415807.0  447924.459215   \n",
       "\n",
       "           etiv    lhcortexvol    rhcortexvol  subcortgrayvol   totalgrayvol  \n",
       "0  1.426071e+06  235970.986784  231070.843234         55652.0  630349.830018  \n",
       "1  1.496023e+06  253436.665847  251339.508308         56449.0  660946.174155  \n",
       "2  1.382242e+06  219169.291362  216107.626903         52020.0  602504.918266  \n",
       "3  1.431293e+06  240910.228531  234546.852078         61610.0  660398.080609  \n",
       "4  1.428136e+06  228720.549249  226526.284380         56680.0  636282.833629  \n",
       "5  1.434673e+06  237350.015321  239459.392592         58747.0  641977.407913  \n",
       "6  1.384159e+06  240920.042524  238075.620090         56453.0  644256.662613  \n",
       "7  1.317540e+06  220408.214312  217204.039368         53839.0  597344.253679  \n",
       "8  1.257785e+06  231597.223154  236752.885222         54622.0  654545.108376  \n",
       "9  1.392282e+06  227413.110316  220511.348899         52490.0  613702.459215  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_code</th>\n",
       "      <th>brainsegvol</th>\n",
       "      <th>cerebralwhitemattervol</th>\n",
       "      <th>cortexvol</th>\n",
       "      <th>etiv</th>\n",
       "      <th>lhcortexvol</th>\n",
       "      <th>rhcortexvol</th>\n",
       "      <th>subcortgrayvol</th>\n",
       "      <th>totalgrayvol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NT002</td>\n",
       "      <td>1098726.0</td>\n",
       "      <td>432028.0</td>\n",
       "      <td>467041.830018</td>\n",
       "      <td>1.426071e+06</td>\n",
       "      <td>235970.986784</td>\n",
       "      <td>231070.843234</td>\n",
       "      <td>55652.0</td>\n",
       "      <td>630349.830018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CT003</td>\n",
       "      <td>1164172.0</td>\n",
       "      <td>466003.0</td>\n",
       "      <td>504776.174155</td>\n",
       "      <td>1.496023e+06</td>\n",
       "      <td>253436.665847</td>\n",
       "      <td>251339.508308</td>\n",
       "      <td>56449.0</td>\n",
       "      <td>660946.174155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NT005</td>\n",
       "      <td>1070379.0</td>\n",
       "      <td>419660.0</td>\n",
       "      <td>435276.918266</td>\n",
       "      <td>1.382242e+06</td>\n",
       "      <td>219169.291362</td>\n",
       "      <td>216107.626903</td>\n",
       "      <td>52020.0</td>\n",
       "      <td>602504.918266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CT007</td>\n",
       "      <td>1135751.0</td>\n",
       "      <td>435282.0</td>\n",
       "      <td>475457.080609</td>\n",
       "      <td>1.431293e+06</td>\n",
       "      <td>240910.228531</td>\n",
       "      <td>234546.852078</td>\n",
       "      <td>61610.0</td>\n",
       "      <td>660398.080609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CT010</td>\n",
       "      <td>1112571.0</td>\n",
       "      <td>422521.0</td>\n",
       "      <td>455246.833629</td>\n",
       "      <td>1.428136e+06</td>\n",
       "      <td>228720.549249</td>\n",
       "      <td>226526.284380</td>\n",
       "      <td>56680.0</td>\n",
       "      <td>636282.833629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CT012</td>\n",
       "      <td>1093848.0</td>\n",
       "      <td>403552.0</td>\n",
       "      <td>476809.407913</td>\n",
       "      <td>1.434673e+06</td>\n",
       "      <td>237350.015321</td>\n",
       "      <td>239459.392592</td>\n",
       "      <td>58747.0</td>\n",
       "      <td>641977.407913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>CT013</td>\n",
       "      <td>1072627.0</td>\n",
       "      <td>391345.0</td>\n",
       "      <td>478995.662613</td>\n",
       "      <td>1.384159e+06</td>\n",
       "      <td>240920.042524</td>\n",
       "      <td>238075.620090</td>\n",
       "      <td>56453.0</td>\n",
       "      <td>644256.662613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NT015</td>\n",
       "      <td>1031328.0</td>\n",
       "      <td>400304.0</td>\n",
       "      <td>437612.253679</td>\n",
       "      <td>1.317540e+06</td>\n",
       "      <td>220408.214312</td>\n",
       "      <td>217204.039368</td>\n",
       "      <td>53839.0</td>\n",
       "      <td>597344.253679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NT016</td>\n",
       "      <td>1104085.0</td>\n",
       "      <td>407686.0</td>\n",
       "      <td>468350.108376</td>\n",
       "      <td>1.257785e+06</td>\n",
       "      <td>231597.223154</td>\n",
       "      <td>236752.885222</td>\n",
       "      <td>54622.0</td>\n",
       "      <td>654545.108376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NT017</td>\n",
       "      <td>1079215.0</td>\n",
       "      <td>415807.0</td>\n",
       "      <td>447924.459215</td>\n",
       "      <td>1.392282e+06</td>\n",
       "      <td>227413.110316</td>\n",
       "      <td>220511.348899</td>\n",
       "      <td>52490.0</td>\n",
       "      <td>613702.459215</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 33
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## crate a csv files ov the parces in the cortex along the brain ( not split between the right and left side)",
   "id": "7b08b6118b0b0738"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-05T08:27:46.980965Z",
     "start_time": "2025-12-05T08:27:46.893504Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "# ---------- CONFIG ----------\n",
    "IN_CSV  = Path(\"data/stats_t1_fs/ses2/ses2_aparc_voxels_lh_rh.csv\")\n",
    "OUT_CSV = Path(\"data/stats_t1_fs/ses2/ses2_aparc_voxels_merge.csv\")\n",
    "AGGREGATION = \"sum\"     # \"sum\" or \"mean\"\n",
    "# ----------------------------\n",
    "\n",
    "def merge_two_cols(df, cols, how=\"sum\"):\n",
    "    \"\"\"Utility to merge two numeric columns by sum or mean.\"\"\"\n",
    "    vals = []\n",
    "    for c in cols:\n",
    "        if c is not None and c in df.columns:\n",
    "            vals.append(df[c])\n",
    "    if not vals:\n",
    "        return np.nan\n",
    "    vals = pd.concat(vals, axis=1)\n",
    "    return vals.mean(axis=1) if how == \"mean\" else vals.sum(axis=1)\n",
    "\n",
    "# Load LH/RH file\n",
    "df = pd.read_csv(IN_CSV)\n",
    "\n",
    "# Pattern for columns like: insula_lh , insula_rh\n",
    "pat = re.compile(r\"^(?P<struct>.+)_(?P<hemi>lh|rh)$\", re.IGNORECASE)\n",
    "\n",
    "pairs = {}\n",
    "other_cols = []\n",
    "\n",
    "for col in df.columns:\n",
    "    m = pat.match(col)\n",
    "    if m:\n",
    "        struct = m.group(\"struct\")\n",
    "        hemi   = m.group(\"hemi\").lower()\n",
    "\n",
    "        # No sessions in file  no filtering needed\n",
    "        key = struct\n",
    "        pairs.setdefault(key, {\"lh\": None, \"rh\": None})\n",
    "        pairs[key][hemi] = col\n",
    "\n",
    "    else:\n",
    "        other_cols.append(col)\n",
    "\n",
    "# Start output with non-hemisphere columns first (subject_code)\n",
    "out = df[other_cols].copy()\n",
    "\n",
    "# Create merged columns: \"<struct>\"\n",
    "for struct, hemis in pairs.items():\n",
    "    new_col = struct\n",
    "    out[new_col] = merge_two_cols(df, [hemis.get(\"lh\"), hemis.get(\"rh\")], how=AGGREGATION)\n",
    "\n",
    "# Sort columns (subject_code first)\n",
    "def col_sort_key(c):\n",
    "    return \" 0\" if c == \"subject_code\" else c.lower()\n",
    "\n",
    "out = out[sorted(out.columns, key=col_sort_key)]\n",
    "\n",
    "# Save\n",
    "OUT_CSV.parent.mkdir(parents=True, exist_ok=True)\n",
    "out.to_csv(OUT_CSV, index=False)\n",
    "\n",
    "print(f\"Saved merged file: {OUT_CSV}\")\n",
    "display(out.head(10))\n"
   ],
   "id": "57ac47b4f7a4893",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved merged file: data\\stats_t1_fs\\ses2\\ses2_aparc_voxels_merge.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "  subject_code  bankssts  caudalanteriorcingulate  caudalmiddlefrontal  \\\n",
       "0        NT002      4579                     3445                11643   \n",
       "1        CT003      4977                     3671                12983   \n",
       "2        NT005      4764                     3096                 8133   \n",
       "3        CT007      4126                     4542                11733   \n",
       "4        CT010      4722                     3794                 8563   \n",
       "5        CT012      5359                     3855                10957   \n",
       "6        CT013      4962                     4204                11514   \n",
       "7        NT015      4340                     3074                11861   \n",
       "8        NT016      5390                     4290                10152   \n",
       "9        NT017      6238                     3007                10445   \n",
       "\n",
       "   cuneus  entorhinal  frontalpole  fusiform  inferiorparietal  \\\n",
       "0    8158        3199         3072     19352             28076   \n",
       "1    6265        3644         2592     20023             35161   \n",
       "2    5218        3618         2136     18624             24135   \n",
       "3    5753        4160         2510     18863             25535   \n",
       "4    6720        3180         2639     18998             24366   \n",
       "5    6092        3903         2211     22157             25096   \n",
       "6    6431        3344         2798     21859             28499   \n",
       "7    8074        3075         2035     16821             25314   \n",
       "8    6203        3971         2599     20322             26345   \n",
       "9    5343        3779         2158     20003             30572   \n",
       "\n",
       "   inferiortemporal  ...  precentral  precuneus  rostralanteriorcingulate  \\\n",
       "0             23250  ...       25270      19127                      4741   \n",
       "1             25432  ...       29073      21454                      5092   \n",
       "2             21707  ...       23671      16700                      4266   \n",
       "3             20782  ...       27401      18594                      5008   \n",
       "4             19047  ...       20727      18586                      4952   \n",
       "5             24732  ...       25455      18884                      4322   \n",
       "6             22234  ...       23758      18775                      4705   \n",
       "7             21644  ...       24127      18504                      4218   \n",
       "8             22672  ...       24038      19590                      4763   \n",
       "9             21390  ...       21366      19577                      3806   \n",
       "\n",
       "   rostralmiddlefrontal  superiorfrontal  superiorparietal  superiortemporal  \\\n",
       "0                 31531            41715             27752             23988   \n",
       "1                 32926            43905             29753             24047   \n",
       "2                 29028            38787             24466             22525   \n",
       "3                 32675            45778             24666             26741   \n",
       "4                 33094            45005             23903             22845   \n",
       "5                 31537            43770             20835             27560   \n",
       "6                 30728            44717             25206             23373   \n",
       "7                 27481            35196             22482             22399   \n",
       "8                 29267            38342             28569             24163   \n",
       "9                 27286            38201             23330             23373   \n",
       "\n",
       "   supramarginal  temporalpole  transversetemporal  \n",
       "0          20113          4774                1777  \n",
       "1          18794          6029                1707  \n",
       "2          18930          5389                1922  \n",
       "3          18242          5718                1945  \n",
       "4          20184          4524                1927  \n",
       "5          20464          5831                1965  \n",
       "6          18521          3612                2052  \n",
       "7          19109          3679                1596  \n",
       "8          23431          4443                2484  \n",
       "9          21716          4386                2029  \n",
       "\n",
       "[10 rows x 35 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_code</th>\n",
       "      <th>bankssts</th>\n",
       "      <th>caudalanteriorcingulate</th>\n",
       "      <th>caudalmiddlefrontal</th>\n",
       "      <th>cuneus</th>\n",
       "      <th>entorhinal</th>\n",
       "      <th>frontalpole</th>\n",
       "      <th>fusiform</th>\n",
       "      <th>inferiorparietal</th>\n",
       "      <th>inferiortemporal</th>\n",
       "      <th>...</th>\n",
       "      <th>precentral</th>\n",
       "      <th>precuneus</th>\n",
       "      <th>rostralanteriorcingulate</th>\n",
       "      <th>rostralmiddlefrontal</th>\n",
       "      <th>superiorfrontal</th>\n",
       "      <th>superiorparietal</th>\n",
       "      <th>superiortemporal</th>\n",
       "      <th>supramarginal</th>\n",
       "      <th>temporalpole</th>\n",
       "      <th>transversetemporal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NT002</td>\n",
       "      <td>4579</td>\n",
       "      <td>3445</td>\n",
       "      <td>11643</td>\n",
       "      <td>8158</td>\n",
       "      <td>3199</td>\n",
       "      <td>3072</td>\n",
       "      <td>19352</td>\n",
       "      <td>28076</td>\n",
       "      <td>23250</td>\n",
       "      <td>...</td>\n",
       "      <td>25270</td>\n",
       "      <td>19127</td>\n",
       "      <td>4741</td>\n",
       "      <td>31531</td>\n",
       "      <td>41715</td>\n",
       "      <td>27752</td>\n",
       "      <td>23988</td>\n",
       "      <td>20113</td>\n",
       "      <td>4774</td>\n",
       "      <td>1777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CT003</td>\n",
       "      <td>4977</td>\n",
       "      <td>3671</td>\n",
       "      <td>12983</td>\n",
       "      <td>6265</td>\n",
       "      <td>3644</td>\n",
       "      <td>2592</td>\n",
       "      <td>20023</td>\n",
       "      <td>35161</td>\n",
       "      <td>25432</td>\n",
       "      <td>...</td>\n",
       "      <td>29073</td>\n",
       "      <td>21454</td>\n",
       "      <td>5092</td>\n",
       "      <td>32926</td>\n",
       "      <td>43905</td>\n",
       "      <td>29753</td>\n",
       "      <td>24047</td>\n",
       "      <td>18794</td>\n",
       "      <td>6029</td>\n",
       "      <td>1707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NT005</td>\n",
       "      <td>4764</td>\n",
       "      <td>3096</td>\n",
       "      <td>8133</td>\n",
       "      <td>5218</td>\n",
       "      <td>3618</td>\n",
       "      <td>2136</td>\n",
       "      <td>18624</td>\n",
       "      <td>24135</td>\n",
       "      <td>21707</td>\n",
       "      <td>...</td>\n",
       "      <td>23671</td>\n",
       "      <td>16700</td>\n",
       "      <td>4266</td>\n",
       "      <td>29028</td>\n",
       "      <td>38787</td>\n",
       "      <td>24466</td>\n",
       "      <td>22525</td>\n",
       "      <td>18930</td>\n",
       "      <td>5389</td>\n",
       "      <td>1922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CT007</td>\n",
       "      <td>4126</td>\n",
       "      <td>4542</td>\n",
       "      <td>11733</td>\n",
       "      <td>5753</td>\n",
       "      <td>4160</td>\n",
       "      <td>2510</td>\n",
       "      <td>18863</td>\n",
       "      <td>25535</td>\n",
       "      <td>20782</td>\n",
       "      <td>...</td>\n",
       "      <td>27401</td>\n",
       "      <td>18594</td>\n",
       "      <td>5008</td>\n",
       "      <td>32675</td>\n",
       "      <td>45778</td>\n",
       "      <td>24666</td>\n",
       "      <td>26741</td>\n",
       "      <td>18242</td>\n",
       "      <td>5718</td>\n",
       "      <td>1945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CT010</td>\n",
       "      <td>4722</td>\n",
       "      <td>3794</td>\n",
       "      <td>8563</td>\n",
       "      <td>6720</td>\n",
       "      <td>3180</td>\n",
       "      <td>2639</td>\n",
       "      <td>18998</td>\n",
       "      <td>24366</td>\n",
       "      <td>19047</td>\n",
       "      <td>...</td>\n",
       "      <td>20727</td>\n",
       "      <td>18586</td>\n",
       "      <td>4952</td>\n",
       "      <td>33094</td>\n",
       "      <td>45005</td>\n",
       "      <td>23903</td>\n",
       "      <td>22845</td>\n",
       "      <td>20184</td>\n",
       "      <td>4524</td>\n",
       "      <td>1927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CT012</td>\n",
       "      <td>5359</td>\n",
       "      <td>3855</td>\n",
       "      <td>10957</td>\n",
       "      <td>6092</td>\n",
       "      <td>3903</td>\n",
       "      <td>2211</td>\n",
       "      <td>22157</td>\n",
       "      <td>25096</td>\n",
       "      <td>24732</td>\n",
       "      <td>...</td>\n",
       "      <td>25455</td>\n",
       "      <td>18884</td>\n",
       "      <td>4322</td>\n",
       "      <td>31537</td>\n",
       "      <td>43770</td>\n",
       "      <td>20835</td>\n",
       "      <td>27560</td>\n",
       "      <td>20464</td>\n",
       "      <td>5831</td>\n",
       "      <td>1965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>CT013</td>\n",
       "      <td>4962</td>\n",
       "      <td>4204</td>\n",
       "      <td>11514</td>\n",
       "      <td>6431</td>\n",
       "      <td>3344</td>\n",
       "      <td>2798</td>\n",
       "      <td>21859</td>\n",
       "      <td>28499</td>\n",
       "      <td>22234</td>\n",
       "      <td>...</td>\n",
       "      <td>23758</td>\n",
       "      <td>18775</td>\n",
       "      <td>4705</td>\n",
       "      <td>30728</td>\n",
       "      <td>44717</td>\n",
       "      <td>25206</td>\n",
       "      <td>23373</td>\n",
       "      <td>18521</td>\n",
       "      <td>3612</td>\n",
       "      <td>2052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NT015</td>\n",
       "      <td>4340</td>\n",
       "      <td>3074</td>\n",
       "      <td>11861</td>\n",
       "      <td>8074</td>\n",
       "      <td>3075</td>\n",
       "      <td>2035</td>\n",
       "      <td>16821</td>\n",
       "      <td>25314</td>\n",
       "      <td>21644</td>\n",
       "      <td>...</td>\n",
       "      <td>24127</td>\n",
       "      <td>18504</td>\n",
       "      <td>4218</td>\n",
       "      <td>27481</td>\n",
       "      <td>35196</td>\n",
       "      <td>22482</td>\n",
       "      <td>22399</td>\n",
       "      <td>19109</td>\n",
       "      <td>3679</td>\n",
       "      <td>1596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NT016</td>\n",
       "      <td>5390</td>\n",
       "      <td>4290</td>\n",
       "      <td>10152</td>\n",
       "      <td>6203</td>\n",
       "      <td>3971</td>\n",
       "      <td>2599</td>\n",
       "      <td>20322</td>\n",
       "      <td>26345</td>\n",
       "      <td>22672</td>\n",
       "      <td>...</td>\n",
       "      <td>24038</td>\n",
       "      <td>19590</td>\n",
       "      <td>4763</td>\n",
       "      <td>29267</td>\n",
       "      <td>38342</td>\n",
       "      <td>28569</td>\n",
       "      <td>24163</td>\n",
       "      <td>23431</td>\n",
       "      <td>4443</td>\n",
       "      <td>2484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NT017</td>\n",
       "      <td>6238</td>\n",
       "      <td>3007</td>\n",
       "      <td>10445</td>\n",
       "      <td>5343</td>\n",
       "      <td>3779</td>\n",
       "      <td>2158</td>\n",
       "      <td>20003</td>\n",
       "      <td>30572</td>\n",
       "      <td>21390</td>\n",
       "      <td>...</td>\n",
       "      <td>21366</td>\n",
       "      <td>19577</td>\n",
       "      <td>3806</td>\n",
       "      <td>27286</td>\n",
       "      <td>38201</td>\n",
       "      <td>23330</td>\n",
       "      <td>23373</td>\n",
       "      <td>21716</td>\n",
       "      <td>4386</td>\n",
       "      <td>2029</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows  35 columns</p>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## merge between parcels along the hemispheres to create lobes and arrange the into one csv",
   "id": "d2a1aeb36d8ae7bf"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-05T08:27:47.109521Z",
     "start_time": "2025-12-05T08:27:47.018568Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "# ---------- CONFIG ----------\n",
    "IN_CSV   = Path(\"data/stats_t1_fs/ses2/ses2_aparc_voxels_lh_rh.csv\")\n",
    "MAP_XLSX = Path(\"data/stats_t1_fs/mapping_lobes_networks.xlsx\")\n",
    "MAP_SHEET = \"aparc_voxels_normalized_ttests\"\n",
    "\n",
    "OUT_CSV = Path(\"data/stats_t1_fs/ses2/ses2_aparc_lobes_lr.csv\")\n",
    "\n",
    "AGGREGATION = \"sum\"   # \"sum\" or \"mean\"\n",
    "STRUCTNAME_COL_CANDIDATES = [\"Parameter\"]\n",
    "LOBEFILTER_COL_CANDIDATES = [\"Lobes\"]\n",
    "# --------------------------------\n",
    "\n",
    "# Pattern for columns like: insula_lh or precuneus_rh\n",
    "pat = re.compile(r\"^(?P<struct>.+)_(?P<hemi>lh|rh)$\", re.IGNORECASE)\n",
    "\n",
    "# Load LH/RH-style file\n",
    "df = pd.read_csv(IN_CSV)\n",
    "\n",
    "# All region-level columns\n",
    "lr_cols = [c for c in df.columns if pat.match(c)]\n",
    "\n",
    "# --- 2) Load mapping for struct  lobe ---\n",
    "map_df = pd.read_excel(MAP_XLSX, sheet_name=MAP_SHEET)\n",
    "col_struct = pick_column(map_df, STRUCTNAME_COL_CANDIDATES)\n",
    "col_lobe   = pick_column(map_df, LOBEFILTER_COL_CANDIDATES)\n",
    "\n",
    "map_df = map_df[[col_struct, col_lobe]].dropna()\n",
    "map_df[col_struct] = map_df[col_struct].astype(str)\n",
    "map_df[col_lobe]   = map_df[col_lobe].astype(str)\n",
    "\n",
    "# Mapping uses non-hemisphere names  slugify\n",
    "struct_to_lobe = {\n",
    "    slugify(s): slugify(l)\n",
    "    for s, l in zip(map_df[col_struct], map_df[col_lobe])\n",
    "}\n",
    "\n",
    "# --- 3) Determine structs that exist in CSV ---\n",
    "present_structs = {}\n",
    "for c in lr_cols:\n",
    "    m = pat.match(c)\n",
    "    struct = slugify(m.group(\"struct\"))\n",
    "    hemi   = m.group(\"hemi\").lower()\n",
    "    present_structs.setdefault(struct, set()).add(hemi)\n",
    "\n",
    "# Output (start with subject_code)\n",
    "out = df[[\"subject_code\"]].copy()\n",
    "\n",
    "# Lobes present in BOTH data & mapping\n",
    "lobes_present = sorted({\n",
    "    struct_to_lobe.get(struct)\n",
    "    for struct in present_structs\n",
    "    if struct_to_lobe.get(struct) is not None\n",
    "})\n",
    "\n",
    "# --- 4) Aggregate by lobe and hemisphere ---\n",
    "def reduce_cols(df, cols, how=\"sum\"):\n",
    "    if not cols:\n",
    "        return np.nan\n",
    "    vals = df[cols]\n",
    "    return vals.mean(axis=1) if how == \"mean\" else vals.sum(axis=1)\n",
    "\n",
    "for lobe in lobes_present:\n",
    "    for hemi in (\"lh\", \"rh\"):\n",
    "        cols_for_group = []\n",
    "        for struct in present_structs:\n",
    "\n",
    "            # skip if struct not assigned to this lobe\n",
    "            if struct_to_lobe.get(struct) != lobe:\n",
    "                continue\n",
    "\n",
    "            col_name = f\"{struct}_{hemi}\"\n",
    "            if col_name in df.columns:\n",
    "                cols_for_group.append(col_name)\n",
    "\n",
    "        # ALWAYS create a column (even if empty) for consistency\n",
    "        new_col = f\"{lobe}_{hemi}\"\n",
    "        out[new_col] = reduce_cols(df, cols_for_group, how=AGGREGATION)\n",
    "\n",
    "# Sort columns\n",
    "def order_key(c):\n",
    "    return \" 0\" if c == \"subject_code\" else c.lower()\n",
    "\n",
    "out = out[sorted(out.columns, key=order_key)]\n",
    "\n",
    "# Save\n",
    "OUT_CSV.parent.mkdir(parents=True, exist_ok=True)\n",
    "out.to_csv(OUT_CSV, index=False)\n",
    "\n",
    "print(f\"Saved lobe-level file: {OUT_CSV}\")\n",
    "display(out.head(10))\n"
   ],
   "id": "26e48aeeae172e73",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved lobe-level file: data\\stats_t1_fs\\ses2\\ses2_aparc_lobes_lr.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "  subject_code  cingulate_lh  cingulate_rh  frontal_lh  frontal_rh  insula_lh  \\\n",
       "0        NT002          9525          9767       84987       78929       6454   \n",
       "1        CT003         10438          9949       89117       88941       6563   \n",
       "2        NT005          7271          8535       79151       75220       8017   \n",
       "3        CT007          9926         11358       92743       86548       7207   \n",
       "4        CT010          9800         10009       79270       85702       6363   \n",
       "5        CT012          9596         10471       85530       83433       7577   \n",
       "6        CT013         10936         10014       87884       84834       6784   \n",
       "7        NT015          9468          7617       74930       74928       6483   \n",
       "8        NT016          9289         10992       79260       79476       6582   \n",
       "9        NT017          9217          7526       78777       77023       6701   \n",
       "\n",
       "   insula_rh  occipital_lh  occipital_rh  parietal_lh  parietal_rh  \\\n",
       "0       6136         25121         27506        56993        55219   \n",
       "1       6085         24755         25926        63330        65360   \n",
       "2       7694         21182         21997        49062        51324   \n",
       "3       7242         24109         24609        50691        52915   \n",
       "4       6153         25503         27415        56446        46166   \n",
       "5       7480         23507         24856        50048        51916   \n",
       "6       7060         27218         27059        53481        54265   \n",
       "7       6059         26398         26922        51254        51356   \n",
       "8       6748         22572         27181        56742        56610   \n",
       "9       6647         21193         22112        55769        54753   \n",
       "\n",
       "   temporal_lh  temporal_rh  \n",
       "0        52785        53510  \n",
       "1        58963        54846  \n",
       "2        54209        51011  \n",
       "3        56065        51659  \n",
       "4        51053        50793  \n",
       "5        60694        60971  \n",
       "6        54676        54525  \n",
       "7        51652        49947  \n",
       "8        56679        55316  \n",
       "9        55440        52108  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_code</th>\n",
       "      <th>cingulate_lh</th>\n",
       "      <th>cingulate_rh</th>\n",
       "      <th>frontal_lh</th>\n",
       "      <th>frontal_rh</th>\n",
       "      <th>insula_lh</th>\n",
       "      <th>insula_rh</th>\n",
       "      <th>occipital_lh</th>\n",
       "      <th>occipital_rh</th>\n",
       "      <th>parietal_lh</th>\n",
       "      <th>parietal_rh</th>\n",
       "      <th>temporal_lh</th>\n",
       "      <th>temporal_rh</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NT002</td>\n",
       "      <td>9525</td>\n",
       "      <td>9767</td>\n",
       "      <td>84987</td>\n",
       "      <td>78929</td>\n",
       "      <td>6454</td>\n",
       "      <td>6136</td>\n",
       "      <td>25121</td>\n",
       "      <td>27506</td>\n",
       "      <td>56993</td>\n",
       "      <td>55219</td>\n",
       "      <td>52785</td>\n",
       "      <td>53510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CT003</td>\n",
       "      <td>10438</td>\n",
       "      <td>9949</td>\n",
       "      <td>89117</td>\n",
       "      <td>88941</td>\n",
       "      <td>6563</td>\n",
       "      <td>6085</td>\n",
       "      <td>24755</td>\n",
       "      <td>25926</td>\n",
       "      <td>63330</td>\n",
       "      <td>65360</td>\n",
       "      <td>58963</td>\n",
       "      <td>54846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NT005</td>\n",
       "      <td>7271</td>\n",
       "      <td>8535</td>\n",
       "      <td>79151</td>\n",
       "      <td>75220</td>\n",
       "      <td>8017</td>\n",
       "      <td>7694</td>\n",
       "      <td>21182</td>\n",
       "      <td>21997</td>\n",
       "      <td>49062</td>\n",
       "      <td>51324</td>\n",
       "      <td>54209</td>\n",
       "      <td>51011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CT007</td>\n",
       "      <td>9926</td>\n",
       "      <td>11358</td>\n",
       "      <td>92743</td>\n",
       "      <td>86548</td>\n",
       "      <td>7207</td>\n",
       "      <td>7242</td>\n",
       "      <td>24109</td>\n",
       "      <td>24609</td>\n",
       "      <td>50691</td>\n",
       "      <td>52915</td>\n",
       "      <td>56065</td>\n",
       "      <td>51659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CT010</td>\n",
       "      <td>9800</td>\n",
       "      <td>10009</td>\n",
       "      <td>79270</td>\n",
       "      <td>85702</td>\n",
       "      <td>6363</td>\n",
       "      <td>6153</td>\n",
       "      <td>25503</td>\n",
       "      <td>27415</td>\n",
       "      <td>56446</td>\n",
       "      <td>46166</td>\n",
       "      <td>51053</td>\n",
       "      <td>50793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CT012</td>\n",
       "      <td>9596</td>\n",
       "      <td>10471</td>\n",
       "      <td>85530</td>\n",
       "      <td>83433</td>\n",
       "      <td>7577</td>\n",
       "      <td>7480</td>\n",
       "      <td>23507</td>\n",
       "      <td>24856</td>\n",
       "      <td>50048</td>\n",
       "      <td>51916</td>\n",
       "      <td>60694</td>\n",
       "      <td>60971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>CT013</td>\n",
       "      <td>10936</td>\n",
       "      <td>10014</td>\n",
       "      <td>87884</td>\n",
       "      <td>84834</td>\n",
       "      <td>6784</td>\n",
       "      <td>7060</td>\n",
       "      <td>27218</td>\n",
       "      <td>27059</td>\n",
       "      <td>53481</td>\n",
       "      <td>54265</td>\n",
       "      <td>54676</td>\n",
       "      <td>54525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NT015</td>\n",
       "      <td>9468</td>\n",
       "      <td>7617</td>\n",
       "      <td>74930</td>\n",
       "      <td>74928</td>\n",
       "      <td>6483</td>\n",
       "      <td>6059</td>\n",
       "      <td>26398</td>\n",
       "      <td>26922</td>\n",
       "      <td>51254</td>\n",
       "      <td>51356</td>\n",
       "      <td>51652</td>\n",
       "      <td>49947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NT016</td>\n",
       "      <td>9289</td>\n",
       "      <td>10992</td>\n",
       "      <td>79260</td>\n",
       "      <td>79476</td>\n",
       "      <td>6582</td>\n",
       "      <td>6748</td>\n",
       "      <td>22572</td>\n",
       "      <td>27181</td>\n",
       "      <td>56742</td>\n",
       "      <td>56610</td>\n",
       "      <td>56679</td>\n",
       "      <td>55316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NT017</td>\n",
       "      <td>9217</td>\n",
       "      <td>7526</td>\n",
       "      <td>78777</td>\n",
       "      <td>77023</td>\n",
       "      <td>6701</td>\n",
       "      <td>6647</td>\n",
       "      <td>21193</td>\n",
       "      <td>22112</td>\n",
       "      <td>55769</td>\n",
       "      <td>54753</td>\n",
       "      <td>55440</td>\n",
       "      <td>52108</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 35
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## creating a file of the lobes per brain and arrange this into csv",
   "id": "8da29edbfe78b60d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-05T08:27:47.309231Z",
     "start_time": "2025-12-05T08:27:47.217336Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "# ---------- CONFIG ----------\n",
    "IN_CSV   = Path(\"data/stats_t1_fs/ses2/ses2_aparc_voxels_merge.csv\")\n",
    "MAP_XLSX = Path(\"data/stats_t1_fs/mapping_lobes_networks.xlsx\")\n",
    "MAP_SHEET = \"aparc_voxels_normalized_ttests\"\n",
    "\n",
    "OUT_CSV = Path(\"data/stats_t1_fs/ses2/ses2_aparc_lobes_full_brain.csv\")\n",
    "\n",
    "AGGREGATION = \"sum\"   # \"sum\" or \"mean\"\n",
    "STRUCTNAME_COL_CANDIDATES = [\"Parameter\"]\n",
    "LOBEFILTER_COL_CANDIDATES = [\"Lobes\"]\n",
    "# --------------------------------\n",
    "\n",
    "# No session pattern needed  column names are just <struct>\n",
    "df = pd.read_csv(IN_CSV)\n",
    "\n",
    "# All structural columns (exclude subject_code)\n",
    "struct_cols = [c for c in df.columns if c != \"subject_code\"]\n",
    "\n",
    "# --- Load mapping file ---\n",
    "map_df = pd.read_excel(MAP_XLSX, sheet_name=MAP_SHEET)\n",
    "\n",
    "col_struct = pick_column(map_df, STRUCTNAME_COL_CANDIDATES)\n",
    "col_lobe   = pick_column(map_df, LOBEFILTER_COL_CANDIDATES)\n",
    "\n",
    "map_df = map_df[[col_struct, col_lobe]].dropna()\n",
    "map_df[col_struct] = map_df[col_struct].astype(str)\n",
    "map_df[col_lobe]   = map_df[col_lobe].astype(str)\n",
    "\n",
    "# slugify mapping\n",
    "struct_to_lobe = {\n",
    "    slugify(s): slugify(l)\n",
    "    for s, l in zip(map_df[col_struct], map_df[col_lobe])\n",
    "}\n",
    "\n",
    "# Determine structs present in CSV\n",
    "present_structs = {slugify(c) for c in struct_cols}\n",
    "\n",
    "# Lobes present\n",
    "lobes_present = sorted({\n",
    "    struct_to_lobe.get(s)\n",
    "    for s in present_structs\n",
    "    if struct_to_lobe.get(s) is not None\n",
    "})\n",
    "\n",
    "# Output dataframe\n",
    "out = df[[\"subject_code\"]].copy()\n",
    "\n",
    "# Reduce per-lobe\n",
    "def reduce_cols(df, cols, how=\"sum\"):\n",
    "    if not cols:\n",
    "        return np.nan\n",
    "    vals = df[cols]\n",
    "    return vals.mean(axis=1) if how == \"mean\" else vals.sum(axis=1)\n",
    "\n",
    "for lobe in lobes_present:\n",
    "\n",
    "    cols_for_group = []\n",
    "\n",
    "    for struct_col in struct_cols:\n",
    "        if struct_to_lobe.get(slugify(struct_col)) == lobe:\n",
    "            cols_for_group.append(struct_col)\n",
    "\n",
    "    out[lobe] = reduce_cols(df, cols_for_group, how=AGGREGATION)\n",
    "\n",
    "# Order columns\n",
    "def order_key(c):\n",
    "    return \" 0\" if c == \"subject_code\" else c\n",
    "\n",
    "out = out[sorted(out.columns, key=order_key)]\n",
    "\n",
    "# Save\n",
    "OUT_CSV.parent.mkdir(parents=True, exist_ok=True)\n",
    "out.to_csv(OUT_CSV, index=False)\n",
    "\n",
    "print(f\"Saved lobe-level file: {OUT_CSV}\")\n",
    "display(out.head(10))\n"
   ],
   "id": "c15f1854981808d0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved lobe-level file: data\\stats_t1_fs\\ses2\\ses2_aparc_lobes_full_brain.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "  subject_code  cingulate  frontal  insula  occipital  parietal  temporal\n",
       "0        NT002      19292   163916   12590      52627    112212    106295\n",
       "1        CT003      20387   178058   12648      50681    128690    113809\n",
       "2        NT005      15806   154371   15711      43179    100386    105220\n",
       "3        CT007      21284   179291   14449      48718    103606    107724\n",
       "4        CT010      19809   164972   12516      52918    102612    101846\n",
       "5        CT012      20067   168963   15057      48363    101964    121665\n",
       "6        CT013      20950   172718   13844      54277    107746    109201\n",
       "7        NT015      17085   149858   12542      53320    102610    101599\n",
       "8        NT016      20281   158736   13330      49753    113352    111995\n",
       "9        NT017      16743   155800   13348      43305    110522    107548"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_code</th>\n",
       "      <th>cingulate</th>\n",
       "      <th>frontal</th>\n",
       "      <th>insula</th>\n",
       "      <th>occipital</th>\n",
       "      <th>parietal</th>\n",
       "      <th>temporal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NT002</td>\n",
       "      <td>19292</td>\n",
       "      <td>163916</td>\n",
       "      <td>12590</td>\n",
       "      <td>52627</td>\n",
       "      <td>112212</td>\n",
       "      <td>106295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CT003</td>\n",
       "      <td>20387</td>\n",
       "      <td>178058</td>\n",
       "      <td>12648</td>\n",
       "      <td>50681</td>\n",
       "      <td>128690</td>\n",
       "      <td>113809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NT005</td>\n",
       "      <td>15806</td>\n",
       "      <td>154371</td>\n",
       "      <td>15711</td>\n",
       "      <td>43179</td>\n",
       "      <td>100386</td>\n",
       "      <td>105220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CT007</td>\n",
       "      <td>21284</td>\n",
       "      <td>179291</td>\n",
       "      <td>14449</td>\n",
       "      <td>48718</td>\n",
       "      <td>103606</td>\n",
       "      <td>107724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CT010</td>\n",
       "      <td>19809</td>\n",
       "      <td>164972</td>\n",
       "      <td>12516</td>\n",
       "      <td>52918</td>\n",
       "      <td>102612</td>\n",
       "      <td>101846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CT012</td>\n",
       "      <td>20067</td>\n",
       "      <td>168963</td>\n",
       "      <td>15057</td>\n",
       "      <td>48363</td>\n",
       "      <td>101964</td>\n",
       "      <td>121665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>CT013</td>\n",
       "      <td>20950</td>\n",
       "      <td>172718</td>\n",
       "      <td>13844</td>\n",
       "      <td>54277</td>\n",
       "      <td>107746</td>\n",
       "      <td>109201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NT015</td>\n",
       "      <td>17085</td>\n",
       "      <td>149858</td>\n",
       "      <td>12542</td>\n",
       "      <td>53320</td>\n",
       "      <td>102610</td>\n",
       "      <td>101599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NT016</td>\n",
       "      <td>20281</td>\n",
       "      <td>158736</td>\n",
       "      <td>13330</td>\n",
       "      <td>49753</td>\n",
       "      <td>113352</td>\n",
       "      <td>111995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NT017</td>\n",
       "      <td>16743</td>\n",
       "      <td>155800</td>\n",
       "      <td>13348</td>\n",
       "      <td>43305</td>\n",
       "      <td>110522</td>\n",
       "      <td>107548</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 36
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## creatnf csv file for the networks for the whole brain based on previous mappping",
   "id": "6058499b63f9110a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-05T08:27:47.404788Z",
     "start_time": "2025-12-05T08:27:47.312173Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "# ---------- CONFIG ----------\n",
    "IN_CSV   = Path(\"data/stats_t1_fs/ses2/ses2_aparc_voxels_merge.csv\")\n",
    "MAP_XLSX = Path(\"data/stats_t1_fs/mapping_lobes_networks.xlsx\")\n",
    "MAP_SHEET = \"aparc_voxels_normalized_ttests\"\n",
    "\n",
    "OUT_CSV = Path(\"data/stats_t1_fs/ses2/ses2_aparc_nets_full_brain.csv\")\n",
    "\n",
    "AGGREGATION = \"sum\"   # \"sum\" (default) or \"mean\"\n",
    "STRUCTNAME_COL_CANDIDATES = [\"Parameter\"]\n",
    "YEOFILTER_COL_CANDIDATES  = [\"Yeo\"]\n",
    "# --------------------------------\n",
    "\n",
    "# Pattern for columns WITHOUT sessions: <struct>\n",
    "pat = re.compile(r\"^(?P<struct>.+)$\")\n",
    "\n",
    "# 1) Load input table\n",
    "df = pd.read_csv(IN_CSV)\n",
    "\n",
    "# keep only structural columns (exclude subject_code)\n",
    "struct_cols = [c for c in df.columns if c != \"subject_code\"]\n",
    "df_struct = df[[\"subject_code\"] + struct_cols].copy()\n",
    "\n",
    "# 2) Load mapping file\n",
    "map_df = pd.read_excel(MAP_XLSX, sheet_name=MAP_SHEET)\n",
    "\n",
    "col_struct = pick_column(map_df, STRUCTNAME_COL_CANDIDATES)\n",
    "col_net    = pick_column(map_df, YEOFILTER_COL_CANDIDATES)\n",
    "\n",
    "map_df = map_df[[col_struct, col_net]].dropna()\n",
    "map_df[col_struct] = map_df[col_struct].astype(str)\n",
    "map_df[col_net]    = map_df[col_net].astype(str)\n",
    "\n",
    "# slugify mapping\n",
    "struct_to_net = {\n",
    "    slugify(s): slugify(n)\n",
    "    for s, n in zip(map_df[col_struct], map_df[col_net])\n",
    "}\n",
    "\n",
    "# Which structs exist (slugified)\n",
    "present_structs = {slugify(c) for c in struct_cols}\n",
    "\n",
    "# Networks that actually appear\n",
    "networks_present = sorted({\n",
    "    struct_to_net.get(s)\n",
    "    for s in present_structs\n",
    "    if struct_to_net.get(s)\n",
    "})\n",
    "\n",
    "# 3) Aggregate networks\n",
    "out = df_struct[[\"subject_code\"]].copy()\n",
    "\n",
    "def reduce_cols(df, cols, how=\"sum\"):\n",
    "    if not cols:\n",
    "        return np.nan\n",
    "    vals = df[cols]\n",
    "    return vals.mean(axis=1) if how == \"mean\" else vals.sum(axis=1)\n",
    "\n",
    "for net in networks_present:\n",
    "    cols_for_group = []\n",
    "\n",
    "    for struct_col in struct_cols:\n",
    "        if struct_to_net.get(slugify(struct_col)) == net:\n",
    "            cols_for_group.append(struct_col)\n",
    "\n",
    "    out[net] = reduce_cols(df_struct, cols_for_group, how=AGGREGATION)\n",
    "\n",
    "# 4) Sort\n",
    "def order_key(c):\n",
    "    return \" 0\" if c == \"subject_code\" else c\n",
    "\n",
    "out = out[sorted(out.columns, key=order_key)]\n",
    "\n",
    "# 5) Rename networks\n",
    "net_map = {\n",
    "    \"default_mode\"      : \"DMN_GM\",\n",
    "    \"dorsal_attention\"  : \"DAN_GM\",\n",
    "    \"frontoparietal\"    : \"FPN_GM\",\n",
    "    \"limbic\"            : \"LIM_GM\",\n",
    "    \"somatomotor\"       : \"SMN_GM\",\n",
    "    \"ventral_attention\" : \"VAN_GM\",\n",
    "    \"visual\"            : \"VIS_GM\",\n",
    "}\n",
    "\n",
    "out = out.rename(columns=net_map)\n",
    "\n",
    "# Save\n",
    "OUT_CSV.parent.mkdir(parents=True, exist_ok=True)\n",
    "out.to_csv(OUT_CSV, index=False)\n",
    "\n",
    "print(f\"Saved network-level file (no sessions): {OUT_CSV}\")\n",
    "display(out.head(10))\n"
   ],
   "id": "29a45b22dbfe9216",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved network-level file (no sessions): data\\stats_t1_fs\\ses2\\ses2_aparc_nets_full_brain.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "  subject_code  DMN_GM  DAN_GM  FPN_GM  LIM_GM  SMN_GM  VAN_GM  VIS_GM\n",
       "0        NT002  139908   27752   43174   57681   74665   51773   71979\n",
       "1        CT003  155634   29753   45909   65389   86844   50040   70704\n",
       "2        NT005  129439   24466   37161   57323   70700   53781   61803\n",
       "3        CT007  142120   24666   44408   60856   78762   56679   67581\n",
       "4        CT010  140862   23903   41657   53975   68826   53534   71916\n",
       "5        CT012  145244   20835   42494   62125   78424   56437   70520\n",
       "6        CT013  147309   25206   42242   59456   73384   55003   76136\n",
       "7        NT015  130953   22482   39342   53820   71315   48961   70141\n",
       "8        NT016  139734   28569   39419   59945   72395   57310   70075\n",
       "9        NT017  139925   23330   37731   57606   68591   56775   63308"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_code</th>\n",
       "      <th>DMN_GM</th>\n",
       "      <th>DAN_GM</th>\n",
       "      <th>FPN_GM</th>\n",
       "      <th>LIM_GM</th>\n",
       "      <th>SMN_GM</th>\n",
       "      <th>VAN_GM</th>\n",
       "      <th>VIS_GM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NT002</td>\n",
       "      <td>139908</td>\n",
       "      <td>27752</td>\n",
       "      <td>43174</td>\n",
       "      <td>57681</td>\n",
       "      <td>74665</td>\n",
       "      <td>51773</td>\n",
       "      <td>71979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CT003</td>\n",
       "      <td>155634</td>\n",
       "      <td>29753</td>\n",
       "      <td>45909</td>\n",
       "      <td>65389</td>\n",
       "      <td>86844</td>\n",
       "      <td>50040</td>\n",
       "      <td>70704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NT005</td>\n",
       "      <td>129439</td>\n",
       "      <td>24466</td>\n",
       "      <td>37161</td>\n",
       "      <td>57323</td>\n",
       "      <td>70700</td>\n",
       "      <td>53781</td>\n",
       "      <td>61803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CT007</td>\n",
       "      <td>142120</td>\n",
       "      <td>24666</td>\n",
       "      <td>44408</td>\n",
       "      <td>60856</td>\n",
       "      <td>78762</td>\n",
       "      <td>56679</td>\n",
       "      <td>67581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CT010</td>\n",
       "      <td>140862</td>\n",
       "      <td>23903</td>\n",
       "      <td>41657</td>\n",
       "      <td>53975</td>\n",
       "      <td>68826</td>\n",
       "      <td>53534</td>\n",
       "      <td>71916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CT012</td>\n",
       "      <td>145244</td>\n",
       "      <td>20835</td>\n",
       "      <td>42494</td>\n",
       "      <td>62125</td>\n",
       "      <td>78424</td>\n",
       "      <td>56437</td>\n",
       "      <td>70520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>CT013</td>\n",
       "      <td>147309</td>\n",
       "      <td>25206</td>\n",
       "      <td>42242</td>\n",
       "      <td>59456</td>\n",
       "      <td>73384</td>\n",
       "      <td>55003</td>\n",
       "      <td>76136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NT015</td>\n",
       "      <td>130953</td>\n",
       "      <td>22482</td>\n",
       "      <td>39342</td>\n",
       "      <td>53820</td>\n",
       "      <td>71315</td>\n",
       "      <td>48961</td>\n",
       "      <td>70141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NT016</td>\n",
       "      <td>139734</td>\n",
       "      <td>28569</td>\n",
       "      <td>39419</td>\n",
       "      <td>59945</td>\n",
       "      <td>72395</td>\n",
       "      <td>57310</td>\n",
       "      <td>70075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NT017</td>\n",
       "      <td>139925</td>\n",
       "      <td>23330</td>\n",
       "      <td>37731</td>\n",
       "      <td>57606</td>\n",
       "      <td>68591</td>\n",
       "      <td>56775</td>\n",
       "      <td>63308</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 37
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## creating the merged final file",
   "id": "eba332595e9e328a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-05T08:27:47.930347Z",
     "start_time": "2025-12-05T08:27:47.443522Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "# ========== CONFIG ==========\n",
    "OUTPUT_XLSX = Path(\"data/stats_t1_fs/ses2/ses2_T1_data.xlsx\")\n",
    "\n",
    "# The sheet that merges TWO CSVs into one\n",
    "MERGED_SHEET_NAME = \"global_parameters\"\n",
    "MERGED_CSVS = [\n",
    "    Path(\"data/stats_t1_fs/ses2/ses2_aparc_summary_data.csv\"),\n",
    "    Path(\"data/stats_t1_fs/ses2/ses2_aseg_summary_data.csv\"),\n",
    "]\n",
    "MERGE_KEY = \"subject_code\"\n",
    "MERGE_HOW = \"outer\"           # \"inner\", \"left\", \"right\", \"outer\"\n",
    "MERGE_SUFFIXES = (\"_x\", \"_y\") # for overlapping column names\n",
    "\n",
    "# Other individual sheets: sheet_name -> csv path\n",
    "OTHER_SHEETS = {\n",
    "    \"subcortical_vol\": Path(\"data/stats_t1_fs/ses2/ses2_aseg_data.csv\"),\n",
    "    \"cortical_vol_lr\": Path(\"data/stats_t1_fs/ses2/ses2_aparc_voxels_lh_rh.csv\"),\n",
    "    \"cortical_vol_full_brain\": Path(\"data/stats_t1_fs/ses2/ses2_aparc_voxels_merge.csv\"),\n",
    "    \"cortical_lobes_lr_\": Path(\"data/stats_t1_fs/ses2/ses2_aparc_lobes_lr.csv\"),\n",
    "    \"cortical_lobes_full_brain\": Path(\"data/stats_t1_fs/ses2/ses2_aparc_lobes_full_brain.csv\"),  # <- check your path (removed .csv.csv)\n",
    "    \"cortical_networks_full_brain\": Path(\"data/stats_t1_fs/ses2/ses2_aparc_nets_full_brain.csv\"),\n",
    "}\n",
    "# ===========================\n",
    "\n",
    "# ---------- helpers (local to this cell) ----------\n",
    "\n",
    "# ---------------------------------------------------\n",
    "\n",
    "# 1) Merge the two CSVs into one sheet\n",
    "df_a = _read_csv(MERGED_CSVS[0], MERGE_KEY)\n",
    "df_b = _read_csv(MERGED_CSVS[1], MERGE_KEY)\n",
    "\n",
    "if df_a.empty and df_b.empty:\n",
    "    merged_df = pd.DataFrame(columns=[MERGE_KEY])\n",
    "else:\n",
    "    if MERGE_KEY not in df_a.columns or MERGE_KEY not in df_b.columns:\n",
    "        raise ValueError(f\"MERGE_KEY '{MERGE_KEY}' must be present in both files.\")\n",
    "    merged_df = df_a.merge(df_b, on=MERGE_KEY, how=MERGE_HOW, suffixes=MERGE_SUFFIXES)\n",
    "\n",
    "# Keep subject_code first, then sort consistently\n",
    "merged_df = _order_columns_subject_first(merged_df, MERGE_KEY)\n",
    "merged_df = _sort_consistent(merged_df, MERGE_KEY)\n",
    "\n",
    "# 2) Write everything to one Excel workbook (all sheets sorted the same way)\n",
    "with pd.ExcelWriter(OUTPUT_XLSX, engine=\"openpyxl\") as writer:\n",
    "    # merged sheet\n",
    "    merged_df.to_excel(writer, index=False, sheet_name=MERGED_SHEET_NAME[:31])\n",
    "    _autosize_columns(writer, merged_df, MERGED_SHEET_NAME[:31])\n",
    "\n",
    "    # other sheets (one CSV per sheet)\n",
    "    for sheet_name, csv_path in OTHER_SHEETS.items():\n",
    "        df = _read_csv(csv_path, MERGE_KEY)\n",
    "        df = _order_columns_subject_first(df, MERGE_KEY)\n",
    "        df = _sort_consistent(df, MERGE_KEY)\n",
    "        safe_name = sheet_name[:31]  # Excel sheet name limit is 31 chars\n",
    "        df.to_excel(writer, index=False, sheet_name=safe_name)\n",
    "        _autosize_columns(writer, df, safe_name)\n",
    "\n",
    "print(f\"Saved Excel workbook: {OUTPUT_XLSX}\")\n"
   ],
   "id": "cdde2349016e7ece",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Excel workbook: data\\stats_t1_fs\\ses2\\ses2_T1_data.xlsx\n"
     ]
    }
   ],
   "execution_count": 38
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## adding the dict column to the column dict sheet",
   "id": "172cdc77fe901ca5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-05T08:27:48.499409Z",
     "start_time": "2025-12-05T08:27:48.022421Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "MAP_XLSX = Path(\"data/stats_t1_fs/ses2/ses2_T1_data.xlsx\")\n",
    "\n",
    "# Load workbook\n",
    "xlsx = pd.ExcelFile(MAP_XLSX)\n",
    "\n",
    "print(\" Sheets found in workbook:\\n\")\n",
    "\n",
    "for sheet in xlsx.sheet_names:\n",
    "    print(f\"--- Sheet: {sheet} ---\")\n",
    "    df = pd.read_excel(MAP_XLSX, sheet_name=sheet)\n",
    "    print(\"Columns:\", list(df.columns))\n",
    "    print()\n"
   ],
   "id": "5c9b749d3bcb24a2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Sheets found in workbook:\n",
      "\n",
      "--- Sheet: global_parameters ---\n",
      "Columns: ['subject_code', 'meanthickness_lh', 'meanthickness_rh', 'whitesurfarea_lh', 'whitesurfarea_rh', 'brainsegvol', 'cerebralwhitemattervol', 'cortexvol', 'etiv', 'lhcortexvol', 'rhcortexvol', 'subcortgrayvol', 'totalgrayvol']\n",
      "\n",
      "--- Sheet: subcortical_vol ---\n",
      "Columns: ['subject_code', '3rd_ventricle', '4th_ventricle', '5th_ventricle', 'brain_stem', 'cc_anterior', 'cc_central', 'cc_mid_anterior', 'cc_mid_posterior', 'cc_posterior', 'csf', 'left_accumbens_area', 'left_amygdala', 'left_caudate', 'left_cerebellum_cortex', 'left_cerebellum_white_matter', 'left_choroid_plexus', 'left_hippocampus', 'left_inf_lat_vent', 'left_lateral_ventricle', 'left_non_wm_hypointensities', 'left_pallidum', 'left_putamen', 'left_thalamus', 'left_ventraldc', 'left_vessel', 'left_wm_hypointensities', 'non_wm_hypointensities', 'optic_chiasm', 'right_accumbens_area', 'right_amygdala', 'right_caudate', 'right_cerebellum_cortex', 'right_cerebellum_white_matter', 'right_choroid_plexus', 'right_hippocampus', 'right_inf_lat_vent', 'right_lateral_ventricle', 'right_non_wm_hypointensities', 'right_pallidum', 'right_putamen', 'right_thalamus', 'right_ventraldc', 'right_vessel', 'right_wm_hypointensities', 'wm_hypointensities']\n",
      "\n",
      "--- Sheet: cortical_vol_lr ---\n",
      "Columns: ['subject_code', 'bankssts_lh', 'bankssts_rh', 'caudalanteriorcingulate_lh', 'caudalanteriorcingulate_rh', 'caudalmiddlefrontal_lh', 'caudalmiddlefrontal_rh', 'cuneus_lh', 'cuneus_rh', 'entorhinal_lh', 'entorhinal_rh', 'frontalpole_lh', 'frontalpole_rh', 'fusiform_lh', 'fusiform_rh', 'inferiorparietal_lh', 'inferiorparietal_rh', 'inferiortemporal_lh', 'inferiortemporal_rh', 'insula_lh', 'insula_rh', 'isthmuscingulate_lh', 'isthmuscingulate_rh', 'lateraloccipital_lh', 'lateraloccipital_rh', 'lateralorbitofrontal_lh', 'lateralorbitofrontal_rh', 'lingual_lh', 'lingual_rh', 'medialorbitofrontal_lh', 'medialorbitofrontal_rh', 'middletemporal_lh', 'middletemporal_rh', 'paracentral_lh', 'paracentral_rh', 'parahippocampal_lh', 'parahippocampal_rh', 'parsopercularis_lh', 'parsopercularis_rh', 'parsorbitalis_lh', 'parsorbitalis_rh', 'parstriangularis_lh', 'parstriangularis_rh', 'pericalcarine_lh', 'pericalcarine_rh', 'postcentral_lh', 'postcentral_rh', 'posteriorcingulate_lh', 'posteriorcingulate_rh', 'precentral_lh', 'precentral_rh', 'precuneus_lh', 'precuneus_rh', 'rostralanteriorcingulate_lh', 'rostralanteriorcingulate_rh', 'rostralmiddlefrontal_lh', 'rostralmiddlefrontal_rh', 'superiorfrontal_lh', 'superiorfrontal_rh', 'superiorparietal_lh', 'superiorparietal_rh', 'superiortemporal_lh', 'superiortemporal_rh', 'supramarginal_lh', 'supramarginal_rh', 'temporalpole_lh', 'temporalpole_rh', 'transversetemporal_lh', 'transversetemporal_rh']\n",
      "\n",
      "--- Sheet: cortical_vol_full_brain ---\n",
      "Columns: ['subject_code', 'bankssts', 'caudalanteriorcingulate', 'caudalmiddlefrontal', 'cuneus', 'entorhinal', 'frontalpole', 'fusiform', 'inferiorparietal', 'inferiortemporal', 'insula', 'isthmuscingulate', 'lateraloccipital', 'lateralorbitofrontal', 'lingual', 'medialorbitofrontal', 'middletemporal', 'paracentral', 'parahippocampal', 'parsopercularis', 'parsorbitalis', 'parstriangularis', 'pericalcarine', 'postcentral', 'posteriorcingulate', 'precentral', 'precuneus', 'rostralanteriorcingulate', 'rostralmiddlefrontal', 'superiorfrontal', 'superiorparietal', 'superiortemporal', 'supramarginal', 'temporalpole', 'transversetemporal']\n",
      "\n",
      "--- Sheet: cortical_lobes_lr_ ---\n",
      "Columns: ['subject_code', 'cingulate_lh', 'cingulate_rh', 'frontal_lh', 'frontal_rh', 'insula_lh', 'insula_rh', 'occipital_lh', 'occipital_rh', 'parietal_lh', 'parietal_rh', 'temporal_lh', 'temporal_rh']\n",
      "\n",
      "--- Sheet: cortical_lobes_full_brain ---\n",
      "Columns: ['subject_code', 'cingulate', 'frontal', 'insula', 'occipital', 'parietal', 'temporal']\n",
      "\n",
      "--- Sheet: cortical_networks_full_brain ---\n",
      "Columns: ['subject_code', 'DMN_GM', 'DAN_GM', 'FPN_GM', 'LIM_GM', 'SMN_GM', 'VAN_GM', 'VIS_GM']\n",
      "\n"
     ]
    }
   ],
   "execution_count": 39
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-05T08:27:49.152514Z",
     "start_time": "2025-12-05T08:27:48.502969Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "from openpyxl import load_workbook\n",
    "\n",
    "# ---------- CONFIG ----------\n",
    "EXCEL_PATH = \"data/stats_t1_fs/ses2/ses2_T1_data.xlsx\"\n",
    "DICT_SHEET = \"dict_columns\"\n",
    "# ----------------------------\n",
    "\n",
    "# Load workbook\n",
    "wb = load_workbook(EXCEL_PATH)\n",
    "\n",
    "# If dict_columns already exists  delete it (fresh rebuild)\n",
    "if DICT_SHEET in wb.sheetnames:\n",
    "    wb.remove(wb[DICT_SHEET])\n",
    "\n",
    "# Create new empty sheet\n",
    "ws = wb.create_sheet(DICT_SHEET)\n",
    "\n",
    "# Load sheet names using pandas\n",
    "xlsx = pd.ExcelFile(EXCEL_PATH)\n",
    "\n",
    "current_col = 1  # Start in column A\n",
    "\n",
    "for sheet in xlsx.sheet_names:\n",
    "\n",
    "    # Write sheet name in row 1\n",
    "    ws.cell(row=1, column=current_col, value=sheet)\n",
    "\n",
    "    # Load the sheet to get the columns\n",
    "    df = pd.read_excel(EXCEL_PATH, sheet_name=sheet)\n",
    "\n",
    "    # Write each column name below\n",
    "    for row_i, col_name in enumerate(df.columns, start=2):\n",
    "        ws.cell(row=row_i, column=current_col, value=col_name)\n",
    "\n",
    "    # Move 3 columns right  1 for data, 2 blank columns between blocks\n",
    "    current_col += 3\n",
    "\n",
    "# Save updated workbook (same file)\n",
    "wb.save(EXCEL_PATH)\n",
    "\n",
    "print(f\"Sheet '{DICT_SHEET}' created and saved into {EXCEL_PATH}\")\n"
   ],
   "id": "7e352257fb8a4882",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sheet 'dict_columns' created and saved into data/stats_t1_fs/ses2/ses2_T1_data.xlsx\n"
     ]
    }
   ],
   "execution_count": 40
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
